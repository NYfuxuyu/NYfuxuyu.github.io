(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{492:function(t,s,a){"use strict";a.r(s);var n=a(4),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("blockquote",[a("p",[t._v("场景设计")])]),t._v(" "),a("h2",{attrs:{id:"系统设计思路"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#系统设计思路"}},[t._v("#")]),t._v(" 系统设计思路")]),t._v(" "),a("p",[t._v("这部分内容主要参考了Github的一个国外的开源项目，写的很好，感兴趣的小伙伴可以去看看：")]),t._v(" "),a("p",[t._v("https:// github.com/donnemartin/system-design-primer")]),t._v(" "),a("p",[t._v("常见的系统设计题有设计一个秒杀系统、红包雨、URL短网址等，完成一个系统设计题大概需要分为四步。 需要注意的是，在面试过程中是比较紧张的，但遇到这种系统设计题，一定先不要急着回答，一定要先需要设计系统的一些使用场景。")]),t._v(" "),a("ol",[a("li",[t._v("第一步：像面试官不断提问，搞清楚系统的使用场景 系统的功能是什么系统的目标群体是什么系统的用户量有多大 希望每秒钟处理多少请求？希望处理多少数据？希望的读写比率？")]),t._v(" "),a("li",[t._v("第二步：创造一个高层级的设计画出主要的组件和连接")])]),t._v(" "),a("p",[t._v("例如设计一个网络爬虫，这个是个完整的架构图，在这一步只需要画出一个抽象的架构图即 可，不需要这么具体。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072100719.png",alt:"image-20220507210044470"}})]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v("设计核心组件 对每一个核心组件进行具体地分析。例如，面试官让你设计一个url短网址，你需要考虑这些问题")])]),t._v(" "),a("ul",[a("li",[t._v("生成并储存一个完整 url 的hash\n"),a("ul",[a("li",[t._v("MD5和 Base62")]),t._v(" "),a("li",[t._v("Hash 碰撞")]),t._v(" "),a("li",[t._v("SQL 还是 NoSQL")]),t._v(" "),a("li",[t._v("数据库模型")])])]),t._v(" "),a("li",[t._v("将一个 hashed url 翻译成完整的 url\n"),a("ul",[a("li",[t._v("数据库查找")])])]),t._v(" "),a("li",[t._v("API 和面向对象设计")])]),t._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[t._v("对系统进行优化找到系统的瓶颈所在，对其进行优化，例如可以考虑水平扩展、数据库分片等等。")])]),t._v(" "),a("h2",{attrs:{id:"系统性能指标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#系统性能指标"}},[t._v("#")]),t._v(" 系统性能指标")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("响应时间")]),t._v(" "),a("p",[t._v("响应时间指从发出请求开始到收到最后响应数据所需的时间，响应时间是系统最重要的性能指标其直观地反映了系统的“快慢”。")])]),t._v(" "),a("li",[a("p",[t._v("并发数")]),t._v(" "),a("p",[t._v("并发数指系统能够同时处理请求的数目，这个数字反映了系统的负载特性。")])]),t._v(" "),a("li",[a("p",[t._v("吞吐量")]),t._v(" "),a("p",[t._v("吞吐量指单位时间内系统处理的请求数量，体现系统的整体处理能力。")]),t._v(" "),a("p",[t._v("QPS（Query Per Second）：服务器每秒可以执行的查询次数")]),t._v(" "),a("p",[t._v("TPS（Transaction Per Second）：服务器每秒处理的事务数")]),t._v(" "),a("p",[t._v("并发数=QPS*平均响应时间")])]),t._v(" "),a("li",[a("p",[t._v("经常听到的一些系统活跃度的名词")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("PV（Page View）")]),t._v(" "),a("p",[t._v("页面点击量或者浏览量，用户每次对网站中的每个页面访问均被记录一个PV，多次访问则会累计")])]),t._v(" "),a("li",[a("p",[t._v("UV（Unique visitor）")]),t._v(" "),a("p",[t._v("独立访客，统计一天内访问网站的用户数，一个用户多次访问网站算一个用户")])]),t._v(" "),a("li",[a("p",[t._v("IP（Internet Protocol）")]),t._v(" "),a("p",[t._v("指一天内访问某站点的IP总数，以用户的IP地址作为统计的指标，相同IP多次访问某站点算一 次")]),t._v(" "),a("p",[t._v("IP和UV的区别： 在同一个IP地址下，两个不同的账号访问同一个站点，UV算两次，IP算一次")])]),t._v(" "),a("li",[a("p",[t._v("DAU（Daily Active User）：日活跃用户数量。")])]),t._v(" "),a("li",[a("p",[t._v("MAU(monthly active users)：月活跃用户人数。")])])])]),t._v(" "),a("li",[a("p",[t._v("常用软件的QPS")]),t._v(" "),a("ul",[a("li",[t._v("Nginx：一般Nginx的QPS是比较大的，单机的可达到30万")]),t._v(" "),a("li",[t._v("MySQL：对于读操作可达几百k，对于写操作更低，大概只有100k")]),t._v(" "),a("li",[t._v("Redis：大概在几万左右，像set命令甚至可达10万")]),t._v(" "),a("li",[t._v("Tomcat：单机 Tomcat 的QPS 在 2万左右。")]),t._v(" "),a("li",[t._v("Memcached：大概在几十万左右")])])])]),t._v(" "),a("h2",{attrs:{id:"经典系统设计题目"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#经典系统设计题目"}},[t._v("#")]),t._v(" 经典系统设计题目")]),t._v(" "),a("h3",{attrs:{id:"分布式id生成器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分布式id生成器"}},[t._v("#")]),t._v(" 分布式ID生成器")]),t._v(" "),a("p",[t._v("如何设计一个分布式ID生成器(Distributed ID Generator)，并保证ID按时间粗略有序？")]),t._v(" "),a("p",[t._v("应用场景(Scenario)")]),t._v(" "),a("p",[t._v("现实中很多业务都有生成唯一ID的需求，例如：")]),t._v(" "),a("ul",[a("li",[t._v("用户ID")]),t._v(" "),a("li",[t._v("微博ID")]),t._v(" "),a("li",[t._v("聊天消息ID")]),t._v(" "),a("li",[t._v("帖子ID")]),t._v(" "),a("li",[t._v("订单ID")])]),t._v(" "),a("p",[t._v("这个ID往往会作为数据库主键，所以需要保证全局唯一。数据库会在这个字段上建立聚集索引 (Clustered Index，参考 MySQL InnoDB)，即该字段会影响各条数据再物理存储上的顺序。")]),t._v(" "),a("p",[t._v("ID还要尽可能短，节省内存，让数据库索引效率更高。基本上64位整数能够满足绝大多数的场景，但是 如果能做到比64位更短那就更好了。需要根据具体业务进行分析，预估出ID的最大值，这个最大值通常 比64位整数的上限小很多，于是我们可以用更少的bit表示这个ID。")]),t._v(" "),a("p",[t._v("查询的时候，往往有分页或者排序的需求，所以需要给每条数据添加一个时间字段，并在其上建立普通 索引(Secondary Index)。但是普通索引的访问效率比聚集索引慢，如果能够让ID按照时间粗略有序，则 可以省去这个时间字段。为什么不是按照时间精确有序呢？因为按照时间精确有序是做不到的，除非用 一个单机算法，在分布式场景下做到精确有序性能一般很差。")]),t._v(" "),a("p",[a("strong",[t._v("这就引出了ID生成的三大核心需求：")])]),t._v(" "),a("ul",[a("li",[t._v("全局唯一(unique)")]),t._v(" "),a("li",[t._v("按照时间粗略有序(sortable by time)")]),t._v(" "),a("li",[t._v("尽可能短")])]),t._v(" "),a("p",[t._v("下面介绍一些常用的生成ID的方法。")]),t._v(" "),a("p",[t._v("UUID")]),t._v(" "),a("p",[t._v("用过MongoDB的人会知道，MongoDB会自动给每一条数据赋予一个唯一的ObjectId,保证不会重复，这 是怎么做到的呢？实际上它用的是一种UUID算法，生成的ObjectId占12个字节，由以下几个部分组成，")]),t._v(" "),a("ul",[a("li",[t._v("4个字节表示的Unix timestamp")]),t._v(" "),a("li",[t._v("3个字节表示的机器的ID")]),t._v(" "),a("li",[t._v("2个字节表示的进程ID")]),t._v(" "),a("li",[t._v("3个字节表示的计数器")])]),t._v(" "),a("p",[t._v("UUID是一类算法的统称，具体有不同的实现。UUID的有点是每台机器可以独立产生ID，理论上保证不会重复，所以天然是分布式的，缺点是生成的ID太长，不仅占用内存，而且索引查询效率低。")]),t._v(" "),a("p",[t._v("多台MySQL服务器")]),t._v(" "),a("p",[t._v("既然MySQL可以产生自增ID，那么用多台MySQL服务器，能否组成一个高性能的分布式发号器呢？ 显然可以。")]),t._v(" "),a("p",[t._v("假设用8台MySQL服务器协同工作，第一台MySQL初始值是1，每次自增8，第二台MySQL初始值是2， 每次自增8，依次类推。前面用一个 round-robin load balancer 挡着，每来一个请求，由 round-robin  balancer 随机地将请求发给8台MySQL中的任意一个，然后返回一个ID。")]),t._v(" "),a("p",[t._v("Flickr就是这么做的，仅仅使用了两台MySQL服务器。可见这个方法虽然简单无脑，但是性能足够好。 不过要注意，在MySQL中，不需要把所有ID都存下来，每台机器只需要存一个MAX_ID就可以了。这需要用到MySQL的一个REPLACE INTO特性。")]),t._v(" "),a("p",[t._v("这个方法跟单台数据库比，缺点是ID是不是严格递增的，只是粗略递增的。不过这个问题不大，我们的目标是粗略有序，不需要严格递增。")]),t._v(" "),a("p",[a("strong",[t._v("Twitter Snowflake")])]),t._v(" "),a("p",[t._v("比如 Twitter 有个成熟的开源项目，就是专门生成ID的，Twitter Snowflake 。Snowflake的核心算法如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072110162.png",alt:"image-20220507211034902"}})]),t._v(" "),a("p",[t._v("最高位不用，永远为0，其余三组bit占位均可浮动，看具体的业务需求而定。默认情况下41bit的时间戳 可以支持该算法使用到2082年，10bit的工作机器id可以支持1023台机器，序列号支持1毫秒产生4095 个自增序列id。")]),t._v(" "),a("p",[t._v("Instagram用了类似的方案，41位表示时间戳，13位表示shard Id(一个shard Id对应一台PostgreSQL机 器),最低10位表示自增ID，怎么样，跟Snowflake的设计非常类似吧。这个方案用一个PostgreSQL集群 代替了Twitter Snowflake 集群，优点是利用了现成的PostgreSQL，容易懂，维护方便。")]),t._v(" "),a("p",[t._v("有的面试官会问，如何让ID可以粗略的按照时间排序？上面的这种格式的ID，含有时间戳，且在高位， 恰好满足要求。如果面试官又问，如何保证ID严格有序呢？在分布式这个场景下，是做不到的，要想高性能，只能做到粗略有序，无法保证严格有序。")]),t._v(" "),a("h3",{attrs:{id:"短网址系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#短网址系统"}},[t._v("#")]),t._v(" 短网址系统")]),t._v(" "),a("p",[t._v("如何设计一个短网址服务(TinyURL)？")]),t._v(" "),a("p",[a("strong",[t._v("使用场景(Scenario)")])]),t._v(" "),a("p",[t._v("微博和Twitter都有140字数的限制，如果分享一个长网址，很容易就超出限制，发布出去。短网址服务 可以把一个长网址变成短网址，方便在社交网络上传播。")]),t._v(" "),a("p",[t._v("短网址的长度")]),t._v(" "),a("p",[t._v("当前互联网上的网页总数大概是 45亿(参考 http://www.worldwidewebsize.com)，45亿超过了 2^{32}=4294967296232=4294967296，但远远小于64位整数的上限值，那么用一个64位整数足够了。")]),t._v(" "),a("p",[t._v("微博的短网址服务用的是长度为7的字符串，这个字符串可以看做是62进制的数，那么最大能表示 {62}^7=3521614606208627=3521614606208个网址，远远大于45亿。所以长度为7就足够了。")]),t._v(" "),a("p",[t._v("一个64位整数如何转化为字符串呢？，假设我们只是用大小写字母加数字，那么可以看做是62进制数， log_{62} {(2^{64}-1)}=10.7log62(264−1)=10.7，即字符串最长11就足够了。")]),t._v(" "),a("p",[t._v("实际生产中，还可以再短一点，比如新浪微博采用的长度就是7，因为 62^7=3521614606208627=3521614606208，这个量级远远超过互联网上的URL总数了，绝对够用 了。")]),t._v(" "),a("p",[t._v("现代的web服务器（例如Apache, Nginx）大部分都区分URL里的大小写了，所以用大小写字母来区分不 同的URL是没问题的。")]),t._v(" "),a("p",[t._v("因此，"),a("strong",[t._v("正确答案：长度不超过7的字符串，由大小写字母加数字共62个字母组成")])]),t._v(" "),a("p",[t._v("一对一还是一对多映射？")]),t._v(" "),a("p",[t._v("一个长网址，对应一个短网址，还是可以对应多个短网址？ 这也是个重大选择问题")]),t._v(" "),a("p",[t._v("一般而言，一个长网址，在不同的地点，不同的用户等情况下，生成的短网址应该不一样，这样，在后端数据库中，可以更好的进行数据分析。如果一个长网址与一个短网址一一对应，那么在数据库中，仅有一行数据，无法区分不同的来源，就无法做数据分析了。")]),t._v(" "),a("p",[t._v("以这个7位长度的短网址作为唯一ID，这个ID下可以挂各种信息，比如生成该网址的用户名，所在网站， HTTP头部的 User Agent等信息，收集了这些信息，才有可能在后面做大数据分析，挖掘数据的价值。 短网址服务商的一大盈利来源就是这些数据。")]),t._v(" "),a("p",[a("strong",[t._v("正确答案：一对多")])]),t._v(" "),a("p",[t._v("如何计算短网址")]),t._v(" "),a("p",[t._v("现在我们设定了短网址是一个长度为7的字符串，如何计算得到这个短网址呢？ 最容易想到的办法是哈希，先hash得到一个64位整数，将它转化为62进制整，截取低7位即可。但是哈 希算法会有冲突，如何处理冲突呢，又是一个麻烦。这个方法只是转移了矛盾，没有解决矛盾，抛弃。")]),t._v(" "),a("p",[a("strong",[t._v("正确答案：分布式ID生成器")])]),t._v(" "),a("p",[t._v("如何存储")]),t._v(" "),a("p",[t._v("如果存储短网址和长网址的对应关系？以短网址为 primary key, 长网址为value, 可以用传统的关系数据 库存起来，例如MySQL, PostgreSQL，也可以用任意一个分布式KV数据库，例如Redis, LevelDB。")]),t._v(" "),a("p",[t._v("如果你手痒想要手工设计这个存储，那就是另一个话题了，你需要完整地造一个KV存储引擎轮子。当前 流行的KV存储引擎有LevelDB何RockDB，去读它们的源码吧")]),t._v(" "),a("p",[t._v("301还是302重定向")]),t._v(" "),a("p",[t._v("这也是一个有意思的问题。这个问题主要是考察你对301和302的理解，以及浏览器缓存机制的理解。")]),t._v(" "),a("p",[t._v("301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。但 是如果用了301， Google，百度等搜索引擎，搜索的时候会直接展示真实地址，那我们就无法统计到短 地址被点击的次数了，也无法收集用户的Cookie, User Agent 等信息，这些信息可以用来做很多有意思 的大数据分析，也是短网址服务商的主要盈利来源。")]),t._v(" "),a("p",[a("strong",[t._v("所以，正确答案是302重定向。")])]),t._v(" "),a("p",[t._v("预防攻击")]),t._v(" "),a("p",[t._v("如果一些别有用心的黑客，短时间内向TinyURL服务器发送大量的请求，会迅速耗光ID，怎么办呢？")]),t._v(" "),a("p",[t._v("首先，限制IP的单日请求总数，超过阈值则直接拒绝服务。")]),t._v(" "),a("p",[t._v("光限制IP的请求数还不够，因为黑客一般手里有上百万台肉鸡的，IP地址大大的有，所以光限制IP作用不大")]),t._v(" "),a("p",[t._v("可以用一台Redis作为缓存服务器，存储的不是 ID->长网址，而是 长网址->ID，仅存储一天以内的数 据，用LRU机制进行淘汰。这样，如果黑客大量发同一个长网址过来，直接从缓存服务器里返回短网址即可，他就无法耗光我们的ID了。")]),t._v(" "),a("h3",{attrs:{id:"定时任务调度器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#定时任务调度器"}},[t._v("#")]),t._v(" 定时任务调度器")]),t._v(" "),a("p",[t._v("请实现一个定时任务调度器，有很多任务，每个任务都有一个时间戳，任务会在该时间点开始执行。")]),t._v(" "),a("p",[t._v("定时执行任务是一个很常见的需求，例如Uber打车48小时后自动好评，淘宝购物15天后默认好评，等等。")]),t._v(" "),a("h5",{attrs:{id:"方案1-priorityblockingqueue-polling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案1-priorityblockingqueue-polling"}},[t._v("#")]),t._v(" "),a("strong",[t._v("方案1: PriorityBlockingQueue + Polling")])]),t._v(" "),a("p",[t._v("我们很快可以想到第一个办法：")]),t._v(" "),a("ul",[a("li",[t._v("用一个"),a("code",[t._v("java.util.concurrent.PriorityBlockingQueue")]),t._v(" 来作为优先队列。因为我们需要一个优 先队列，又需要线程安全，用"),a("code",[t._v("PriorityBlockingQueue")]),t._v(" 再合适不过了。你也可以手工实现一个自 己的 "),a("code",[t._v("PriorityBlockingQueue")]),t._v("，用 "),a("code",[t._v("java.util.PriorityQueue + ReentrantLock")]),t._v("，用一把锁 把这个队列保护起来，就是线程安全的啦")]),t._v(" "),a("li",[t._v("对于生产者，可以用一个"),a("code",[t._v("while(true)")]),t._v(" ，造一些随机任务塞进去")]),t._v(" "),a("li",[t._v("对于消费者，起一个线程，在 "),a("code",[t._v("while(true)")]),t._v(" 里每隔几秒检查一下队列，如果有任务，则取出来执行")])]),t._v(" "),a("p",[t._v("这个方案的确可行，总结起来就是轮询(polling)。轮询通常有个很大的缺点，就是时间间隔不好设置， 间隔太长，任务无法及时处理，间隔太短，会很耗CPU。")]),t._v(" "),a("h5",{attrs:{id:"方案2-priorityblockingqueue-时间差"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案2-priorityblockingqueue-时间差"}},[t._v("#")]),t._v(" "),a("strong",[t._v("方案2: PriorityBlockingQueue + 时间差")])]),t._v(" "),a("p",[t._v("可以把方案1改进一下， while(true) 里的逻辑变成：")]),t._v(" "),a("ul",[a("li",[t._v("偷看一下堆顶的元素，但并不取出来，如果该任务过期了，则取出来")]),t._v(" "),a("li",[t._v("如果没过期，则计算一下时间差，然后 sleep()该时间差")])]),t._v(" "),a("p",[t._v("不再是 sleep() 一个固定间隔了，消除了轮询的缺点。")]),t._v(" "),a("p",[t._v("稍等！这个方案其实有个致命的缺陷，导致它比 PiorityBlockingQueue + Polling 更加不可用，这 个缺点是什么呢？。。。假设当前堆顶的任务在100秒后执行，消费者线程peek()偷看到了后，开始 sleep 100秒，这时候一个新的任务插了进来，该任务在10秒后应该执行，但是由于消费者线程要睡眠 100秒，这个新任务无法及时处理")]),t._v(" "),a("h5",{attrs:{id:"方案3-delayqueue"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案3-delayqueue"}},[t._v("#")]),t._v(" "),a("strong",[t._v("方案3: DelayQueue")])]),t._v(" "),a("p",[t._v("方案2虽然已经不错了，但是还可以优化一下，Java里有一个DelayQueue，完全符合题目的要求。 DelayQueue 设计得非常巧妙，可以看做是一个特化版的 PriorityBlockingQueue ，它把"),a("strong",[t._v("计算时间差并让消费者等待该时间差的功能集成进了队列")]),t._v("，消费者不需要关心时间差的事情了，直接在 while(true) 里不断 take() 就行了")]),t._v(" "),a("p",[t._v("DelayQueue的实现原理见下面的代码。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delayed")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("locks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Condition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("locks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReentrantLock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TimeUnit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NANOSECONDS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delayed")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("transient")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReentrantLock")]),t._v(" lock "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReentrantLock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" q "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Condition")]),t._v(" available "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("newCondition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),t._v(" leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * Inserts the specified element into this delay queue.\n     *\n     * @param e the element to add\n     * @return {@code true}\n     * @throws NullPointerException if the specified element is null\n     */")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("boolean")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReentrantLock")]),t._v(" lock "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("lock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("offer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("peek")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("signal")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("unlock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * Retrieves and removes the head of this queue, waiting if necessary\n     * until an element with an expired delay is available on this queue.\n     *\n     * @return the head of this queue\n     * @throws InterruptedException {@inheritDoc}\n     */")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("take")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("InterruptedException")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReentrantLock")]),t._v(" lock "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("lockInterruptibly")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("E")]),t._v(" first "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("peek")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("first "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("await")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" delay "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDelay")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("NANOSECONDS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delay "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    first "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// don't retain ref while waiting")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("await")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),t._v(" thisThread "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("currentThread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                        leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" thisThread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                           available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awaitNanos")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" thisThread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n               "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("peek")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("signal")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            lock"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("unlock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),a("p",[t._v("这个代码中有几个要点要注意一下。")]),t._v(" "),a("p",[a("strong",[t._v("1.put()方法")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("peek")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("signal")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("如果第一个元素等于刚刚插入进去的元素，说明刚才队列是空的。现在队列里有了一个任务，那么就"),a("strong",[t._v("应该唤醒所有在等待的消费者线程，避免了方案2的缺点")]),t._v("。将 leader 重置为null，这些消费者之间互相竞争，自然有一个会被选为leader。")]),t._v(" "),a("p",[a("strong",[t._v("2.线程leader的作用")])]),t._v(" "),a("p",[t._v("leader 这个成员有啥作用？DelayQueue的设计其实是一个Leader/Follower模式， leader 就是指向 Leader线程的。该模式可以减少不必要的等待时间，当一个线程是Leader时，它只需要一个时间差；其 他Follower线程则无限等待。比如头节点任务还有5秒就要开始了，那么Leader线程会sleep 5秒，不需要傻傻地等待固定时间间隔。")]),t._v(" "),a("p",[t._v("想象一下有个多个消费者线程用take方法去取任务,内部先加锁,然后每个线程都去peek头节点。如果 leader不为空说明已经有线程在取了，让当前消费者无限等待。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("await")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("如果为空说明没有其他消费者去取任务,设置leader为当前消费者，并让改消费者等待指定的时间，")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),t._v(" thisThread "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("currentThread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" thisThread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("awaitNanos")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" thisThread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n             leader "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("下次循环会走如下分支，取到任务结束，")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delay "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n")])])]),a("p",[a("strong",[t._v("3. take()方法中为什么释放first")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[t._v("first "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// don't retain ref while waiting")]),t._v("\n")])])]),a("p",[t._v("我们可以看到 Doug Lea 后面写的注释，那么这行代码有什么用呢？ 如果删除这行代码，会发生什么呢？假设现在有3个消费者线程，")]),t._v(" "),a("ul",[a("li",[t._v("线程A进来获取first,然后进入 else 的 else ,设置了leader为当前线程A，并让A等待一段时间")]),t._v(" "),a("li",[t._v("线程B进来获取first, 进入else的阻塞操作,然后无限期等待，这时线程B是持有first引用的")]),t._v(" "),a("li",[t._v("线程A等待指定时间后被唤醒，获取对象成功，出队，这个对象理应被GC回收，但是它还被线程B持有着，GC链可达，所以不能回收这个first")]),t._v(" "),a("li",[t._v("只要线程B无限期的睡眠，那么这个本该被回收的对象就不能被GC销毁掉，那么就会造成内存泄露")])]),t._v(" "),a("p",[a("strong",[t._v("Task对象")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delayed")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concurrent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TimeUnit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delayed")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" startTime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// milliseconds")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" delay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startTime "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("currentTimeMillis")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" delay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDelay")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TimeUnit")]),t._v(" unit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),t._v(" diff "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" startTime "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("currentTimeMillis")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" unit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("convert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("diff"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TimeUnit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MILLISECONDS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compareTo")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Delayed")]),t._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startTime "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startTime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"task "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" at "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" startTime"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),a("p",[t._v("JDK中有一个接口 java.util.concurrent.Delayed ，可以用于表示具有过期时间的元素，刚好可以拿 来表示任务这个概念。")]),t._v(" "),a("p",[t._v("生产者")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskProducer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Runnable")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Random")]),t._v(" random "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Random")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskProducer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("q "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" delay "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("nextInt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),t._v(" task "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UUID"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("randomUUID")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" delay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Put "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sleep")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("InterruptedException")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("printStackTrace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("生产者很简单，就是一个死循环，不断地产生一些是时间随机的任务。")]),t._v(" "),a("p",[t._v("消费者")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskConsumer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Runnable")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskConsumer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("q "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),t._v(" task "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("take")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Take "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("InterruptedException")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("printStackTrace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("当 DelayQueue 里没有任务时， TaskConsumer 会无限等待，直到被唤醒，因此它不会消耗CPU。")]),t._v(" "),a("p",[t._v("定时任务调度器")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskScheduler")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Task")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" queue "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DelayQueue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskProducer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Producer Thread"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("start")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Thread")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TaskConsumer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Consumer Thread"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("start")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),a("p",[a("code",[t._v("DelayQueue")]),t._v("这个方案，每个消费者线程只需要等待所需要的时间差，因此响应速度更快。它内部用了 一个优先队列，所以插入和删除的时间复杂度都是logn。")]),t._v(" "),a("p",[t._v("JDK里还有一个"),a("code",[t._v("ScheduledThreadPoolExecutor")]),t._v("，原理跟"),a("code",[t._v("DelayQueue")]),t._v("类似，封装的更完善，平时工作中可以用它，不过面试中，还是拿"),a("code",[t._v("DelayQueue")]),t._v("来讲吧，它封装得比较薄，容易讲清楚原理。")]),t._v(" "),a("h5",{attrs:{id:"方案4-时间轮-hashedwheeltimer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案4-时间轮-hashedwheeltimer"}},[t._v("#")]),t._v(" "),a("strong",[t._v("方案4: 时间轮(HashedWheelTimer)")])]),t._v(" "),a("p",[t._v("时间轮(HashedWheelTimer)其实很简单，就是一个循环队列，如下图所示，")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072125288.png",alt:"image-20220507212508021"}})]),t._v(" "),a("p",[t._v("上图是一个长度为8的循环队列，假设该时间轮精度为秒，即每秒走一格，像手表那样，走完一圈就是8 秒。每个格子指向一个任务集合，时间轮无限循环，每转到一个格子，就扫描该格子下面的所有任务， 把时间到期的任务取出来执行。")]),t._v(" "),a("p",[t._v("举个例子，假设指针当前正指向格子0，来了一个任务需要4秒后执行，那么这个任务就会放在格子4下 面，如果来了一个任务需要20秒后执行怎么？由于这个循环队列转一圈只需要8秒，这个任务需要多转2 圈，所以这个任务的位置虽然依旧在格子4(20%8+0=4)下面，不过需要多转2圈后才执行。因此每个任务 需要有一个字段记录需圈数，每转一圈就减1，减到0则立刻取出来执行。")]),t._v(" "),a("p",[t._v("怎么实现时间轮呢？Netty中已经有了一个时间轮的实现, HashedWheelTimer.java，可以参考它的源代 码。")]),t._v(" "),a("p",[t._v("时间轮的优点是性能高，插入和删除的时间复杂度都是O(1)。Linux 内核中的定时器采用的就是这个方 案。")]),t._v(" "),a("p",[a("strong",[t._v("Follow up: 如何设计一个分布式的定时任务调度器呢？ 答: Redis ZSet, RabbitMQ等")])]),t._v(" "),a("h3",{attrs:{id:"最近一个小时内访问频率最高的10个ip"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#最近一个小时内访问频率最高的10个ip"}},[t._v("#")]),t._v(" 最近一个小时内访问频率最高的10个IP")]),t._v(" "),a("p",[t._v("实时输出最近一个小时内访问频率最高的10个IP，要求：")]),t._v(" "),a("ul",[a("li",[t._v("实时输出")]),t._v(" "),a("li",[t._v("从当前时间向前数的1个小时")]),t._v(" "),a("li",[t._v("QPS可能会达到10W/s")])]),t._v(" "),a("p",[t._v("这道题乍一看很像Top K 频繁项，是不是需要 Lossy Count 或 Count-Min Sketch 之类的算法呢？")]),t._v(" "),a("p",[t._v("其实杀鸡焉用牛刀，这道题用不着上述算法，请听我仔细分析。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072127448.png",alt:"image-20220507212718717"}})]),t._v(" "),a("p",[t._v('有的人问，可不可以用"IP + 时间"作为key, 把所有pair放在单个HashMap里？如果把所有数据放在一个 HashMap里，有两个巨大的缺点，')]),t._v(" "),a("ul",[a("li",[t._v("第4步里，怎么淘汰掉一个小时前的pair呢？这时候后台线程只能每隔一秒，全量扫描这个 HashMap里的所有pair,把过期数据删除，这是线性时间复杂度，很慢。")]),t._v(" "),a("li",[t._v('这时候HashMap里的key存放的是"IP + 时间"组合成的字符串，占用内存远远大于一个int。而前面 的方案，不用存真正的时间，只需要开一个3600长度的数组来表示一个小时时间窗口。')])]),t._v(" "),a("h3",{attrs:{id:"key-value存储引擎"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-value存储引擎"}},[t._v("#")]),t._v(" key-Value存储引擎")]),t._v(" "),a("p",[t._v("请设计一个Key-Value存储引擎(Design a key-value store)。")]),t._v(" "),a("p",[t._v("这是一道频繁出现的题目，个人认为也是一道很好的题目，这题纵深非常深，内行的人可以讲的非常深。")]),t._v(" "),a("p",[t._v("首先讲两个术语，数据库和存储引擎。数据库往往是一个比较丰富完整的系统, 提供了SQL查询语言，事务和水平扩展等支持。然而存储引擎则是小而精, 纯粹专注于单机的读/写/存储。一般来说, 数据库底层 往往会使用某种存储引擎。")]),t._v(" "),a("p",[t._v("目前开源的KV存储引擎中，RocksDB是流行的一个，MongoDB和MySQL底层可以切换成RocksDB， TiDB底层直接使用了RocksDB。大多数分布式数据库的底层不约而同的都选择了RocksDB。")]),t._v(" "),a("p",[t._v("RocksDB最初是从LevelDB进化而来的，我们先从简单一点的LevelDB入手，借鉴它的设计思路。")]),t._v(" "),a("p",[t._v("LevelDB整体结构")]),t._v(" "),a("p",[t._v("有一个反直觉的事情是，"),a("strong",[t._v("内存随机写甚至比硬盘的顺序读还要慢")]),t._v("，磁盘随机写就更慢了，说明我们要避 免随机写，最好设计成顺序写。因此好的KV存储引擎，都在尽量避免更新操作，把更新和删除操作转化 为顺序写操作。LevelDB采用了一种SSTable的数据结构来达到这个目的。")]),t._v(" "),a("p",[t._v("SSTable(Sorted String Table)就是一组按照key排序好的 key-value对, key和value都是字节数组。 SSTable既可以在内存中，也可以在硬盘中。SSTable底层使用LSM Tree(Log-Structured Merge Tree) 来存放有序的key-value对。")]),t._v(" "),a("p",[t._v("LevelDB整体由如下几个组成部分")]),t._v(" "),a("ol",[a("li",[t._v("MemTable。即内存中的SSTable，新数据会写入到这里，然后批量写入磁盘，以此提高写的吞吐量。")]),t._v(" "),a("li",[t._v("Log文件。写MemTable前会写Log文件，即用WAL(Write Ahead Log)方式记录日志，如果机器突 然掉电，内存中的MemTable丢失了，还可以通过日志恢复数据。WAL日志是很多传统数据库例如 MySQL采用的技术，详细解释可以参考数据库如何用 WAL 保证事务一致性？ - 知乎专栏。")]),t._v(" "),a("li",[t._v(".Immutable MemTable。内存中的MemTable达到指定的大小后，将不再接收新数据，同时会有新 的MemTable产生，新数据写入到这个新的MemTable里，Immutable MemTable随后会写入硬 盘，变成一个SST文件。")]),t._v(" "),a("li",[t._v("SSTable 文件。即硬盘上的SSTable，文件尾部追加了一块索引，记录key->offset，提高随机读的 效率。SST文件为Level 0到Level N多层，每一层包含多个SST文件；单个SST文件容量随层次增加 成倍增长；Level0的SST文件由Immutable MemTable直接Dump产生，其他Level的SST文件由其 上一层的文件和本层文件归并产生。")]),t._v(" "),a("li",[t._v("Manifest文件。 Manifest文件中记录SST文件在不同Level的分布，单个SST文件的最大最小key， 以及其他一些LevelDB需要的元信息。")]),t._v(" "),a("li",[t._v("Current文件。从上面的介绍可以看出，LevelDB启动时的首要任务就是找到当前的Manifest，而 Manifest可能有多个。Current文件简单的记录了当前Manifest的文件名。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072129759.png",alt:"image-20220507212945499"}})]),t._v(" "),a("p",[t._v("LevelDB的一些核心逻辑如下，")]),t._v(" "),a("ol",[a("li",[t._v("首先SST文件尾部的索引要放在内存中，这样读索引就不需要一次磁盘IO了")]),t._v(" "),a("li",[t._v("所有读要先查看 MemTable ，如果没有再查看内存中的索引")]),t._v(" "),a("li",[t._v("所有写操作只能写到 MemTable , 因为SST文件不可修改")]),t._v(" "),a("li",[t._v("定期把 Immutable MemTable 写入硬盘，成为 SSTable 文件，同时新建一个 MemTable 会继 续接收新来的写操作")]),t._v(" "),a("li",[t._v("定期对 SSTable 文件进行合并")]),t._v(" "),a("li",[t._v("由于硬盘上的 SSTable 文件是不可修改的，那怎么更新和删除数据呢？对于更新操作，追加 一个新的key-value对到文件尾部，由于读 SSTable 文件是从前向后读的，所以新数据会最先被读到；对于删除操作，追加“墓碑”值(tombstone)，表示删除该key，在定期合并 SSTable 文件时丢弃这些key, 即可删除这些key")])]),t._v(" "),a("p",[a("strong",[t._v("Manifest文件")])]),t._v(" "),a("p",[t._v("Manifest文件记录各个SSTable各个文件的管理信息，比如该SST文件处于哪个Level，文件名称叫 啥，最小key和最大key各自是多少，如下图所示")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072131015.png",alt:"image-20220507213107745"}})]),t._v(" "),a("p",[a("strong",[t._v("Log文件")])]),t._v(" "),a("p",[t._v("Log文件主要作用是系统发生故障时，能够保证不会丢失数据。因为在数据写入内存中的 MemTable之前，会先写入Log文件，这样即使系统发生故障，MemTable中的数据没有来得及 Dump到磁盘，LevelDB也可以根据log文件恢复内存中的MemTable，不会造成系统丢失数据。这 个方式就叫做 WAL(Write Ahead Log)，很多传统数据库例如MySQL也使用了WAL技术来记录日志。")]),t._v(" "),a("p",[t._v("每个Log文件由多个block组成，每个block大小为32K，读取和写入以block为基本单位。下图所示的Log文件包含3个Block")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072131851.png",alt:"image-20220507213151602"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072132827.png",alt:"image-20220507213200525"}})]),t._v(" "),a("p",[t._v("MemTable 是内存中的数据结构，存储的内容跟硬盘上的SSTable一样，只是格式不一样。 Immutable MemTable的内存结构和Memtable是完全一样的，区别仅仅在于它是只读的，而 MemTable则是允许写入和读取的。当MemTable写入的数据占用内存到达指定大小，则自动转换 为Immutable Memtable，等待Dump到磁盘中，系统会自动生成一个新的MemTable供写操作写 入新数据，理解了MemTable，那么Immutable MemTable自然不在话下。")]),t._v(" "),a("p",[t._v("MemTable里的数据是按照key有序的，因此当插入新数据时，需要把这个key-value对插入到合适 的位置上，以保持key有序性。MemTable底层的核心数据结构是一个跳表(Skip List)。跳表是红黑 树的一种替代数据结构，具有更高的写入速度，而且实现起来更加简单，请参考跳表(Skip List)。")]),t._v(" "),a("p",[t._v("前面我们介绍了LevelDB的一些内存数据结构和文件，这里开始介绍一些动态操作，例如读取，写入，更新和删除数据，分层合并，错误恢复等操作。")]),t._v(" "),a("p",[t._v("添加、更新和删除数据")]),t._v(" "),a("p",[t._v("LevelDB写入新数据时，具体分为两个步骤：")]),t._v(" "),a("ol",[a("li",[t._v("将这个操作顺序追加到log文件末尾。尽管这是一个磁盘操作，但是文件的顺序写入效率还是跟高的，所以不会降低写入的速度")]),t._v(" "),a("li",[t._v("如果log文件写入成功，那么将这条key-value记录插入到内存中MemTable。")])]),t._v(" "),a("p",[t._v("LevelDB更新一条记录时，并不会本地修改SST文件，而是会作为一条新数据写入MemTable，随后会写入SST文件，在SST文件合并过程中，新数据会处于文件尾部，而读取操作是从文件尾部倒着 开始读的，所以新值一定会最先被读到。")]),t._v(" "),a("p",[t._v("LevelDB删除一条记录时，也不会修改SST文件，而是用一个特殊值(墓碑值，tombstone)作为 value，将这个key-value对追加到SST文件尾部，在SST文件合并过程中，这种值的key都会被忽略掉。")]),t._v(" "),a("p",[t._v("核心思想就是把写操作转换为顺序追加，从而提高了写的效率。")]),t._v(" "),a("p",[a("strong",[t._v("读取数据")])]),t._v(" "),a("p",[t._v("读操作使用了如下几个手段进行优化：")]),t._v(" "),a("ul",[a("li",[t._v("MemTable + SkipList")]),t._v(" "),a("li",[t._v("Binary Search(通过 manifest 文件)")]),t._v(" "),a("li",[t._v("页缓存")]),t._v(" "),a("li",[t._v("bloom filter")]),t._v(" "),a("li",[t._v("周期性分层合并")])]),t._v(" "),a("h3",{attrs:{id:"top-k频繁项"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#top-k频繁项"}},[t._v("#")]),t._v(" Top k频繁项")]),t._v(" "),a("p",[t._v("寻找数据流中出现最频繁的k个元素(find top k frequent items in a data stream)。这个问题也称为 Heavy Hitters.")]),t._v(" "),a("p",[t._v("这题也是从实践中提炼而来的，例如搜索引擎的热搜榜，找出访问网站次数最多的前10个IP地址，等等。")]),t._v(" "),a("h5",{attrs:{id:"方案1-hashmap-heap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案1-hashmap-heap"}},[t._v("#")]),t._v(" 方案1: HashMap + Heap")]),t._v(" "),a("p",[t._v("用一个 HashMap ，存放所有元素出现的次数，用一个小根堆，容量为k，存放目前出 现过的最频繁的k个元素，")]),t._v(" "),a("ol",[a("li",[t._v("每次从数据流来一个元素，如果在HashMap里已存在，则把对应的计数器增1，如果不存在，则插入，计数器初始化为1")]),t._v(" "),a("li",[t._v("在堆里查找该元素，如果找到，把堆里的计数器也增1，并调整堆；如果没有找到，把这个元素的 次数跟堆顶元素比较，如果大于堆丁元素的出现次数，则把堆丁元素替换为该元素，并调整堆")]),t._v(" "),a("li",[t._v("空间复杂度 O(n) 。HashMap需要存放下所有元素，需要 O(n) 的空间，堆需要存放k个元素，需 要 O(k) 的空间，跟 O(n) 相比可以忽略不急，总的时间复杂度是 O(n)")]),t._v(" "),a("li",[t._v("时间复杂度 O(n) 。每次来一个新元素，需要在HashMap里查找一下，需要 O(1) 的时间；然后要 在堆里查找一下， O(k) 的时间，有可能需要调堆，又需要 O(logk) 的时间，总的时间复杂度是 O(n(k+logk)) ，k是常量，所以可以看做是O(n)。")])]),t._v(" "),a("p",[t._v("如果元素数量巨大，单机内存存不下，怎么办？ 有两个办法，见方案2和3。")]),t._v(" "),a("h5",{attrs:{id:"方案2-多机hashmap-heap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案2-多机hashmap-heap"}},[t._v("#")]),t._v(" 方案2: 多机HashMap + Heap")]),t._v(" "),a("ul",[a("li",[t._v("可以把数据进行分片。假设有8台机器，第1台机器只处理 hash(elem)%8 == 0 的元素，第2台机器 只处理 hash(elem)%8==1 的元素，以此类推。")]),t._v(" "),a("li",[t._v("每台机器都有一个HashMap和一个 Heap, 各自独立计算出 top k 的元素")]),t._v(" "),a("li",[t._v("把每台机器的Heap，通过网络汇总到一台机器上，将多个Heap合并成一个Heap，就可以计算出 总的 top k 个元素了")])]),t._v(" "),a("h5",{attrs:{id:"方案3-count-min-sketch-heap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案3-count-min-sketch-heap"}},[t._v("#")]),t._v(" 方案3: Count-Min Sketch + Heap")]),t._v(" "),a("p",[t._v("既然方案1中的HashMap太大，内存装不小，那么可以用Count-Min Sketch算法代替HashMap，")]),t._v(" "),a("ul",[a("li",[t._v("在数据流不断流入的过程中，维护一个标准的Count-Min Sketch 二维数组")]),t._v(" "),a("li",[t._v("维护一个小根堆，容量为k")]),t._v(" "),a("li",[t._v("每次来一个新元素，\n"),a("ul",[a("li",[t._v("将相应的sketch增1")]),t._v(" "),a("li",[t._v("在堆中查找该元素，如果找到，把堆里的计数器也增1，并调整堆；如果没有找到，把这个元 素的sketch作为钙元素的频率的近似值，跟堆顶元素比较，如果大于堆丁元素的频率，则把堆顶元素替换为该元素，并调整堆")])])])]),t._v(" "),a("p",[t._v("这个方法的时间复杂度和空间复杂度如下：")]),t._v(" "),a("ul",[a("li",[t._v("空间复杂度 O(dm) 。m是二维数组的列数，d是二维数组的行数，堆需要 O(k) 的空间，不过k通常很小，堆的空间可以忽略不计")]),t._v(" "),a("li",[t._v("时间复杂度 O(nlogk) 。每次来一个新元素，需要在二维数组里查找一下，需要 O(1) 的时间；然 后要在堆里查找一下， O(logk) 的时间，有可能需要调堆，又需要 O(logk) 的时间，总的时间复杂度是 O(nlogk) 。")])]),t._v(" "),a("h5",{attrs:{id:"方案4-lossy-counting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方案4-lossy-counting"}},[t._v("#")]),t._v(" 方案4: Lossy Counting")]),t._v(" "),a("p",[t._v("Lossy Couting 算法流程：")]),t._v(" "),a("ul",[a("li",[t._v("建立一个HashMap，用于存放每个元素的出现次数")]),t._v(" "),a("li",[t._v("建立一个窗口（窗口的大小由错误率决定，后面具体讨论）")]),t._v(" "),a("li",[t._v("等待数据流不断流进这个窗口，直到窗口满了，开始统计每个元素出现的频率，统计结束后，每个元素的频率减1，然后将出现次数为0的元素从HashMap中删除")]),t._v(" "),a("li",[t._v("返回第2步，不断循环")])]),t._v(" "),a("p",[t._v("Lossy Counting 背后朴素的思想是，出现频率高的元素，不太可能减一后变成0，如果某个元素在某个 窗口内降到了0，说明它不太可能是高频元素，可以不再跟踪它的计数器了。随着处理的窗口越来越多， HashMap也会不断增长，同时HashMap里的低频元素会被清理出去，这样内存占用会保持在一个很低的水平。")]),t._v(" "),a("p",[t._v("很显然，Lossy Counting 算法是个近似算法，但它的错误率是可以在数学上证明它的边界的。假设要求 错误率不大于ε，那么窗口大小为1/ε，对于长度为N的流，有N／（1/ε）＝εN 个窗口，由于每个窗口结 束时减一了，那么频率最多被少计数了窗口个数εN。")]),t._v(" "),a("p",[t._v("该算法只需要一遍扫描，所以时间复杂度是 O(n) 。")]),t._v(" "),a("p",[t._v("该算法的内存占用，主要在于那个HashMap, Gurmeet Singh Manku 在他的论文里，证明了HashMap 里最多有 1/ε log (εN) 个元素，所以空间复杂度是 O(1/ε log (εN)) 。")]),t._v(" "),a("h3",{attrs:{id:"网站大文件上传"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#网站大文件上传"}},[t._v("#")]),t._v(" 网站大文件上传")]),t._v(" "),a("p",[t._v("如果你的项目涉及到文件上传的话，面试官很可能会问你这个问题。")]),t._v(" "),a("p",[t._v("我们先看第一个场景："),a("strong",[t._v("大文件上传中途，突然失败！")])]),t._v(" "),a("p",[t._v("试想一个，你想上传一个 5g 的视频，上传进度到 99% 的时候，特么的，突然网络断了，这个时候，你发现自己竟然需要重新上传。我就问你抓狂不？")]),t._v(" "),a("p",[a("strong",[t._v("有没有解决办法呢？")]),t._v(" 答案就是："),a("strong",[t._v("分片上传！")])]),t._v(" "),a("p",[a("strong",[t._v("什么是分片上传呢？")]),t._v(" 简单来说，我们只需要先将文件切分成多个文件分片（就像我下面绘制的图片所展示的那样），然后再上传这些小的文件分片。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/0d9f29f1023e9c9688dbe7d7df97fc12.png",alt:"img"}})]),t._v(" "),a("p",[t._v("前端发送了所有文件分片之后，服务端再将这些文件分片进行合并即可。")]),t._v(" "),a("p",[t._v("使用分片上传主要有下面 2 点好处：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("断点续传")]),t._v(" ：上传文件中途暂停或失败（比如遇到网络问题）之后，不需要重新上传，只需要上传哪些未成功上传的文件分片即可。所以，分片上传是断点续传的基础。")]),t._v(" "),a("li",[a("strong",[t._v("多线程上传")]),t._v(" ：我们可以通过多线程同时对一个文件的多个文件分片进行上传，这样的话就大大加快的文件上传的速度。")])]),t._v(" "),a("p",[a("strong",[t._v("前端怎么生成文件分片呢？后端如何合并文件分片呢？")])]),t._v(" "),a("p",[t._v("前端可以通过 "),a("strong",[a("code",[t._v("Blob.slice()")])]),t._v(" 方法来对文件进行切割（"),a("code",[t._v("File")]),t._v(" 对象是继承 "),a("code",[t._v("Blob")]),t._v(" 对象的，因此 "),a("code",[t._v("File")]),t._v(" 对象也有 "),a("code",[t._v("slice()")]),t._v(" 方法）。")]),t._v(" "),a("p",[t._v("生成文件切片的示例代码如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/7ddfd1d732eb7605f6ca0ebff34dc5f6.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[a("code",[t._v("RandomAccessFile")])]),t._v(" 类可以帮助我们合并文件分片，示例代码如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/fdda9509919179ad9f3ca9b62314613f.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[t._v("何为秒传？")])]),t._v(" "),a("p",[t._v("秒传说的就是我们在上传某个文件的时候，首先根据文件的唯一标识判断一下服务端是否已经上传过该文件，如果上传过的话，直接就返回给用户文件上传成功即可。")]),t._v(" "),a("p",[t._v("一般情况下，这个唯一标识都是通过对文件的名称、最后修改时间等信息取 MD5 值得到的，这个可以通过使用 "),a("code",[t._v("spark-md5")]),t._v(" 这个库来生成。")]),t._v(" "),a("p",[t._v("需要注意的是：你不能根据文件名就决定文件是否已经上传到服务端，因为很可能存在文件名相同，但是，内容不同的情况。另外，体验更好的是文件内容不变，唯一标识就不应该改变。因此，我们可以根据文件的内容来计算 MD5 值。")]),t._v(" "),a("p",[t._v("另外，还存在一种情况是我们要上传的文件已经上传了部分文件切片到服务端。这个时候，我们直接返回已上传的切片列表给前端即可。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/345e31afd324594ccba9623ceca3fefb.png",alt:"img"}})]),t._v(" "),a("p",[t._v("然后，前端再将剩余未上传的分片上传到服务端。")]),t._v(" "),a("p",[t._v("我简单画了一张图描述一下断点续传和秒传。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/72c617e781eae3a378dfec9d32b6b4f8.png",alt:"img"}})]),t._v(" "),a("h3",{attrs:{id:"如何设计微博-feed-流-信息流系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何设计微博-feed-流-信息流系统"}},[t._v("#")]),t._v(" 如何设计微博 Feed 流/信息流系统")]),t._v(" "),a("p",[t._v("“如何设计微博 Feed 流/信息流系统？ ”是一道比较常见的系统设计问题，面试中比较常见。")]),t._v(" "),a("p",[t._v("这篇文章简单谈谈我的看法。个人能力有限，有些地方大家可以结合自己的经验自行扩展！爱你们哦！")]),t._v(" "),a("p",[a("strong",[t._v("下面是正文！")])]),t._v(" "),a("p",[t._v("Feed 流是社交和资讯平台不可缺少的重要组成。TimeLine 时期，Feed 流推送的机制完全基于时间，比如朋友圈动态、几年前的微信订阅号就是这种机制。")]),t._v(" "),a("p",[t._v("现在的 Feed 流主要是基于智能化/个性化的推荐，简单来说，就是你喜欢什么我就给你推荐什么。这样的话，人们被推送的信息会极大地由自己的个人兴趣主导，你自己所处的信息世界就像桎梏于蚕茧一般的“茧房”中一样。这也就是“信息茧房”所表达的意思。")]),t._v(" "),a("h5",{attrs:{id:"feed-流基础"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#feed-流基础"}},[t._v("#")]),t._v(" Feed 流基础")]),t._v(" "),a("h5",{attrs:{id:"何为-feed-流？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#何为-feed-流？"}},[t._v("#")]),t._v(" 何为 Feed 流？")]),t._v(" "),a("p",[t._v("简单来说就是能够实时/智能推送信息的数据流。像咱们的朋友圈动态（timeline）、知乎的推荐（智能化推荐 ）、你订阅的 Up 主的动态（timeline）都属于 "),a("strong",[t._v("Feed 流")]),t._v("。")]),t._v(" "),a("h5",{attrs:{id:"几种常见的-feed-流形式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#几种常见的-feed-流形式"}},[t._v("#")]),t._v(" 几种常见的 Feed 流形式")]),t._v(" "),a("p",[t._v("我总结了 3 种常见的 Feed 流形式。")]),t._v(" "),a("h6",{attrs:{id:"纯智能推荐"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#纯智能推荐"}},[t._v("#")]),t._v(" 纯智能推荐")]),t._v(" "),a("p",[t._v("你看到的内容完全是基于你看过的内容而推荐的，比较典型的产品有头条首页推荐、知乎首页推荐。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/699d4f66cc0091c090671d0839a3c1c0.png",alt:"img"}})]),t._v(" "),a("p",[t._v("智能推荐需要依赖 "),a("strong",[t._v("推荐系统")]),t._v(" ，推荐质量的好坏和推荐算法有非常大的关系。")]),t._v(" "),a("p",[t._v("推荐系统的相关文献把它们分成三类："),a("strong",[t._v("协同过滤")]),t._v("（仅使用用户与商品的交互信息生成推荐）系统、"),a("strong",[t._v("基于内容")]),t._v("（利用用户偏好和／或商品偏好）的系统和 "),a("strong",[t._v("混合推荐模型")]),t._v("（使用交互信息、用户和商品的元数据）的系统。")]),t._v(" "),a("p",[t._v("另外，随着深度学习应用的爆发式发展，特别是在计算机视觉、自然语言处理和语音方面的进展，基于深度学习的推荐系统越来越引发大家的关注。循环神经网络（RNN）理论上能够有效地对用户偏好和物品属性的动态性进行建模，基于当前的趋势，预测未来的行为。")]),t._v(" "),a("h6",{attrs:{id:"纯-timeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#纯-timeline"}},[t._v("#")]),t._v(" 纯 Timeline")]),t._v(" "),a("p",[t._v("你看到的内容完全按照时间来排序，比较典型的产品有微信朋友圈、QQ 空间、微博关注者动态。")]),t._v(" "),a("p",[t._v("微信朋友圈：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/5001bab8a83890c875d107608623ab28.png",alt:"img"}})]),t._v(" "),a("p",[t._v("微博关注者动态：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/61dda8dd35201ed58c9220268f632a6b.png",alt:"img"}})]),t._v(" "),a("p",[t._v("纯 Timeline 这种方式实现起来最简单，直接按照时间排序就行了。")]),t._v(" "),a("p",[t._v("纯 Timeline 这种形式更适用于好友社交领域，用户关注更多的是人发出的内容，而不仅仅是内容。")]),t._v(" "),a("h6",{attrs:{id:"智能推荐-timeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#智能推荐-timeline"}},[t._v("#")]),t._v(" 智能推荐+Timeline")]),t._v(" "),a("p",[t._v("智能推荐+Timeline 这个也是目前我觉得比较好的一种方式，实现起来比较简单，同时又能一定程度地避免 “信息茧房” 的问题。")]),t._v(" "),a("h5",{attrs:{id:"设计-feed-流系统的注意事项"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#设计-feed-流系统的注意事项"}},[t._v("#")]),t._v(" 设计 Feed 流系统的注意事项")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("实时性")]),t._v(" ：你关注的人发了微博信息之后，信息需要在短时间之内出现在你的信息流中。")]),t._v(" "),a("li",[a("strong",[t._v("高并发")]),t._v(" ：信息流是微博的主体模块，是用户进入到微博之后最先看到的模块，因此它的并发请求量是最高的，可以达到每秒几十万次请求。")]),t._v(" "),a("li",[a("strong",[t._v("性能")]),t._v(" ： 信息流拉取性能直接影响用户的使用体验。微博信息流系统中需要聚合的数据非常多。聚合这么多的数据就需要查询多次缓存、数据库、计数器，而在每秒几十万次的请求下，如何保证在 100ms 之内完成这些查询操作，展示微博的信息流呢？这是微博信息流系统最复杂之处，也是技术上最大的挑战。")]),t._v(" "),a("li",[t._v("......")])]),t._v(" "),a("h5",{attrs:{id:"feed-流架构设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#feed-流架构设计"}},[t._v("#")]),t._v(" Feed 流架构设计")]),t._v(" "),a("p",[t._v("我们这里以 "),a("strong",[t._v("微博关注者动态")]),t._v(" 为例。")]),t._v(" "),a("h5",{attrs:{id:"feed-流的-3-种推送模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#feed-流的-3-种推送模式"}},[t._v("#")]),t._v(" Feed 流的 3 种推送模式")]),t._v(" "),a("h6",{attrs:{id:"推模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#推模式"}},[t._v("#")]),t._v(" 推模式")]),t._v(" "),a("p",[t._v("当一个用户发送一个动态（比如微博、视频）之后，主动将这个动态推送给其他相关用户（比如粉丝）。")]),t._v(" "),a("p",[t._v("推模式下，我们需要将这个动态插入到每位粉丝对应的 feed 表中，这个存储成本是比较高的。尤其是对于粉丝数量比较多的大 V 来说，每发一条动态，需要存储的数据量实在太大。")]),t._v(" "),a("p",[t._v("假如狗蛋，有 n 个粉丝 1、2 ~ n。那么，狗蛋发一条微博时，我们需要执行的 SQL 语句如下：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" outbox"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("userId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" create_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"goudan"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current_time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//写入用户狗蛋的发件箱")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" inbox"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("userId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" create_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current_time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//写入用户2的收件箱")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" inbox"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("userId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" create_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $feedId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current_time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//写入用户n的收件箱")]),t._v("\n")])])]),a("p",[t._v("当我们要查询用户 n 的信息流时，只需要执行下面这条 SQL 就可以了：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" feedId "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" inbox "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" userId "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("可以很明显的看出，推模式最大的问题就是写入数据库的操作太多。")]),t._v(" "),a("p",[t._v("正常情况下，一个微博用户的粉丝大概在 150 左右，挨个写入也还好。不过，微博大 V 的粉丝可能在几百万，几千万，如果挨个给每个写入一条数据的话，是肯定不能接受的！因此，推模式不适合关注者粉丝过多的场景。")]),t._v(" "),a("h6",{attrs:{id:"拉模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#拉模式"}},[t._v("#")]),t._v(" 拉模式")]),t._v(" "),a("p",[t._v("不同于推模式，拉模式下我们是自己主动去拉取动态（拉取你关注的人的动态），然后将这些动态根据相关指标（比如时间、热度）进行实时聚合。")]),t._v(" "),a("p",[t._v("拉模式存储成本虽然降低，但是查询和聚合这两个操作的成本会比较高。尤其是对于单个用户关注了很多人的情况来说，你需要定时获取他关注的所有人的动态然后再做聚合，这个成本可想而知。")]),t._v(" "),a("p",[t._v("另外，拉模式下的数据流的实时性要比推模式差的。")]),t._v(" "),a("h6",{attrs:{id:"推垃结合模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#推垃结合模式"}},[t._v("#")]),t._v(" 推垃结合模式")]),t._v(" "),a("p",[t._v("推拉结合的核心是针对微博大 V 和不活跃用户特殊处理。")]),t._v(" "),a("p",[t._v("首先，我们需要区分出系统哪些用户属于微博大 V（10w 粉丝以上？）。其次，我们需要根据登录行为来判断哪些用户属于不活跃用户。")]),t._v(" "),a("p",[t._v("有了这些数据之后，就好办了！当微博大 V 发送微博的时候，我们仅仅将这条微博写入到活跃用户，不活跃的用户自己去拉取。示意图如下（图片来自：《高并发系统设计 40 问》）：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/587f58dd2d32a59510706f9c8a031f4f.png",alt:"img"}})]),t._v(" "),a("p",[t._v("推拉结合非常适合用户粉丝数比较大的场景。")]),t._v(" "),a("h5",{attrs:{id:"存储"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#存储"}},[t._v("#")]),t._v(" 存储")]),t._v(" "),a("p",[t._v("我们的存储的数据量会比较大，所以，存储库必须要满足可以水平扩展。")]),t._v(" "),a("p",[t._v("一般情况，通用的存储方案就是 "),a("strong",[t._v("MySQL + Redis")]),t._v(" 。MySQL 永久保存数据， Redis 作为缓存提高热点数据的访问速度。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/5bb5862e85941141de073e6e08a4fce4.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[t._v("如果缓存的数据量太大怎么办?")]),t._v(" 我们可以考虑使用"),a("strong",[t._v("Redis Cluster")]),t._v("，也就是 Redis 集群。Redis Cluster 可以帮助我们解决 Redis 大数据量缓存的问题，并且，也方便我们进行横向拓展（增加 Redis 机器）。")]),t._v(" "),a("p",[t._v("为了提高系统的并发，我们可以考虑对数据进行 "),a("strong",[t._v("读写分离")]),t._v(" 和 "),a("strong",[t._v("分库分表")]),t._v(" 。")]),t._v(" "),a("p",[t._v("读写分离主要是为了将数据库的读和写操作分不到不同的数据库节点上。主服务器负责写，从服务器负责读。另外，一主一从或者一主多从都可以。读写分离可以大幅提高读性能，小幅提高写的性能。因此，读写分离更适合单机并发读请求比较多的场景。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/e1c8a28aa60ff84cac256d40d39e88c2.png",alt:"读写分离"}})]),t._v(" "),a("p",[t._v("读写分离")]),t._v(" "),a("p",[t._v("分库分表是为了解决由于库、表数据量过大，而导致数据库性能持续下降的问题。常见的分库分表工具有："),a("code",[t._v("sharding-jdbc")]),t._v("（当当）、"),a("code",[t._v("TSharding")]),t._v("（蘑菇街）、"),a("code",[t._v("MyCAT")]),t._v("（基于 Cobar）、"),a("code",[t._v("Cobar")]),t._v("（阿里巴巴）...。 推荐使用 "),a("code",[t._v("sharding-jdbc")]),t._v("。 因为，"),a("code",[t._v("sharding-jdbc")]),t._v(" 是一款轻量级 "),a("code",[t._v("Java")]),t._v(" 框架，以 "),a("code",[t._v("jar")]),t._v(" 包形式提供服务，不要我们做额外的运维工作，并且兼容性也很好。")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://time.geekbang.org/column/intro/100006601?code=i00Nq3pHUcUj04ZWy70NCRl%2FD2Lfj8GVzcGzZ3Wf5Ug%3D",target:"_blank",rel:"noopener noreferrer"}},[t._v("《从零开始学架构》"),a("OutboundLink")],1),t._v(" 中的有一张图片对于垂直拆分和水平拆分的描述还挺直观的。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/b2792b8ddbff47e85cc8f2279fecc73b.jpg",alt:"img"}})]),t._v(" "),a("p",[t._v("另外，如果觉得分库分表比较麻烦的话，可以考虑使用 "),a("a",{attrs:{href:"https://docs.pingcap.com/zh/tidb/stable",target:"_blank",rel:"noopener noreferrer"}},[t._v("TiDB"),a("OutboundLink")],1),t._v(" 这类分布式数据库。TiDB 是国内 PingCAP 团队开发的一个分布式 SQL 数据库。其灵感来自于 Google 的 F1, TiDB 支持包括传统 RDBMS 和 NoSQL 的特性，具备水平扩容或者缩容、金融级高可用。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/fb6fce08fb9a3fe06362a9aceab5420e.png",alt:"img"}})]),t._v(" "),a("h3",{attrs:{id:"如何设计一个排行榜"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何设计一个排行榜"}},[t._v("#")]),t._v(" 如何设计一个排行榜")]),t._v(" "),a("p",[t._v("排行榜到处可见，比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜等等。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/5ed1b5437d7213579e06b9bc1b2ff349.png",alt:"img"}})]),t._v(" "),a("p",[t._v("今天让我们从程序设计的角度，来看看如何设计一个排行榜！")]),t._v(" "),a("p",[t._v("我们先从最基础的实现方式来说起。")]),t._v(" "),a("h5",{attrs:{id:"mysql-的-order-by-关键字"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql-的-order-by-关键字"}},[t._v("#")]),t._v(" MySQL 的 ORDER BY 关键字")]),t._v(" "),a("p",[t._v("第一种要介绍的实现方式就是直接使用 MySQL 的 "),a("code",[t._v("ORDER BY")]),t._v(" 关键字。 "),a("code",[t._v("ORDER BY")]),t._v(" 关键字可以对查询出来的数据按照指定的字段进行排序。")]),t._v(" "),a("p",[t._v("我相信但凡是学过 MySQL 的人，一定都用过 "),a("code",[t._v("ORDER BY")]),t._v(" 关键字！没用过的，先不要看下面的文章了，麻烦默默反思 3 分钟。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" column1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" column2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_name\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ORDER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" column1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" column2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ASC")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DESC")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我之前在一个用户数据量不大（6w 用户左右）并且排序需求并不复杂的项目中使用的就是这种方法。")]),t._v(" "),a("p",[t._v("这种方式的优缺点也比较明显。"),a("strong",[t._v("好处是比较简单，不需要引入额外的组件，成本比较低。坏处就是每次生成排行榜都比较耗时，对数据库的性能消耗非常之大，数据量一大，业务场景稍微复杂一点就顶不住了。")])]),t._v(" "),a("p",[t._v("我们这里创建一个名为 "),a("code",[t._v("cus_order")]),t._v(" 的表，来实际测试一下这种排序方式。为了测试方便， "),a("code",[t._v("cus_order")]),t._v(" 这张表只有 "),a("code",[t._v("id")]),t._v("、"),a("code",[t._v("score")]),t._v("、"),a("code",[t._v("name")]),t._v("这 3 个字段。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("cus_order"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unsigned")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AUTO_INCREMENT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("InnoDB")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AUTO_INCREMENT")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100000")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CHARSET")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("utf8mb4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我们定义一个简单的存储过程（PROCEDURE）来插入 100w 测试数据。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DELIMITER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFINER")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("@`%`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PROCEDURE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("BatchinsertDataToCusOder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IN")]),t._v(" start_num "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IN")]),t._v(" max_num "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BEGIN")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DECLARE")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),t._v(" start_num"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHILE")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" max_num "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DO")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("cus_order"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("RAND"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CONCAT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'user'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHILE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DELIMITER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("存储过程定义完成之后，我们执行存储过程即可！")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CALL")]),t._v(" BatchinsertDataToCusOder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入100w+的随机数据")]),t._v("\n")])])]),a("p",[t._v("等待一会，100w 的测试数据就插入完成了！")]),t._v(" "),a("p",[t._v("为了能够对这 100w 数据按照 "),a("code",[t._v("score")]),t._v(" 进行排序，我们需要执行下面的 SQL 语句。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("cus_order"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ORDER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DESC")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#降序排序")]),t._v("\n")])])]),a("p",[t._v("为了能够查看这套 SQL 语句的执行时间，我们需要通过"),a("code",[t._v("show profiles")]),t._v("命令。")]),t._v(" "),a("p",[t._v("不过，请确保你的 "),a("code",[t._v("profiling")]),t._v(" 是开启（on）的状态（可以通过 "),a("code",[t._v("show variables")]),t._v(" 命令查看）。")]),t._v(" "),a("p",[t._v("默认情况下， "),a("code",[t._v("profiling")]),t._v(" 是关闭（off）的状态，你直接通过"),a("code",[t._v("set @@profiling=1")]),t._v("命令即可开启。")]),t._v(" "),a("p",[t._v("然后，我们就查询到了具体的执行速度。")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Query_ID"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Duration"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.63526325")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Query"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SELECT `score`,`name` FROM `cus_order` ORDER BY `score` DESC"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("可以看到，一共耗时了接近 4 s。")]),t._v(" "),a("p",[a("strong",[t._v("如何优化呢？")]),t._v(" "),a("strong",[t._v("加索引并且限制排序数据量")]),t._v(" 是一种比较常见的优化方式。")]),t._v(" "),a("p",[t._v("我们对 "),a("code",[t._v("score")]),t._v(" 字段加字段，并限制只排序 "),a("code",[t._v("score")]),t._v(" 排名前 500 的数据。")]),t._v(" "),a("p",[t._v("这个时候，我们再执行下面的 SQL 语句，速度就快了很多，只需要 0.01 秒就排序了前 500 名的数据。")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Query_ID"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("38")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Duration"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0102915")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"Query"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SELECT `score`,`name` FROM `cus_order` ORDER BY `score` DESC LIMIT 500"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("当然了，这只是一个最简单的场景，实际项目中的复杂度要比我这里列举的例子复杂很多，执行速度也会慢很多。")]),t._v(" "),a("p",[t._v("不过，"),a("strong",[t._v("能不用 MySQL 的 ORDER BY 关键字还是要看具体的业务场景。如果说你的项目需要排序数据量比较小并且业务场景不复杂的话（比如你对你博客的所有文章按照阅读量来排序），我觉得直接使用 MySQL 的 "),a("code",[t._v("ORDER BY")]),t._v(" 关键字就可以了。")])]),t._v(" "),a("h5",{attrs:{id:"redis-的-sorted-set"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redis-的-sorted-set"}},[t._v("#")]),t._v(" Redis 的 sorted set")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/061065c539360ede10c2b511934e72f1.png",alt:"img"}})]),t._v(" "),a("p",[t._v("了解过 Redis 常见数据结构的小伙伴，都知道 Redis 中有一个叫做 "),a("code",[t._v("sorted set")]),t._v(" 的数据结构经常被用在各种排行榜的场景下。")]),t._v(" "),a("p",[t._v("通过 "),a("code",[t._v("sorted set")]),t._v(" ，我们能够轻松应对百万级别的用户数据排序。这简直就是专门为排行榜设计的数据结构啊！")]),t._v(" "),a("p",[t._v("Redis 中 "),a("code",[t._v("sorted set")]),t._v(" 有点类似于 Java 中的 "),a("code",[t._v("TreeSet")]),t._v(" 和 "),a("code",[t._v("HashMap")]),t._v(" 的结合体，"),a("code",[t._v("sorted set")]),t._v(" 中的数据会按照权重参数 "),a("code",[t._v("score")]),t._v(" 的值进行排序。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("ZADD key "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("NX"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("XX"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("GT"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("LT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("CH"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("INCR"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" score member "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("score member "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("User")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("Score")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user1")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("112.0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("100.0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user3")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("123.0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user4")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("100.0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user5")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("33.0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("user6")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("993.0")])])])]),t._v(" "),a("p",[t._v("我们这里简单来演示一下。我们把上表中的数据添加到"),a("code",[t._v("sorted set")]),t._v("中。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 通过 zadd 命令添加了 6 个元素到 cus_order_set 中")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD cus_order_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("112.0")]),t._v(" user1 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),t._v(" user2 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("123.0")]),t._v(" user3 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),t._v(" user4 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33.0")]),t._v(" user5 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("993.0")]),t._v(" user6\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/76f52695316b92b44cdce03c4e030009.png",alt:"img"}})]),t._v(" "),a("p",[a("code",[t._v("sorted set")]),t._v(" 基本可以满足大部分排行榜的场景。")]),t._v(" "),a("p",[a("strong",[t._v("如果我们要查看包含所有用户的排行榜怎么办？")]),t._v(" 通过 "),a("code",[t._v("ZRANGE")]),t._v(" (从小到大排序) / "),a("code",[t._v("ZREVRANGE")]),t._v(" （从大到小排序）")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -1 代表的是全部的用户数据，")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZREVRANGE cus_order_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" -1\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user6"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user3"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user4"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user2"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user5"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("如果我们要查看只包含前 3 名的排行榜怎么办？")]),t._v(" 限定范围区间即可。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0 为 start  2 为 stop")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZREVRANGE cus_order_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user6"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user3"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("如果我们需要查询某个用户的分数怎么办呢？")]),t._v(" 通过 "),a("code",[t._v("ZSCORE")]),t._v(" 命令即可。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZSCORE  cus_order_set "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"112"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("如果我们需要查询某个用户的排名怎么办呢？")]),t._v(" 通过 "),a("code",[t._v("ZREVRANK")]),t._v(" 命令即可。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZREVRANK  cus_order_set "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user3"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# user3 排名第2")]),t._v("\n")])])]),a("p",[a("strong",[t._v("如何对用户的排名数据进行更新呢？")]),t._v(" 通过 "),a("code",[t._v("ZINCRBY")]),t._v("命令即可。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对 user1 的分数加2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZINCRBY cus_order_set +2 "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"114"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对 user1 的分数减1")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZINCRBY cus_order_set -1 "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"113"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查看 user1 的分数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZSCORE  cus_order_set "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"113"')]),t._v("\n")])])]),a("p",[t._v("除了我上面提到的之外，还有一些其他的命令来帮助你解决更多排行榜场景的需求，想要深入研究的小伙伴可以仔细学习哦！")]),t._v(" "),a("p",[t._v("不过，需要注意的一点是："),a("strong",[t._v("Redis 中只保存了排行榜展示所需的数据，用户的具体相信数据的话，还是需要去对应的数据库（比如 MySQL）中查。")])]),t._v(" "),a("p",[a("strong",[t._v("你以为这样就完事了？")]),t._v(" 不存在的！还有一些无法仅仅通过 Redis 提供的命令解决的场景。")]),t._v(" "),a("p",[t._v("比如，"),a("strong",[t._v("如何实现多条件排序？")]),t._v(" 其实，答案也比较简单，对于大部分场景，我们直接对 "),a("code",[t._v("score")]),t._v(" 值做文章即可。")]),t._v(" "),a("p",[t._v("更具体点的话就是，我们根据特定的条件来拼接 "),a("code",[t._v("score")]),t._v(" 值即可。比如我们还要加上时间先后条件的话，直接在"),a("code",[t._v("score")]),t._v(" 值添加上时间戳即可。")]),t._v(" "),a("p",[t._v("再比如，"),a("strong",[t._v("如何实现指定日期（比如最近 7 天）的用户数据排序？")])]),t._v(" "),a("p",[t._v("我说一种比较简单的方法：我们把每一天的数据都按照日期为名字，比如 20350305 就代表 2035 年 3 月 5 号。")]),t._v(" "),a("p",[t._v("如果我们需要查询最近 n 天的排行榜数据的话，直接 "),a("code",[t._v("ZUNIONSTORE")]),t._v("来求 n 个 "),a("code",[t._v("sorted set")]),t._v(" 的并集即可。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("ZUNIONSTORE last_n_days n "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350305")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350306")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v("\n")])])]),a("p",[t._v("我不知道大家看懂了没有，我这里还是简单地造一些数据模拟一下吧！")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分别添加了 3 天的数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350305")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("112.0")]),t._v(" user1 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),t._v(" user2 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("123.0")]),t._v(" user3\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350306")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),t._v(" user4\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350307")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33.0")]),t._v(" user5 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("993.0")]),t._v(" user6\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),a("p",[t._v("通过 "),a("code",[t._v("ZUNIONSTORE")]),t._v(" 命令来查看最近 3 天的排行榜情况：")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZUNIONSTORE last_n_days "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350305")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350306")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20350307")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\n")])])]),a("p",[t._v("现在，这 3 天的数据都集中在了 "),a("code",[t._v("last_n_days")]),t._v(" 中。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZREVRANGE last_n_days "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" -1\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user6"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user3"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user4"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user2"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user5"')]),t._v("\n")])])]),a("p",[t._v("如果一个用户同时在多个 "),a("code",[t._v("sorted set")]),t._v(" 中的话，它最终的 "),a("code",[t._v("score")]),t._v(" 值就等于这些 "),a("code",[t._v("sorted set")]),t._v(" 中该用户的 "),a("code",[t._v("score")]),t._v(" 值之和。")]),t._v(" "),a("p",[t._v("既然可以求并集，那必然也可以求交集。你可以通过 "),a("code",[t._v("ZINTERSTORE")]),t._v(" 命令来求多个 n 个 "),a("code",[t._v("sorted set")]),t._v(" 的交集。")]),t._v(" "),a("p",[a("strong",[t._v("有哪些场景可以用到多个"),a("code",[t._v("sorted set")]),t._v(" 的交集呢？")]),t._v(" 比如每日打卡的场景，你对某一段时间每天打卡的人进行排序。")]),t._v(" "),a("p",[t._v("这个命令还有一个常用的权重参数 "),a("code",[t._v("weights")]),t._v(" （默认为 1）。在进行并集/交集的过程中，每个集合中的元素会将自己的 "),a("code",[t._v("score")]),t._v(" *"),a("code",[t._v("weights")]),t._v(" 。")]),t._v(" "),a("p",[t._v("我下面演示一下这个参数的作用。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# staff_set 存放员工的排名信息")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD staff_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),t._v(" staff1 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.0")]),t._v(" staff2\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# staff_set 存放管理者的排名信息")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZADD manager_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v(" manager1 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v(" manager2\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),a("p",[t._v("如果，我们需要将员工和管理者放在一起比较，不过，两者权重分别为 1 和 3。")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# staff_set 的权重为1 manager_set的权重为3")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZUNIONSTORE all_user_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" staff_set manager_set WEIGHTS "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n")])])]),a("p",[t._v("最终排序的结果如下：")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("127.0")]),t._v(".0.1:637"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("9")]),t._v(">")]),t._v(" ZREVRANGE all_user_set "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" -1\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"manager2"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"staff2"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"staff1"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"manager1"')]),t._v("\n")])])]),a("h5",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("p",[t._v("上面我一共提到了两种设计排行榜的方法：")]),t._v(" "),a("ol",[a("li",[t._v("MySQL 的 ORDER BY 关键字")]),t._v(" "),a("li",[t._v("Redis 的 sorted set")])]),t._v(" "),a("p",[t._v("其实，这两种没有孰好孰坏，还是要看具体的业务场景。如果说你的项目需要排序数据量比较小并且业务场景不复杂的话（比如你对你博客的所有文章按照阅读量来排序），我觉得直接使用 MySQL 的 "),a("code",[t._v("ORDER BY")]),t._v(" 关键字就可以了，没必要为了排行榜引入一个 Redis。")]),t._v(" "),a("p",[t._v("另外，"),a("strong",[t._v("在没有分页并且数据量不大的情况下，直接在前端拿到所有需要用到的数据之后再进行排序也是可以的。")])]),t._v(" "),a("h2",{attrs:{id:""}},[a("a",{staticClass:"header-anchor",attrs:{href:"#"}},[t._v("#")])])])}),[],!1,null,null,null);s.default=e.exports}}]);