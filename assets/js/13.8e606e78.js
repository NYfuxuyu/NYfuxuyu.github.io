(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{494:function(t,a,s){"use strict";s.r(a);var n=s(4),v=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("blockquote",[s("p",[t._v("海量数据题")])]),t._v(" "),s("h2",{attrs:{id:"基础知识"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基础知识"}},[t._v("#")]),t._v(" 基础知识")]),t._v(" "),s("ul",[s("li",[t._v("bit：位")]),t._v(" "),s("li",[t._v("byte：字节")]),t._v(" "),s("li",[t._v("1 byte= 8 bit")]),t._v(" "),s("li",[t._v("int 类型为 4 byte，共32位bit，unsigned int也是")]),t._v(" "),s("li",[t._v("2^32 byte = 4G")]),t._v(" "),s("li",[t._v("1G= 2^30 =10.7亿")])]),t._v(" "),s("h2",{attrs:{id:"布隆过滤器"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#布隆过滤器"}},[t._v("#")]),t._v(" 布隆过滤器")]),t._v(" "),s("h3",{attrs:{id:"什么是布隆过滤器"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#什么是布隆过滤器"}},[t._v("#")]),t._v(" "),s("strong",[t._v("什么是布隆过滤器")])]),t._v(" "),s("p",[t._v("本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 "),s("strong",[t._v("“某样东西一定不存在或者可能存在”")]),t._v("。")]),t._v(" "),s("p",[t._v("相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。")]),t._v(" "),s("h3",{attrs:{id:"实现原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实现原理"}},[t._v("#")]),t._v(" "),s("strong",[t._v("实现原理")])]),t._v(" "),s("p",[s("strong",[t._v("HashMap 的问题")])]),t._v(" "),s("p",[t._v("讲述布隆过滤器的原理之前，我们先思考一下，通常你判断某个元素是否存在用的是什么？应该蛮多人回答 HashMap 吧，确实可以将值映射到 HashMap 的 Key，然后可以在 O(1) 的时间复杂度内返回结果，效率奇高。但是 HashMap 的实现也有缺点，例如存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了。")]),t._v(" "),s("p",[s("strong",[t._v("布隆过滤器数据结构")])]),t._v(" "),s("p",[t._v("布隆过滤器是一个 bit 向量或者说 bit 数组，长这样：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072006974.png",alt:"image-20220329094822545"}})]),t._v(" "),s("p",[t._v("如果我们要映射一个值到布隆过滤器中，我们需要使用"),s("strong",[t._v("多个不同的哈希函数")]),t._v("生成**多个哈希值，**并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7，则上图转变为：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072006020.png",alt:"image-20220329094904881"}})]),t._v(" "),s("p",[t._v("Ok，我们现在再存一个值 “tencent”，如果哈希函数返回 3、4、8 的话，图继续变为：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072006066.png",alt:"image-20220329095013756"}})]),t._v(" "),s("p",[t._v("值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。现在我们如果想查询 “dianping” 这个值是否存在，哈希函数返回了 1、5、8三个值，结果我们发现 5 这个 bit 位上的值为 0，"),s("strong",[t._v("说明没有任何一个值映射到这个 bit 位上")]),t._v("，因此我们可以很确定地说 “dianping” 这个值不存在。而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “baidu” "),s("strong",[t._v("存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。")])]),t._v(" "),s("p",[t._v("这是为什么呢？答案跟简单，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 “taobao” 即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断 “taobao” 这个值存在。")]),t._v(" "),s("h3",{attrs:{id:"支持删除么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#支持删除么"}},[t._v("#")]),t._v(" 支持删除么")]),t._v(" "),s("p",[t._v("感谢评论区提醒，传统的布隆过滤器并不支持删除操作。但是名为 Counting Bloom filter 的变种可以用来测试元素计数个数是否绝对小于某个阈值，它支持元素删除。可以参考文章 "),s("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//cloud.tencent.com/developer/article/1136056",target:"_blank",rel:"noopener noreferrer"}},[t._v("Counting Bloom Filter 的原理和实现"),s("OutboundLink")],1)]),t._v(" "),s("h3",{attrs:{id:"如何选择哈希函数个数和布隆过滤器长度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何选择哈希函数个数和布隆过滤器长度"}},[t._v("#")]),t._v(" "),s("strong",[t._v("如何选择哈希函数个数和布隆过滤器长度")])]),t._v(" "),s("p",[t._v("很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。")]),t._v(" "),s("p",[t._v("另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072006049.jpeg",alt:"img"}}),t._v("k 为哈希函数个数，m m为布隆过滤器长度，n 为插入的元素个数，p 为误报率")]),t._v(" "),s("p",[t._v("如何选择适合业务的 k 和 m 值呢，这里直接贴一个公式：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072006947.jpeg",alt:"img"}})]),t._v(" "),s("h3",{attrs:{id:"最佳实践"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#最佳实践"}},[t._v("#")]),t._v(" "),s("strong",[t._v("最佳实践")])]),t._v(" "),s("p",[t._v("常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。")]),t._v(" "),s("p",[t._v("另外，既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。")]),t._v(" "),s("p",[s("strong",[t._v("大Value拆分")])]),t._v(" "),s("p",[t._v("Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。")]),t._v(" "),s("p",[t._v("拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。")]),t._v(" "),s("h3",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("ul",[s("li",[t._v("适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集")]),t._v(" "),s("li",[t._v("基本原理及要点：对于原理来说很简单，位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。")]),t._v(" "),s("li",[t._v("扩展：Bloom filter将集合中的元素映射到位数组中，用k（k为哈希函数个数）个映射位是否全1表示元素在不在这个集合中。Counting bloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用counter中的最小值来近似表示元素的出现频率。")]),t._v(" "),s("li",[t._v("使用工具：Bloom Filter；hash函数")])]),t._v(" "),s("p",[t._v("作者：LifelongCode\n链接：https://www.nowcoder.com/discuss/808568?channel=-1&source_id=profile_follow_post_nctrack\n来源：牛客网")]),t._v(" "),s("h2",{attrs:{id:"_1-分而治之-hash映射-hashmap统计-快速-归并-堆排序"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-分而治之-hash映射-hashmap统计-快速-归并-堆排序"}},[t._v("#")]),t._v(" "),s("strong",[t._v("1.分而治之/hash映射 + hashmap统计 + 快速/归并/堆"),s("a",{attrs:{href:""}},[t._v("排序")])])]),t._v(" "),s("p",[t._v("这种方法是典型的“分而治之”的策略，是解决空间限制最常用的方法，即"),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("不能一次性读入内存，而我们需要对"),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("进行的计数、"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("等操作。基本思路如下图所示：先借助哈希"),s("a",{attrs:{href:""}},[t._v("算法")]),t._v("，计算每一条数据的 hash 值，按照 hash 值将"),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("分布存储到多个桶中。根据 hash 函数的唯一性，相同的数据一定在同一个桶中。如此，我们再依次处理这些小文件，最后做合并运算即可")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205072014173.png",alt:"img"}})]),t._v(" "),s("h3",{attrs:{id:"问题1：海量日志数据，统计出某日访问百度次数最多的那个ip"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题1：海量日志数据，统计出某日访问百度次数最多的那个ip"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题1：海量日志数据，统计出某日访问"),s("a",{attrs:{href:""}},[t._v("百度")]),t._v("次数最多的那个IP")])]),t._v(" "),s("p",[t._v("解决方式：IP地址最多有 2^32 = 4G 种取值情况，所以不能完全加载到内存中进行处理，采用 hash分解+ 分而治之 + 归并 方式：")]),t._v(" "),s("p",[t._v("（1）按照 IP 地址的 Hash(IP)%1024 值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；")]),t._v(" "),s("p",[t._v("（2）对于每一个小文件，构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址")]),t._v(" "),s("p",[t._v("（3）然后再在这1024组最大的IP中，找出那个频率最大的IP")]),t._v(" "),s("h3",{attrs:{id:"问题2：有一个1g大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1m。返回频数最高的100个词。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题2：有一个1g大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1m。返回频数最高的100个词。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题2：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。")])]),t._v(" "),s("p",[t._v("解决思想： hash分解+ 分而治之 + 归并")]),t._v(" "),s("p",[t._v("（1）顺序读文件中，对于每个词x，按照 hash(x)/(1024*4) 存到4096个小文件中。这样每个文件大概是250k左右。如果其中的有的文件超过了1M大小，还可以按照hash继续往下分，直到分解得到的小文件的大小都不超过1M。")]),t._v(" "),s("p",[t._v("（2）对每个小文件，可以采用 trie树/hashmap 统计每个文件中出现的词以及相应的频率，并使用 100个节点的小顶堆取出出现频率最大的100个词，并把100个词及相应的频率存入文件。这样又得到了4096个文件。")]),t._v(" "),s("p",[t._v("（3）下一步就是把这4096个文件进行归并的过程了")]),t._v(" "),s("h3",{attrs:{id:"问题3：有a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4g，让你找出a、b文件共同的url？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题3：有a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4g，让你找出a、b文件共同的url？"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题3：有a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案1： hash 分解+ 分而治之 + 归并 的方式：")])]),t._v(" "),s("p",[t._v("如果内存中想要存入所有的 url，共需要 50亿 * 64= 320G大小空间，所以采用 hash 分解+ 分而治之 + 归并 的方式：")]),t._v(" "),s("p",[t._v("（1）遍历文件a，对每个 url 根据某种hash规则，求取hash(url)/1024，然后根据所取得的值将 url 分别存储到1024个小文件（a0~a1023）中。这样每个小文件的大约为300M。如果hash结果很集中使得某个文件ai过大，可以在对ai进行二级hash(ai0~ai1024)，这样 url 就被hash到 1024 个不同级别的文件中。")]),t._v(" "),s("p",[t._v("（2）分别比较文件，a0 VS b0，…… ，a1023 VS b1023，求每对小文件中相同的url时：把其中一个小文件的 url 存储到 hashmap 中，然后遍历另一个小文件的每个url，看其是否在刚才构建的 hashmap 中，如果是，那么就是共同的url，存到文件中。")]),t._v(" "),s("p",[t._v("（3）把1024个文件中的相同 url 合并起来")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案2：Bloom filter")])]),t._v(" "),s("p",[t._v("如果允许有一定的错误率，可以使用 Bloom filter，4G内存大概可以表示 340 亿bit，n = 50亿，如果按照出错率0.01算需要的大概是650亿个bit，现在可用的是340亿，相差并不多，这样可能会使出错率上升些，将其中一个文件中的 url 使用 Bloom filter 映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）")]),t._v(" "),s("h3",{attrs:{id:"问题4：有10个文件，每个文件1g，每个文件的每一行存放的都是用户的-query，每个文件的query都可能重复。要求你按照query的频度排序。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题4：有10个文件，每个文件1g，每个文件的每一行存放的都是用户的-query，每个文件的query都可能重复。要求你按照query的频度排序。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题4：有10个文件，每个文件1G，每个文件的每一行存放的都是用户的 query，每个文件的query都可能重复。要求你按照query的频度"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("。")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案1：hash分解+ 分而治之 +归并")])]),t._v(" "),s("p",[t._v("（1）顺序读取10个文件 a0~a9，按照 hash(query)%10 的结果将 query 写入到另外10个文件（记为 b0~b9）中，这样新生成的文件每个的大小大约也1G")]),t._v(" "),s("p",[t._v("（2）找一台内存2G左右的机器，依次使用 hashmap(query, query_count) 来统计每个 query 出现的次数。利用 快速/堆/归并"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v(" 按照出现次数进行"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("。将"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件c0~c9。")]),t._v(" "),s("p",[t._v("（3）对这10个文件 c0~c9 进行归并"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("（内"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("与外"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("相结合）。每次取 c0~c9 文件的 m 个数据放到内存中，进行 10m 个数据的归并，即使把归并好的数据存到 d结果文件中。如果 ci 对应的m个数据全归并完了，再从 ci 余下的数据中取m个数据重新加载到内存中。直到所有ci文件的所有数据全部归并完成。")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案2：Trie树")])]),t._v(" "),s("p",[t._v("如果query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。在这种情况下，可以采用 trie树/hashmap 等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("就可以了。")]),t._v(" "),s("h3",{attrs:{id:"问题5：海量数据分布在100台电脑中，请高效统计出这批数据的top10"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题5：海量数据分布在100台电脑中，请高效统计出这批数据的top10"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题5："),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("分布在100台电脑中，请高效统计出这批数据的TOP10")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决思想： 分而治之 + 归并")])]),t._v(" "),s("p",[t._v("（1）在每台电脑上求出TOP10，采用包含10个元素的堆完成（TOP10小，用最大堆，TOP10大，用最小堆）")]),t._v(" "),s("p",[t._v("（2）求出每台电脑上的TOP10后，把这100台电脑上的 TOP10 合并之后，共1000个数据，在采用堆"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("或者快排方式 求出 top10")]),t._v(" "),s("p",[t._v("（注意：该题的 TOP10 是取最大值或最小值，如果取频率TOP10，就应该先hash分解，将相同的数据移动到同一台电脑中，再使用hashmap分别统计出现的频率）")]),t._v(" "),s("h3",{attrs:{id:"问题6：在-2-5-亿个整数中找出不重复的整数，内存不足以容纳这2-5亿个整数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题6：在-2-5-亿个整数中找出不重复的整数，内存不足以容纳这2-5亿个整数"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题6：在 2.5 亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案1：hash 分解+ 分而治之 + 归并")])]),t._v(" "),s("p",[t._v("（1）2.5亿个 int 类型 hash 到1024个小文件中 a0~a1023，如果某个小文件大小还大于内存，进行多级hash")]),t._v(" "),s("p",[t._v("（2）将每个小文件读进内存，找出只出现一次的数据，输出到b0~b1023")]),t._v(" "),s("p",[t._v("（3）最后数据合并即可")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案2 ： 2-Bitmap")])]),t._v(" "),s("p",[t._v("如果内存够1GB的话，采用 2-Bitmap 进行统计，共需内存 2^32 * 2bit = 1GB内存。2-bitmap 中，每个数分配 2bit（00表示不存在，01表示出现一次，10表示多次，11无意义），然后扫描这 2.5 亿个整数，查看Bitmap中相对应位，如果是00，则将其置为01；如果是01，将其置为10；如果是10，则保持不变。所描完成后，查看bitmap，把对应位是01的整数输出即可。（如果是找出重复的数据，可以用1-bitmap。第一次bit位由0变1，第二次查询到相应bit位为1说明是重复数据，输出即可）")]),t._v(" "),s("h3",{attrs:{id:"问题7：使用2gb内存找到20亿个整数中出现最多的数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题7：使用2gb内存找到20亿个整数中出现最多的数"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题7：使用2GB内存找到20亿个整数中出现最多的数")])]),t._v(" "),s("p",[t._v("20亿个整数，假定32位=4B，也要8GB内存才能一次性处理（还只是读入内存），现在个人机内存也才差不多8GB，当然服务器肯定是可以处理的，采用哈希表，key=4B,value=4B(大概需要16GB内存，然后读入数字，查找统计数和词频，最后遍历找到最大的)。然，现在要求2GB内存找出出现最多的数，只能先利用hash函数进行分块，具体分块的数目由数据量和内存大小来定。比如目前2GB内存，按照极端情况来算，所有数据都不同，或者只有一个出现两次，需要8B"),s("em",[t._v("20亿=16GB=2GB")]),t._v("8,可以分为8块，或者16块。按照16快的分法，每个小文件大小会来到1GB，2GB的内存当然可以处理，每个小文件使用哈希表来统计词频，最后将16个文件中词频最大的16个数字再外排序一次，找到出现次数最多的那一个。")]),t._v(" "),s("h2",{attrs:{id:"_2-trie树-红黑树-hashmap"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-trie树-红黑树-hashmap"}},[t._v("#")]),t._v(" "),s("strong",[t._v("2. Trie树+"),s("a",{attrs:{href:""}},[t._v("红黑树")]),t._v("+hashmap")])]),t._v(" "),s("p",[t._v("Trie树、"),s("a",{attrs:{href:""}},[t._v("红黑树")]),t._v(" 和 hashmap 可以认为是第一部分中分而治之"),s("a",{attrs:{href:""}},[t._v("算法")]),t._v("的具体实现方法之一。")]),t._v(" "),s("p",[t._v("其中，Trie树适合处理海量字符串数据，尤其是大量的字符串数据中存在前缀时。Trie树在字典的存储，字符串的查找，求取海量字符串的公共前缀，以及字符串统计等方面发挥着重要的作用。")]),t._v(" "),s("ul",[s("li",[t._v("用于存储时，Trie树因为不重复存储公共前缀，节省了大量的存储空间；")]),t._v(" "),s("li",[t._v("用于以字符串的查找时，Trie树依靠其特殊的性质，实现了在任意数据量的字符串集合中都能以O(len)的时间复杂度完成查找（len为要检索的字符串长度）；")]),t._v(" "),s("li",[t._v("在字符串统计中，Trie树能够快速记录每个字符串出现的次数")])]),t._v(" "),s("h3",{attrs:{id:"问题1：上千万或上亿数据（有重复），统计其中出现次数最多的前n个数据。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题1：上千万或上亿数据（有重复），统计其中出现次数最多的前n个数据。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题1：上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案： hashmap/"),s("a",{attrs:{href:""}},[t._v("红黑树")]),t._v(" + 堆"),s("a",{attrs:{href:""}},[t._v("排序")])])]),t._v(" "),s("p",[t._v("（1）如果是上千万或上亿的 int 数据，现在的机器4G内存能存下。所以考虑采用 hashmap/搜索"),s("a",{attrs:{href:""}},[t._v("二叉树")]),t._v("/"),s("a",{attrs:{href:""}},[t._v("红黑树")]),t._v(" 等来进行统计重复次数")]),t._v(" "),s("p",[t._v("（2）然后使用包含 N 个元素的小顶堆找出频率最大的N个数据")]),t._v(" "),s("h3",{attrs:{id:"问题2：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，并给出时间复杂度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题2：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，并给出时间复杂度"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题2：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，并给出时间复杂度")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决思路： trie树 + 堆"),s("a",{attrs:{href:""}},[t._v("排序")])])]),t._v(" "),s("p",[t._v("用 trie树 统计每个词出现的次数，时间复杂度是O(n*len)（len表示单词的平均长度）。")]),t._v(" "),s("p",[t._v("然后使用小顶堆找出出现最频繁的前10个词，时间复杂度是O(n*lg10)。")]),t._v(" "),s("p",[t._v("总的时间复杂度，是O(n"),s("em",[t._v("len)与O(n")]),t._v("lg10)中较大的那一个。")]),t._v(" "),s("h3",{attrs:{id:"问题3：有一千万个字符串记录（这些字符串的重复率比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个），每个查询串的长度为1-255字节。请你统计最热门的10个查询串（重复度越高，说明越热门），要求使用的内存不能超过1g。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题3：有一千万个字符串记录（这些字符串的重复率比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个），每个查询串的长度为1-255字节。请你统计最热门的10个查询串（重复度越高，说明越热门），要求使用的内存不能超过1g。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题3：有一千万个字符串记录（这些字符串的重复率比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个），每个查询串的长度为1-255字节。请你统计最热门的10个查询串（重复度越高，说明越热门），要求使用的内存不能超过1G。")])]),t._v(" "),s("p",[t._v("内存不能超过 1G，每条记录是 255byte，1000W 条记录需要要占据2.375G内存，这个条件就不满足要求了，但是去重后只有 300W 条记录，最多占用0.75G内存，因此可以将它们都存进内存中去。")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案1：Trie树")])]),t._v(" "),s("p",[t._v("使用 trie树（或者使用hashmap），关键字域存该查询串出现的次数。最后用10个元素的最小堆来对出现频率进行"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("。总的时间复杂度，是O(n"),s("em",[t._v("le)与O(n")]),t._v("lg10)中较大的那一个。")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案2：Hash")])]),t._v(" "),s("p",[t._v("第一步、先对这批"),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("预处理，在O（N）的时间内用Hash表完成统计；")]),t._v(" "),s("p",[t._v("第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘*logK；")]),t._v(" "),s("p",[t._v("即，借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比所以，我们最终的时间复杂度是：O（N） + N'*O（logK），（N为1000万，N’为300万）。")]),t._v(" "),s("h3",{attrs:{id:"问题4：1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题4：1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题4：1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案：trie树")])]),t._v(" "),s("h2",{attrs:{id:"_3-bitmap-与-bloom-filter："}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-bitmap-与-bloom-filter："}},[t._v("#")]),t._v(" "),s("strong",[t._v("3. BitMap 与 Bloom Filter：")])]),t._v(" "),s("p",[t._v("1、BitMap 就是通过 bit 位为 1 或 0 来标识某个状态存不存在。可用于数据的快速查找，判重，删除，一般来说适合的处理数据范围小于 8bit *2^32。否则内存超过4G，内存资源消耗有点多。")]),t._v(" "),s("p",[t._v("2、Bloom Filter 主要是用于判定目标数据是否存在于一个"),s("a",{attrs:{href:""}},[t._v("海量数据")]),t._v("集 以及 集合求交集。以存在性判定为例，Bloom Filter 通过对目标数据的映射，能够以 O(k) 的时间复杂度判定目标数据的存在性，其中k为使用的hash函数个数。这样就能大大缩减遍历查找所需的时间。")]),t._v(" "),s("h3",{attrs:{id:"问题1：已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题1：已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题1：已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。")])]),t._v(" "),s("p",[t._v("解决思路：")]),t._v(" "),s("p",[t._v("8位最多99 999 999，需要 100M个bit 位，不到12M的内存空间。我们把 0-99 999 999的每个数字映射到一个Bit位上，这样，就用了小小的12M左右的内存表示了所有的8位数的电话")]),t._v(" "),s("p",[t._v("思路分析")]),t._v(" "),s("p",[t._v("这类题目其实是求解数据重复的问题。对于这类问题，可以使用"),s("strong",[t._v("位图法")]),t._v("处理")]),t._v(" "),s("p",[t._v("8位电话号码可以表示的范围为00000000～99999999。如果用 bit表示一个号码，那么总共需要1亿个bit，总共需要大约"),s("strong",[t._v("10MB")]),t._v("的内存。")]),t._v(" "),s("p",[t._v("申请一个位图并初始化为0，然后遍历所有电话号码，"),s("strong",[t._v("把遍历到的电话号码对应的位图中的bit设置为1")]),t._v("。当遍历完成后，如果bit值为1，则表示这个电话号码在文件中存在，否则这个bit对应的电话号码在文件中不存在。")]),t._v(" "),s("p",[t._v("最后这个"),s("strong",[t._v("位图中bit值为1的数量")]),t._v("就是不同电话号码的个数了。")]),t._v(" "),s("p",[t._v("那么如何确定电话号码对应的是位图中的哪一位呢？")]),t._v(" "),s("p",[t._v("可以使用下面的方法来做"),s("strong",[t._v("电话号码和位图的映射")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("00000000 对应位图最后一位：0×0000…000001。\n00000001 对应位图倒数第二位：0×0000…0000010（1 向左移 "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" 位）。\n00000002 对应位图倒数第三位：0×0000…0000100（1 向左移 "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" 位）。\n……\n00000012 对应位图的倒数第十三位：0×0000…0001 0000 0000 0000（1 向左移 "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(" 位）。\n")])])]),s("p",[t._v("也就是说，电话号码就是1这个数字左移的次数。")]),t._v(" "),s("p",[t._v("具体实现")]),t._v(" "),s("p",[t._v("首先位图可以使用一个"),s("strong",[t._v("int数组")]),t._v("来实现（在Java中int占用"),s("strong",[t._v("4byte")]),t._v("）。")]),t._v(" "),s("p",[t._v("假设电话号码为 P，而通过电话号码获取位图中对应位置的方法为：")]),t._v(" "),s("p",[s("strong",[t._v("第一步")]),t._v("，因为int整数占用4*8=32bit，通过 "),s("strong",[t._v("P/32")]),t._v(" 就可以计算出该电话号码在 bitmap 数组中的下标，从而可以确定它对应的 bit 在数组中的位置。")]),t._v(" "),s("p",[s("strong",[t._v("第二步")]),t._v("，通过 "),s("strong",[t._v("P%32")]),t._v(" 就可以计算出这个电话号码在这个int数字中具体的bit的位置。只要把1向左移 "),s("strong",[t._v("P%32")]),t._v(" 位，然后把得到的值与这个数组中的值做或运算，就可以把这个电话号码在位图中对应的位设置为1。")]),t._v(" "),s("p",[t._v("以00000100号码为例。")]),t._v(" "),s("ol",[s("li",[t._v("首先计算数组下标，100 / 32 = 3，得到数组下标位3。")]),t._v(" "),s("li",[t._v("然后计算电话号码在这个int数字中具体的bit的位置，100 % 32 = 4。取余为0左移1位，故取余为4左移5位，得到000...000010000")]),t._v(" "),s("li",[t._v("将位图中对应的位设置为 1，即arr[2] = arr[2] "),s("strong",[t._v("|")]),t._v(" 000..00010000。")]),t._v(" "),s("li",[t._v("这就将电话号码映射到了位图的某一位了。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202204242132847.png",alt:"图片"}})]),t._v(" "),s("p",[t._v("最后，统计位图中bit值为1的数量，便能得到不同电话号码的个数了。")]),t._v(" "),s("h3",{attrs:{id:"问题2：2-5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2-5亿个整数。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题2：2-5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2-5亿个整数。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题2：2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。")])]),t._v(" "),s("p",[t._v("解决方案：使用 2-bitmap，详情见上文")]),t._v(" "),s("h3",{attrs:{id:"问题3：给40亿个不重复的-unsigned-int-的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题3：给40亿个不重复的-unsigned-int-的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题3：给40亿个不重复的 unsigned int 的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中")])]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案1：Bitmap")])]),t._v(" "),s("p",[t._v("使用 Bitmap，申请 512M 的内存，一个bit位代表一个 unsigned int 值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。")]),t._v(" "),s("blockquote",[s("p",[t._v("解决方案2：位图方法")])]),t._v(" "),s("p",[t._v("又因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；")]),t._v(" "),s("p",[t._v("Step1：这里把40亿个数中的每一个用32位的二进制来表示，假设这40亿个数开始放在一个文件中。")]),t._v(" "),s("p",[t._v("Step2：然后将这40亿个数分成两类:")]),t._v(" "),s("p",[t._v("1.最高位为0")]),t._v(" "),s("p",[t._v("2.最高位为1")]),t._v(" "),s("p",[t._v("Step3：并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找")]),t._v(" "),s("p",[t._v("Step4：再然后把这个文件为又分成两类:")]),t._v(" "),s("p",[t._v("1.次最高位为0")]),t._v(" "),s("p",[t._v("2.次最高位为1")]),t._v(" "),s("p",[t._v("Step5：并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；与要查找的数的次最高位比较并接着进入相应的文件再查找。")]),t._v(" "),s("p",[t._v(".......")]),t._v(" "),s("p",[t._v("以此类推，就可以找到了,而且时间复杂度为O(logn)，方案2完。")]),t._v(" "),s("p",[s("strong",[t._v("补充：")])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("使用位图法判断整形数组是否存在重复")]),t._v(" "),s("p",[t._v("判断集合中存在重复是常见编程任务之一，当集合中数据量比较大时我们通常希望少进行几次扫描，这时双重循环法就不可取了。")]),t._v(" "),s("p",[t._v("位图法比较适合于这种情况，它的做法是按照集合中最大元素max创建一个长度为max+1的新数组，然后再次扫描原数组，遇到几就给新数组的第几位置上1，如遇到5就给新数组的第六个元素置1，这样下次再遇到5想置位时发现新数组的第六个元素已经是1了，这说明这次的数据肯定和以前的数据存在着重复。这种给新数组初始化时置零其后置一的做法类似于位图的处理方法故称位图法。它的运算次数最坏的情况为2N。如果已知数组的最大值即能事先给新数组定长的话效率还能提高一倍。")])])]),t._v(" "),s("h3",{attrs:{id:"问题4：现有两个各有20亿行的文件，每一行都只有一个数字，求这两个文件的交集。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题4：现有两个各有20亿行的文件，每一行都只有一个数字，求这两个文件的交集。"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题4：现有两个各有20亿行的文件，每一行都只有一个数字，求这两个文件的交集。")])]),t._v(" "),s("p",[t._v("解决方案：采用 bitmap 进行问题解决，因为 int 的"),s("a",{attrs:{href:""}},[t._v("最大数")]),t._v("是 2^32 = 4G，用一个二进制的下标来表示一个 int 值，大概需要4G个bit位，即约4G/8 = 512M的内存，就可以解决问题了。")]),t._v(" "),s("p",[t._v("① 首先遍历文件，将每个文件按照数字的正数，负数标记到2个 bitmap 上，为：正数 bitmapA_positive，负数 bitmapA_negative")]),t._v(" "),s("p",[t._v("② 遍历另为一个文件，生成正数：bitmapB_positive，bitmapB_negative")]),t._v(" "),s("p",[t._v("③ 取 bitmapA_positive and bitmapB_positive 得到2个文件的正数的交集，同理得到负数的交集。")]),t._v(" "),s("p",[t._v("④ 合并，问题解决")]),t._v(" "),s("p",[t._v("这里一次只能解决全正数，或全负数，所以要分两次")]),t._v(" "),s("h3",{attrs:{id:"问题5：与上面的问题4类似，只不过现在不是a和b两个大文件，而是a-b-c-d…-多个大文件，求集合的交集"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题5：与上面的问题4类似，只不过现在不是a和b两个大文件，而是a-b-c-d…-多个大文件，求集合的交集"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题5：与上面的问题4类似，只不过现在不是A和B两个大文件，而是A, B, C, D….多个大文件，求集合的交集")])]),t._v(" "),s("p",[t._v("解决方案：")]),t._v(" "),s("p",[t._v("（1）依次遍历每个大文件中的每条数据，遍历每条数据时，都将它插入 Bloom Filter；")]),t._v(" "),s("p",[t._v("（2）如果已经存在，则在另外的集合（记为S）中记录下来；")]),t._v(" "),s("p",[t._v("（3）如果不存在，则插入Bloom Filter；")]),t._v(" "),s("p",[t._v("（4）最后，得到的S即为所有这些大文件中元素的交集")]),t._v(" "),s("h2",{attrs:{id:"_4-多层划分："}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-多层划分："}},[t._v("#")]),t._v(" "),s("strong",[t._v("4. 多层划分：")])]),t._v(" "),s("p",[t._v("多层划分本质上还是分而治之的思想，重在“分”的技巧上！因为元素范围很大，需要通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。适用用于：第k大，中位数，不重复或重复的数字")]),t._v(" "),s("h3",{attrs:{id:"问题1：求取海量整数的中位数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题1：求取海量整数的中位数"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题1：求取海量整数的中位数")])]),t._v(" "),s("p",[t._v("解决方案：")]),t._v(" "),s("ul",[s("li",[t._v("依次遍历整数，按照其大小将他们分拣到n个桶中。如果有的桶数据量很小，有的则数据量很大，大到内存放不下了；对于那些太大的桶，再分割成更小的桶；")]),t._v(" "),s("li",[t._v("之后根据桶数量的统计结果就可以判断中位数落到哪个桶中，如果该桶中还有子桶，就判断在其哪个子桶中，直到最后找出目标。")])]),t._v(" "),s("h3",{attrs:{id:"问题2：一共有n个机器，每个机器上有n个数，每个机器最多存-n-个数，如何找到-n-2-个数中的中数？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题2：一共有n个机器，每个机器上有n个数，每个机器最多存-n-个数，如何找到-n-2-个数中的中数？"}},[t._v("#")]),t._v(" "),s("strong",[t._v("问题2：一共有N个机器，每个机器上有N个数，每个机器最多存 N 个数，如何找到 N^2 个数中的中数？")])]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("解决方案1： hash分解 + "),s("a",{attrs:{href:""}},[t._v("排序")])])])]),t._v(" "),s("ul",[s("li",[t._v("按照升序顺序把这些数字，hash划分为N个范围段。假设数据范围是2^32 的unsigned int 类型。理论上第一台机器应该存的范围为0~(2^32)/N，第i台机器存的范围是(2^32)*(i-1)/N~(2^32)*i/N。hash过程可以扫描每个机器上的N个数，把属于第一个区段的数放到第一个机器上，属于第二个区段的数放到第二个机器上，…，属于第N个区段的数放到第N个机器上。注意这个过程每个机器上存储的数应该是O(N)的。")]),t._v(" "),s("li",[t._v("然后我们依次统计每个机器上数的个数，依次累加，直到找到第k个机器，在该机器上累加的数大于或等于（N^2）/2，而在第k-1个机器上的累加数小于（N^2）/2，并把这个数记为x。那么我们要找的中位数在第k个机器中，排在第（N^2）/2-x位。然后我们对第k个机器的数"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("，并找出第（N^2）/2-x个数，即为所求的中位数的复杂度是O（N^2）的。")])]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("解决方案2： 分而治之 + 归并")])])]),t._v(" "),s("p",[t._v("先对每台机器上的数进行"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("。排好序后，我们采用归并"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("的思想，将这N个机器上的数归并起来得到最终的"),s("a",{attrs:{href:""}},[t._v("排序")]),t._v("。找到第（N^2）/2个便是所求。复杂度是O（N^2 * lgN^2）；")]),t._v(" "),s("h2",{attrs:{id:"_10道最经典的海量数据题目"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10道最经典的海量数据题目"}},[t._v("#")]),t._v(" 10道最经典的海量数据题目")]),t._v(" "),s("h3",{attrs:{id:"如何从大量的-url-中找出相同的-url？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何从大量的-url-中找出相同的-url？"}},[t._v("#")]),t._v(" 如何从大量的 URL 中找出相同的 URL？")]),t._v(" "),s("p",[t._v("给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。")]),t._v(" "),s("p",[t._v("解答思路")]),t._v(" "),s("p",[s("strong",[t._v("1. 分治策略")])]),t._v(" "),s("p",[t._v("每个 URL 占 64B，那么 50 亿个 URL 占用的空间大小约为 320GB。")]),t._v(" "),s("blockquote",[s("p",[t._v("5, 000, 000, 000 _ 64B ≈ 5GB _ 64 = 320GB")])]),t._v(" "),s("p",[t._v("由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。对于这种类型的题目，一般采用"),s("strong",[t._v("分治策略")]),t._v("，即：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。")]),t._v(" "),s("p",[s("strong",[t._v("思路如下")]),t._v("：")]),t._v(" "),s("p",[t._v("首先遍历文件 a，对遍历到的 URL 求 "),s("code",[t._v("hash(URL) % 1000")]),t._v(" ，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, ..., a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, ..., b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, ..., a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。")]),t._v(" "),s("p",[t._v("接着遍历 ai( "),s("code",[t._v("i∈[0,999]")]),t._v(" )，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。")]),t._v(" "),s("p",[s("strong",[t._v("2. 前缀树")])]),t._v(" "),s("p",[t._v("一般而言，URL 的长度差距不会不大，而且前面几个字符，绝大部分相同。这种情况下，非常适合使用"),s("strong",[t._v("字典树")]),t._v("（trie tree） 这种数据结构来进行存储，降低存储成本的同时，提高查询效率。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[t._v("分治策略")]),t._v(" "),s("ol",[s("li",[t._v("分而治之，进行哈希取余；")]),t._v(" "),s("li",[t._v("对每个子文件进行 HashSet 统计。")])]),t._v(" "),s("p",[t._v("前缀树")]),t._v(" "),s("ol",[s("li",[t._v("利用字符串的公共前缀来降低存储成本，提高查询效率。")])]),t._v(" "),s("h3",{attrs:{id:"如何从大量数据中找出高频词？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何从大量数据中找出高频词？"}},[t._v("#")]),t._v(" 如何从大量数据中找出高频词？")]),t._v(" "),s("p",[t._v("有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("由于内存限制，我们依然无法直接将大文件的所有词一次读到内存中。因此，同样可以采用"),s("strong",[t._v("分治策略")]),t._v("，把一个大文件分解成多个小文件，保证每个文件的大小小于 1MB，进而直接将单个小文件读取到内存中进行处理。")]),t._v(" "),s("p",[s("strong",[t._v("思路如下")]),t._v("：")]),t._v(" "),s("p",[t._v("首先遍历大文件，对遍历到的每个词 x，执行 "),s("code",[t._v("hash(x) % 5000")]),t._v(" ，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。")]),t._v(" "),s("p",[t._v("接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 HashMap 来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 "),s("code",[t._v("map.put(x, 1)")]),t._v(" ；若存在，则执行 "),s("code",[t._v("map.put(x, map.get(x)+1)")]),t._v(" ，将该词频数加 1。")]),t._v(" "),s("p",[t._v("上面我们统计了每个小文件单词出现的频数。接下来，我们可以通过维护一个"),s("strong",[t._v("小顶堆")]),t._v("来找出所有词中出现频数最高的 100 个。具体方法是：依次遍历每个小文件，构建一个"),s("strong",[t._v("小顶堆")]),t._v("，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为"),s("strong",[t._v("小顶堆")]),t._v("，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("ol",[s("li",[t._v("分而治之，进行哈希取余；")]),t._v(" "),s("li",[t._v("使用 HashMap 统计频数；")]),t._v(" "),s("li",[t._v("求解"),s("strong",[t._v("最大")]),t._v("的 TopN 个，用"),s("strong",[t._v("小顶堆")]),t._v("；求解"),s("strong",[t._v("最小")]),t._v("的 TopN 个，用"),s("strong",[t._v("大顶堆")]),t._v("。")])]),t._v(" "),s("h3",{attrs:{id:"如何找出某一天访问百度网站最多的-ip？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何找出某一天访问百度网站最多的-ip？"}},[t._v("#")]),t._v(" 如何找出某一天访问百度网站最多的 IP？")]),t._v(" "),s("p",[t._v("现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("这道题只关心某一天访问百度最多的 IP，因此，可以首先对文件进行一次遍历，把这一天访问百度 IP 的相关信息记录到一个单独的大文件中。接下来采用的方法与上一题一样，大致就是先对 IP 进行哈希映射，接着使用 HashMap 统计重复 IP 的次数，最后计算出重复次数最多的 IP。")]),t._v(" "),s("blockquote",[s("p",[t._v("注：这里只需要找出出现次数最多的 IP，可以不必使用堆，直接用一个变量 max 即可。")])]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("ol",[s("li",[t._v("分而治之，进行哈希取余；")]),t._v(" "),s("li",[t._v("使用 HashMap 统计频数；")]),t._v(" "),s("li",[t._v("求解"),s("strong",[t._v("最大")]),t._v("的 TopN 个，用"),s("strong",[t._v("小顶堆")]),t._v("；求解"),s("strong",[t._v("最小")]),t._v("的 TopN 个，用"),s("strong",[t._v("大顶堆")]),t._v("。")])]),t._v(" "),s("h3",{attrs:{id:"在-2-5-亿个整数中找出不重复的整数。注意：内存不足以容纳这-2-5-亿个整数。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#在-2-5-亿个整数中找出不重复的整数。注意：内存不足以容纳这-2-5-亿个整数。"}},[t._v("#")]),t._v(" 在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。")]),t._v(" "),s("p",[t._v("在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("方法一：分治法")]),t._v(" "),s("p",[t._v("与前面的题目方法类似，先将 2.5 亿个数划分到多个小文件，用 HashSet/HashMap 找出每个小文件中不重复的整数，再合并每个子结果，即为最终结果。")]),t._v(" "),s("p",[t._v("方法二：位图法")]),t._v(" "),s("p",[s("strong",[t._v("位图")]),t._v("，就是用一个或多个 bit 来标记某个元素对应的值，而键就是该元素。采用位作为单位来存储数据，可以大大节省存储空间。")]),t._v(" "),s("p",[t._v("位图通过使用位数组来表示某些元素是否存在。它可以用于快速查找，判重，排序等。不是很清楚？我先举个小例子。")]),t._v(" "),s("p",[t._v("假设我们要对 "),s("code",[t._v("[0,7]")]),t._v(" 中的 5 个元素 (6, 4, 2, 1, 5) 进行排序，可以采用位图法。0~7 范围总共有 8 个数，只需要 8bit，即 1 个字节。首先将每个位都置 0：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("0 0 0 0 0 0 0 0\n")])])]),s("p",[t._v("然后遍历 5 个元素，首先遇到 6，那么将下标为 6 的位的 0 置为 1；接着遇到 4，把下标为 4 的位 的 0 置为 1：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("0 0 0 0 1 0 1 0\n")])])]),s("p",[t._v("依次遍历，结束后，位数组是这样的：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("0 1 1 0 1 1 1 0\n")])])]),s("p",[t._v("每个为 1 的位，它的下标都表示了一个数：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("for i in range(8):\n    if bits[i] == 1:\n        print(i)\n")])])]),s("p",[t._v("这样我们其实就已经实现了排序。")]),t._v(" "),s("p",[t._v("对于整数相关的算法的求解，"),s("strong",[t._v("位图法")]),t._v("是一种非常实用的算法。假设 int 整数占用 4B，即 32bit，那么我们可以表示的整数的个数为 232。")]),t._v(" "),s("p",[s("strong",[t._v("那么对于这道题")]),t._v("，我们用 2 个 bit 来表示各个数字的状态：")]),t._v(" "),s("ul",[s("li",[t._v("00 表示这个数字没出现过；")]),t._v(" "),s("li",[t._v("01 表示这个数字出现过一次（即为题目所找的不重复整数）；")]),t._v(" "),s("li",[t._v("10 表示这个数字出现了多次。")])]),t._v(" "),s("p",[t._v("那么这 232 个整数，总共所需内存为 232*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。假设内存满足位图法需求，进行下面的操作：")]),t._v(" "),s("p",[t._v("遍历 2.5 亿个整数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可。")]),t._v(" "),s("p",[t._v("当然，本题中特别说明："),s("strong",[t._v("内存不足以容纳这 2.5 亿个整数")]),t._v("，2.5 亿个整数的内存大小为：2.5e8/1024/1024/1024 * 4=3.72GB， 如果内存大于 1GB，是可以通过位图法解决的。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[s("strong",[t._v("判断数字是否重复的问题")]),t._v("，位图法是一种非常高效的方法，当然前提是：内存要满足位图法所需要的存储空间。")]),t._v(" "),s("h3",{attrs:{id:"如何在大量的数据中判断一个数是否存在？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何在大量的数据中判断一个数是否存在？"}},[t._v("#")]),t._v(" 如何在大量的数据中判断一个数是否存在？")]),t._v(" "),s("p",[t._v("给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("方法一：分治法")]),t._v(" "),s("p",[t._v("依然可以用分治法解决，方法与前面类似，就不再次赘述了。")]),t._v(" "),s("p",[t._v("方法二：位图法")]),t._v(" "),s("p",[t._v("由于 unsigned int 数字的范围是 "),s("code",[t._v("[0, 1 << 32)")]),t._v("，我们用 "),s("code",[t._v("1<<32=4,294,967,296")]),t._v(" 个 bit 来表示每个数字。初始位均为 0，那么总共需要内存：4,294,967,296b≈512M。")]),t._v(" "),s("p",[t._v("我们读取这 40 亿个整数，将对应的 bit 设置为 1。接着读取要查询的数，查看相应位是否为 1，如果为 1 表示存在，如果为 0 表示不存在。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[s("strong",[t._v("判断数字是否存在、判断数字是否重复的问题")]),t._v("，位图法是一种非常高效的方法。")]),t._v(" "),s("h3",{attrs:{id:"如何查询最热门的查询串？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何查询最热门的查询串？"}},[t._v("#")]),t._v(" 如何查询最热门的查询串？")]),t._v(" "),s("p",[t._v("搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。")]),t._v(" "),s("p",[t._v("假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("每个查询串最长为 255B，1000w 个串需要占用 约 2.55G 内存，因此，我们无法将所有字符串全部读入到内存中处理。")]),t._v(" "),s("p",[t._v("方法一：分治法")]),t._v(" "),s("p",[t._v("分治法依然是一个非常实用的方法。")]),t._v(" "),s("p",[t._v("划分为多个小文件，保证单个小文件中的字符串能被直接加载到内存中处理，然后求出每个文件中出现次数最多的 10 个字符串；最后通过一个小顶堆统计出所有文件中出现最多的 10 个字符串。")]),t._v(" "),s("p",[t._v("方法可行，但不是最好，下面介绍其他方法。")]),t._v(" "),s("p",[t._v("方法二：HashMap 法")]),t._v(" "),s("p",[t._v("虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个 HashMap 中，所占用的空间为 300w*(255+4)≈777M（其中，4 表示整数占用的 4 个字节）。由此可见，1G 的内存空间完全够用。")]),t._v(" "),s("p",[s("strong",[t._v("思路如下")]),t._v("：")]),t._v(" "),s("p",[t._v("首先，遍历字符串，若不在 map 中，直接存入 map，value 记为 1；若在 map 中，则把对应的 value 加 1，这一步时间复杂度 "),s("code",[t._v("O(N)")]),t._v(" 。")]),t._v(" "),s("p",[t._v("接着遍历 map，构建一个 10 个元素的小顶堆，若遍历到的字符串的出现次数大于堆顶字符串的出现次数，则进行替换，并将堆调整为小顶堆。")]),t._v(" "),s("p",[t._v("遍历结束后，堆中 10 个字符串就是出现次数最多的字符串。这一步时间复杂度 "),s("code",[t._v("O(Nlog10)")]),t._v(" 。")]),t._v(" "),s("p",[t._v("方法三：前缀树法")]),t._v(" "),s("p",[t._v("方法二使用了 HashMap 来统计次数，当这些字符串有大量相同前缀时，可以考虑使用前缀树来统计字符串出现的次数，树的结点保存字符串出现次数，0 表示没有出现。")]),t._v(" "),s("p",[s("strong",[t._v("思路如下")]),t._v("：")]),t._v(" "),s("p",[t._v("在遍历字符串时，在前缀树中查找，如果找到，则把结点中保存的字符串次数加 1，否则为这个字符串构建新结点，构建完成后把叶子结点中字符串的出现次数置为 1。")]),t._v(" "),s("p",[t._v("最后依然使用小顶堆来对字符串的出现次数进行排序。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[t._v("前缀树经常被用来统计字符串的出现次数。它的另外一个大的用途是字符串查找，判断是否有重复的字符串等。")]),t._v(" "),s("h3",{attrs:{id:"如何统计不同电话号码的个数？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何统计不同电话号码的个数？"}},[t._v("#")]),t._v(" 如何统计不同电话号码的个数？")]),t._v(" "),s("p",[t._v("已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("这道题本质还是求解"),s("strong",[t._v("数据重复")]),t._v("的问题，对于这类问题，一般首先考虑位图法。")]),t._v(" "),s("p",[t._v("对于本题，8 位电话号码可以表示的号码个数为 108 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 12M。")]),t._v(" "),s("p",[s("strong",[t._v("思路如下")]),t._v("：")]),t._v(" "),s("p",[t._v("申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[t._v("求解数据重复问题，记得考虑位图法。")]),t._v(" "),s("h3",{attrs:{id:"如何从-5-亿个数中找出中位数？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何从-5-亿个数中找出中位数？"}},[t._v("#")]),t._v(" 如何从 5 亿个数中找出中位数？")]),t._v(" "),s("p",[t._v("从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 "),s("code",[t._v("(N+1)/2")]),t._v(" 个数；当样本数为偶数时，中位数为 第 "),s("code",[t._v("N/2")]),t._v(" 个数与第 "),s("code",[t._v("1+N/2")]),t._v(" 个数的均值。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("如果这道题没有内存大小限制，则可以把所有数读到内存中排序后找出中位数。但是最好的排序算法的时间复杂度都为 "),s("code",[t._v("O(NlogN)")]),t._v(" 。这里使用其他方法。")]),t._v(" "),s("p",[t._v("方法一：双堆法")]),t._v(" "),s("p",[t._v("维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数"),s("strong",[t._v("小于等于")]),t._v("小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。")]),t._v(" "),s("p",[t._v("若数据总数为"),s("strong",[t._v("偶数")]),t._v("，当这两个堆建好之后，"),s("strong",[t._v("中位数就是这两个堆顶元素的平均值")]),t._v("。当数据总数为"),s("strong",[t._v("奇数")]),t._v("时，根据两个堆的大小，"),s("strong",[t._v("中位数一定在数据多的堆的堆顶")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("class MedianFinder {\n\n    private PriorityQueue<Integer> maxHeap;\n    private PriorityQueue<Integer> minHeap;\n\n    /** initialize your data structure here. */\n    public MedianFinder() {\n        maxHeap = new PriorityQueue<>(Comparator.reverseOrder());\n        minHeap = new PriorityQueue<>(Integer::compareTo);\n    }\n\n    public void addNum(int num) {\n        if (maxHeap.isEmpty() || maxHeap.peek() > num) {\n            maxHeap.offer(num);\n        } else {\n            minHeap.offer(num);\n        }\n\n        int size1 = maxHeap.size();\n        int size2 = minHeap.size();\n        if (size1 - size2 > 1) {\n            minHeap.offer(maxHeap.poll());\n        } else if (size2 - size1 > 1) {\n            maxHeap.offer(minHeap.poll());\n        }\n    }\n\n    public double findMedian() {\n        int size1 = maxHeap.size();\n        int size2 = minHeap.size();\n\n        return size1 == size2\n            ? (maxHeap.peek() + minHeap.peek()) * 1.0 / 2\n            : (size1 > size2 ? maxHeap.peek() : minHeap.peek());\n    }\n}\n")])])]),s("blockquote",[s("p",[t._v("见 LeetCode No.295："),s("a",{attrs:{href:"https://gitee.com/link?target=https%3A%2F%2Fleetcode.com%2Fproblems%2Ffind-median-from-data-stream%2F",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://leetcode.com/problems/find-median-from-data-stream/"),s("OutboundLink")],1)])]),t._v(" "),s("p",[t._v("以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法"),s("strong",[t._v("适用于数据量较小的情况")]),t._v("。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了，下面介绍另一种方法。")]),t._v(" "),s("p",[t._v("方法二：分治法")]),t._v(" "),s("p",[t._v("分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。")]),t._v(" "),s("p",[t._v("对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。")]),t._v(" "),s("p",[t._v("划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。")]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("提示")]),t._v("，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。")])]),t._v(" "),s("p",[t._v("对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。")]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("注意")]),t._v("，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。")])]),t._v(" "),s("p",[t._v("方法总结")]),t._v(" "),s("p",[t._v("分治法，真香！")]),t._v(" "),s("h3",{attrs:{id:"如何找出排名前-500-的数？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何找出排名前-500-的数？"}},[t._v("#")]),t._v(" 如何找出排名前 500 的数？")]),t._v(" "),s("p",[t._v("有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("对于 TopK 问题，最常用的方法是使用堆排序。对本题而言，假设数组降序排列，可以采用以下方法：")]),t._v(" "),s("p",[t._v("首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。")]),t._v(" "),s("p",[t._v("接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。")]),t._v(" "),s("p",[t._v("重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。")]),t._v(" "),s("blockquote",[s("p",[t._v("为了在堆中取出一个数据后，能知道它是从哪个数组中取出的，从而可以从这个数组中取下一个值，可以把数组的指针存放到堆中，对这个指针提供比较大小的方法。")])]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" lombok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Data")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Arrays")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * @author https://github.com/yanglbme\n */")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Data")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Comparable")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 数值\n     */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 记录数值来源的数组\n     */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     * 记录数值在数组中的索引\n     */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("source "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n     *\n     * 由于 PriorityQueue 使用小顶堆来实现，这里通过修改\n     * 两个整数的比较逻辑来让 PriorityQueue 变成大顶堆\n     */")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("compareTo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),t._v(" o"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("compare")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("o"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Test")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTop")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" rowSize "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" columnSize "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建一个columnSize大小的数组，存放结果")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("columnSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" maxHeap "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PriorityQueue")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" rowSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将每个数组的最大一个元素放入堆中")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            maxHeap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" num "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" columnSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 删除堆顶元素")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataWithSource")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" maxHeap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("num"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getValue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" columnSize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n            d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setValue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getIndex")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setIndex")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getIndex")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            maxHeap"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("29")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" top "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTop")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Arrays")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("top"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [30, 29, 25, 20, 19]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("p",[t._v("求 TopK，不妨考虑一下堆排序？")]),t._v(" "),s("h3",{attrs:{id:"如何按照-query-的频度排序？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何按照-query-的频度排序？"}},[t._v("#")]),t._v(" 如何按照 query 的频度排序？")]),t._v(" "),s("p",[t._v("有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。")]),t._v(" "),s("p",[s("strong",[t._v("解答思路")])]),t._v(" "),s("p",[t._v("如果 query 的重复度比较大，可以考虑一次性把所有 query 读入内存中处理；如果 query 的重复率不高，那么可用内存不足以容纳所有的 query，这时候就需要采用分治法或其他的方法来解决。")]),t._v(" "),s("p",[t._v("方法一：HashMap 法")]),t._v(" "),s("p",[t._v("如果 query 重复率高，说明不同 query 总数比较小，可以考虑把所有的 query 都加载到内存中的 HashMap 中。接着就可以按照 query 出现的次数进行排序。")]),t._v(" "),s("p",[t._v("方法二：分治法")]),t._v(" "),s("p",[t._v("分治法需要根据数据量大小以及可用内存的大小来确定问题划分的规模。对于这道题，可以顺序遍历 10 个文件中的 query，通过 Hash 函数 "),s("code",[t._v("hash(query) % 10")]),t._v(" 把这些 query 划分到 10 个小文件中。之后对每个小文件使用 HashMap 统计 query 出现次数，根据次数排序并写入到另外一个单独文件中。")]),t._v(" "),s("p",[t._v("接着对所有文件按照 query 的次数进行排序，这里可以使用归并排序（由于无法把所有 query 都读入内存，因此需要使用外排序）。")]),t._v(" "),s("p",[s("strong",[t._v("方法总结")])]),t._v(" "),s("ul",[s("li",[t._v("内存若够，直接读入进行排序；")]),t._v(" "),s("li",[t._v("内存不够，先划分为小文件，小文件排好序后，整理使用外排序进行归并。")])])])}),[],!1,null,null,null);a.default=v.exports}}]);