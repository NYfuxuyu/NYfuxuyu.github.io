(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{503:function(t,s,a){"use strict";a.r(s);var _=a(4),v=Object(_.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("blockquote",[a("p",[t._v("数据库")])]),t._v(" "),a("h2",{attrs:{id:"数据库基础"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库基础"}},[t._v("#")]),t._v(" 数据库基础")]),t._v(" "),a("h3",{attrs:{id:"数据库的三范式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库的三范式"}},[t._v("#")]),t._v(" 数据库的三范式")]),t._v(" "),a("ul",[a("li",[t._v("第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。")]),t._v(" "),a("li",[t._v("第二范式：要求实体的属性完全依赖于主关键字。所谓完全 依赖是指不能存在仅依赖主关键字一部分的属性。")]),t._v(" "),a("li",[t._v("第三范式：任何非主属性不依赖于其它非主属性。")])]),t._v(" "),a("h3",{attrs:{id:"mysql-支持哪些存储引擎"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql-支持哪些存储引擎"}},[t._v("#")]),t._v(" MySQL 支持哪些存储引擎?")]),t._v(" "),a("p",[t._v("MySQL 支持多种存储引擎,比如 InnoDB,MyISAM,Memory,Archive 等等.在大多数的情况下,直接选择使用 InnoDB 引擎都是最合适的,InnoDB 也是 MySQL 的默认存储引擎。")]),t._v(" "),a("ul",[a("li",[a("p",[a("strong",[t._v("Innodb引擎")]),t._v("：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("MyIASM引擎")]),t._v("(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("MEMORY引擎")]),t._v("：所有的数据都在内存中，数据的处理速度快，但是安全性不高。")])])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}}),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("MyISAM")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Innodb")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("存储结构")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("存储空间")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("MyISAM可被压缩，存储空间较小")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("可移植性、备份及恢复")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("文件格式")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("数据和索引是分别存储的，数据"),a("code",[t._v(".MYD")]),t._v("，索引"),a("code",[t._v(".MYI")])]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("数据和索引是集中存储的，"),a("code",[t._v(".ibd")])])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("记录存储顺序")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("按记录插入顺序保存")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("按主键大小有序插入")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("外键")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("事务")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的）")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("表级锁定")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("行级锁定、表级锁定，锁定力度小并发能力高")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("SELECT")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("MyISAM更优")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}})]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("INSERT、UPDATE、DELETE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}}),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("InnoDB更优")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("select count(*)")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("myisam更快，因为myisam内部维护了一个计数器，可以直接调取。")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}})]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("索引的实现方式")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("B+树索引，myisam 是堆表")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("B+树索引，Innodb 是索引组织表")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("哈希索引")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("全文索引")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")])])])]),t._v(" "),a("h3",{attrs:{id:"超键、候选键、主键、外键分别是什么？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#超键、候选键、主键、外键分别是什么？"}},[t._v("#")]),t._v(" 超键、候选键、主键、外键分别是什么？")]),t._v(" "),a("ul",[a("li",[t._v("超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。")]),t._v(" "),a("li",[t._v("候选键：是最小超键，即没有冗余元素的超键。")]),t._v(" "),a("li",[t._v("主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。")]),t._v(" "),a("li",[t._v("外键：在一个表中存在的另一个表的主键称此表的外键。")])]),t._v(" "),a("h3",{attrs:{id:"sql-约束有哪几种"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sql-约束有哪几种"}},[t._v("#")]),t._v(" SQL 约束有哪几种")]),t._v(" "),a("ul",[a("li",[t._v("NOT NULL: 用于控制字段的内容一定不能为空（NULL）。")]),t._v(" "),a("li",[t._v("UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。")]),t._v(" "),a("li",[t._v("PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。")]),t._v(" "),a("li",[t._v("FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。")]),t._v(" "),a("li",[t._v("CHECK: 用于控制字段的值范围。")])]),t._v(" "),a("h3",{attrs:{id:"mysql-中的-varchar-和-char-有什么区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql-中的-varchar-和-char-有什么区别"}},[t._v("#")]),t._v(" MySQL 中的 varchar 和 char 有什么区别")]),t._v(" "),a("p",[t._v("char 是一个定长字段,假如申请了"),a("code",[t._v("char(10)")]),t._v("的空间,那么无论实际存储多少内容.该字段都占用 10 个字符,而 varchar 是变长的,也就是说申请的只是最大长度,占用的空间为实际字符长度+1,最后一个字符存储使用了多长的空间.")]),t._v(" "),a("p",[t._v("在检索效率上来讲,char > varchar,因此在使用中,如果确定某个字段的值的长度,可以使用 char,否则应该尽量使用 varchar.例如存储用户 MD5 加密后的密码,则应该使用 char。")]),t._v(" "),a("h3",{attrs:{id:"mysql中-in-和-exists-区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql中-in-和-exists-区别"}},[t._v("#")]),t._v(" MySQL中 in 和 exists 区别")]),t._v(" "),a("p",[t._v("MySQL中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。")]),t._v(" "),a("p",[t._v("exists 用于对外表记录做筛选。")]),t._v(" "),a("p",[t._v("exists 会遍历外表，将外查询表的每一行，代入内查询进行判断。当 exists 里的条件语句能够返回记录行时，条件就为真，返回外表当前记录。反之如果exists里的条件语句不能返回记录行，条件为假，则外表当前记录被丢弃")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select a.* from A awhere exists(select 1 from B b where a.id=b.id)\n")])])]),a("p",[t._v("in 是先把后边的语句查出来放到临时表中，然后遍历临时表，将临时表的每一行，代入外查询去查找。")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from Awhere id in(select id from B)\n")])])]),a("p",[t._v("子查询的表大的时候，使用exists可以有效减少总的循环次数来提升速度；当外查询的表大的时候，使用IN可以有效减少对外查询表循环遍历来提升速度。")]),t._v(" "),a("p",[t._v("如果查询的两个表大小相当，那么用in和exists差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。")]),t._v(" "),a("p",[a("strong",[t._v("not in 和not exists")])]),t._v(" "),a("p",[t._v("如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。")]),t._v(" "),a("h3",{attrs:{id:"drop、delete与truncate的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#drop、delete与truncate的区别"}},[t._v("#")]),t._v(" drop、delete与truncate的区别")]),t._v(" "),a("p",[t._v("DML(Data Manipulation Language)数据操纵语言：")]),t._v(" "),a("p",[t._v("适用范围：对数据库中的数据进行一些简单操作，如insert,delete,update,select等.")]),t._v(" "),a("p",[t._v("DDL(Data Definition Language)数据定义语言：")]),t._v(" "),a("p",[t._v("适用范围：对数据库中的某些对象(例如，database,table)进行管理，如Create,Alter和Drop.")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}}),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Delete")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Truncate")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Drop")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("类型")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DML")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DDL")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("DDL")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("回滚")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("可以回滚")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不可回滚")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不可回滚")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("删除内容")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("表结构还在，删除表的全部或一部分数据行")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("表结构还在，删除表中的所有数据")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("从数据库中删除表，所有的数据行，索引和权限也会被删除")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("删除速度")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("删除速度慢，需要逐行删除")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("删除速度快")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("删除速度最快")])])])]),t._v(" "),a("h3",{attrs:{id:"什么是存储过程？有哪些优缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是存储过程？有哪些优缺点"}},[t._v("#")]),t._v(" 什么是存储过程？有哪些优缺点")]),t._v(" "),a("p",[t._v("存储过程是一些预编译的 SQL 语句。")]),t._v(" "),a("p",[t._v("1、更加直白的理解：存储过程可以说是一个记录集，它是由一些 T-SQL 语句组成的代码块，这些 T-SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。")]),t._v(" "),a("p",[t._v("2、存储过程是一个预编译的代码块，执行效率比较高,一个存储过程替代大量 T_SQL 语句 ，可以降低网络通信量，提高通信速率,可以一定程度上确保数据安全")]),t._v(" "),a("p",[t._v("但是,在互联网项目中,其实是不太推荐存储过程的,比较出名的就是阿里的《Java 开发手册》中禁止使用存储过程,我个人的理解是,在互联网项目中,迭代太快,项目的生命周期也比较短,人员流动相比于传统的项目也更加频繁,在这样的情况下,存储过程的管理确实是没有那么方便,同时,复用性也没有写在服务层那么好。")]),t._v(" "),a("h3",{attrs:{id:"sql语句的执行顺序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sql语句的执行顺序"}},[t._v("#")]),t._v(" SQL语句的执行顺序?")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT DISTINCT\n select_list \nFROM\n left_table \nLEFT JOIN\n right_table ON join_condition \nWHERE\n where_condition \nGROUP BY\n group_by_list \nHAVING\n having_condition \nORDER BY\n order_by_condition\n")])])]),a("p",[t._v("执行顺序如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119335.png",alt:"image-20220425123053425"}})]),t._v(" "),a("ul",[a("li",[t._v("FROM：对SQL语句执行查询时，首先对关键字两边的表以笛卡尔积的形式执行连接，并产生一个 虚表V1。虚表就是视图，数据会来自多张表的执行结果。")]),t._v(" "),a("li",[t._v("ON：对FROM连接的结果进行ON过滤,并创建虚表V2")]),t._v(" "),a("li",[t._v("JOIN：将ON过滤后的左表添加进来，并创建新的虚拟表V3")]),t._v(" "),a("li",[t._v("WHERE：对虚拟表V3进行WHERE筛选，创建虚拟表V4")]),t._v(" "),a("li",[t._v("GROUP BY：对V4中的记录进行分组操作，创建虚拟表V5")]),t._v(" "),a("li",[t._v("HAVING：对V5进行过滤，创建虚拟表V6")]),t._v(" "),a("li",[t._v("SELECT：将V6中的结果按照SELECT进行筛选，创建虚拟表V7")]),t._v(" "),a("li",[t._v("DISTINCT：对V7表中的结果进行去重操作，创建虚拟表V8，如果使用了GROUP BY子句则无需使 用DISTINCT，因为分组的时候是将列中唯一的值分成一组，并且每组只返回一行记录，所以所有 的记录都h是不同的。")]),t._v(" "),a("li",[t._v("ORDER BY：对V8表中的结果进行排序。")])]),t._v(" "),a("h3",{attrs:{id:"主键一般用自增id还是uuid？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#主键一般用自增id还是uuid？"}},[t._v("#")]),t._v(" 主键一般用自增ID还是UUID？")]),t._v(" "),a("p",[t._v("使用自增ID的好处：")]),t._v(" "),a("ul",[a("li",[t._v("字段长度较uuid会小很多。")]),t._v(" "),a("li",[t._v("数据库自动编号，按顺序存放，利于检索")]),t._v(" "),a("li",[t._v("无需担心主键重复问题")])]),t._v(" "),a("p",[t._v("使用自增ID的缺点：")]),t._v(" "),a("ul",[a("li",[t._v("因为是自增，在某些业务场景下，容易被其他人查到业务量。")]),t._v(" "),a("li",[t._v("发生数据迁移时，或者表合并时会非常麻烦")]),t._v(" "),a("li",[t._v("在高并发的场景下，竞争自增锁会降低数据库的吞吐能力")])]),t._v(" "),a("p",[t._v("UUID：通用唯一标识码，UUID是基于当前时间、计数器和硬件标识等数据计算生成的。")]),t._v(" "),a("p",[t._v("使用UUID的优点：")]),t._v(" "),a("ul",[a("li",[t._v("唯一标识，不会考虑重复问题，在数据拆分、合并时也能达到全局的唯一性。")]),t._v(" "),a("li",[t._v("可以在应用层生成，提高数据库的吞吐能力。")]),t._v(" "),a("li",[t._v("无需担心业务量泄露的问题。")])]),t._v(" "),a("p",[t._v("使用UUID的缺点：")]),t._v(" "),a("ul",[a("li",[t._v("因为UUID是随机生成的，所以会发生随机IO，影响插入速度，并且会造成硬盘的使用率较低。")]),t._v(" "),a("li",[t._v("UUID占用空间较大，建立的索引越多，造成的影响越大。")]),t._v(" "),a("li",[t._v("UUID之间比较大小较自增ID慢不少，影响查询速度。")])]),t._v(" "),a("p",[t._v("最后说下结论，一般情况MySQL推荐使用自增ID。因为在MySQL的InnoDB存储引擎中，主键索引是一 种聚簇索引，主键索引的B+树的叶子节点按照顺序存储了主键值及数据，如果主键索引是自增ID，只需 要按顺序往后排列即可，如果是UUID，ID是随机生成的，在数据插入时会造成大量的数据移动，产生大量的内存碎片，造成插入性能的下降")]),t._v(" "),a("h2",{attrs:{id:"事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#事务"}},[t._v("#")]),t._v(" 事务")]),t._v(" "),a("h3",{attrs:{id:"什么是数据库事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是数据库事务"}},[t._v("#")]),t._v(" 什么是数据库事务")]),t._v(" "),a("p",[t._v("事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。可以通过commit提交一个事务，也可以使用Rollback进行回滚。")]),t._v(" "),a("h3",{attrs:{id:"acid（事务的四大特性）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#acid（事务的四大特性）"}},[t._v("#")]),t._v(" ACID（事务的四大特性）")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("原子性（Atomicity）")])])]),t._v(" "),a("p",[t._v("事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。")]),t._v(" "),a("p",[t._v("回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。")]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[a("strong",[t._v("一致性（Consistency）")])])]),t._v(" "),a("p",[t._v("数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。")]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[a("strong",[t._v("隔离性（Isolation）")])])]),t._v(" "),a("p",[t._v("一个事务所做的修改在最终提交以前，对其它事务是不可见的。")]),t._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[a("strong",[t._v("持久性（Durability）")])])]),t._v(" "),a("p",[t._v("一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。")]),t._v(" "),a("p",[t._v("系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。")]),t._v(" "),a("h3",{attrs:{id:"事务的隔离级别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#事务的隔离级别"}},[t._v("#")]),t._v(" 事务的隔离级别")]),t._v(" "),a("ul",[a("li",[a("p",[a("strong",[t._v("READ-UNCOMMITTED(读取未提交)：")]),t._v(" 最低的隔离级别，允许读取尚未提交的数据变更，"),a("strong",[t._v("可能会导致脏读、幻读或不可重复读")]),t._v("。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("READ-COMMITTED(读取已提交)：")]),t._v(" 允许读取并发事务已经提交的数据，"),a("strong",[t._v("可以阻止脏读，但是幻读或不可重复读仍有可能发生")]),t._v("。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("REPEATABLE-READ(可重复读)：")]),t._v(" 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，"),a("strong",[t._v("可以阻止脏读和不可重复读，但幻读仍有可能发生")]),t._v("。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("SERIALIZABLE(可串行化)：")]),t._v(" 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，"),a("strong",[t._v("该级别可以防止脏读、不可重复读以及幻读")]),t._v("。")])])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("隔离级别")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("脏读")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("不可重复读")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("幻影读")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("READ-UNCOMMITTED")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("READ-COMMITTED")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("REPEATABLE-READ")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("√")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("SERIALIZABLE")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("×")])])])]),t._v(" "),a("h3",{attrs:{id:"并发一致性问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#并发一致性问题"}},[t._v("#")]),t._v(" 并发一致性问题")]),t._v(" "),a("p",[a("strong",[t._v("丢失修改")])]),t._v(" "),a("p",[t._v("丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改并提交生效，T2 随后修改，T2 的修改覆盖了 T1 的修改。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119384.png",alt:"image-20211207145422704"}})]),t._v(" "),a("p",[a("strong",[t._v("读脏数据")])]),t._v(" "),a("p",[t._v("读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119355.png",alt:"image-20211207145454205"}})]),t._v(" "),a("p",[a("strong",[t._v("不可重复读")])]),t._v(" "),a("p",[t._v("不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119347.png",alt:"image-20211207145513737"}})]),t._v(" "),a("p",[a("strong",[t._v("幻读")])]),t._v(" "),a("p",[t._v("幻读本质上也属于不可重复读的情况，T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119340.png",alt:"image-20211207153818068"}})]),t._v(" "),a("p",[a("strong",[t._v("从控制的角度来讲，不可重复读只需要锁住满足条件的记录，而幻影读要锁住满足条件的及其相近的记录。所以，避免幻读，必须锁住表，避免不可重复读，只需要锁住行")]),t._v("。")]),t._v(" "),a("h3",{attrs:{id:"封锁"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#封锁"}},[t._v("#")]),t._v(" 封锁")]),t._v(" "),a("p",[t._v("MySQL 中提供了两种封锁粒度："),a("strong",[t._v("行级锁")]),t._v("以及"),a("strong",[t._v("表级锁")])]),t._v(" "),a("p",[t._v("应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。")]),t._v(" "),a("p",[t._v("但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。")]),t._v(" "),a("p",[t._v("在选择封锁粒度时，"),a("strong",[t._v("需要在锁开销和并发程度之间做一个权衡")]),t._v("。")]),t._v(" "),a("h5",{attrs:{id:"封锁类型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#封锁类型"}},[t._v("#")]),t._v(" 封锁类型")]),t._v(" "),a("ol",[a("li",[t._v("读写锁")])]),t._v(" "),a("ul",[a("li",[t._v("互斥锁（Exclusive），简写为 X 锁，又称写锁。")]),t._v(" "),a("li",[t._v("共享锁（Shared），简写为 S 锁，又称读锁")])]),t._v(" "),a("p",[t._v("有以下两个规定：")]),t._v(" "),a("ul",[a("li",[t._v("一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。")]),t._v(" "),a("li",[t._v("一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119269.png",alt:"image-20211207155436067"}})]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("意向锁")])]),t._v(" "),a("p",[t._v("使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。")]),t._v(" "),a("p",[t._v("在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。")]),t._v(" "),a("p",[t._v("意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：")]),t._v(" "),a("ul",[a("li",[t._v("一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；")]),t._v(" "),a("li",[t._v("一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。")])]),t._v(" "),a("p",[t._v("通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119829.png",alt:"image-20211207155528420"}})]),t._v(" "),a("p",[t._v("解释如下：")]),t._v(" "),a("ul",[a("li",[t._v("任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁；")]),t._v(" "),a("li",[t._v("这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）")])]),t._v(" "),a("h5",{attrs:{id:"封锁协议"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#封锁协议"}},[t._v("#")]),t._v(" 封锁协议")]),t._v(" "),a("ol",[a("li",[t._v("三级封锁协议")])]),t._v(" "),a("p",[a("strong",[t._v("一级封锁协议")])]),t._v(" "),a("p",[t._v("事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。")]),t._v(" "),a("p",[t._v("可以解决"),a("strong",[t._v("丢失修改")]),t._v("问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119835.png",alt:"image-20211207160731744"}})]),t._v(" "),a("p",[a("strong",[t._v("二级封锁协议")])]),t._v(" "),a("p",[t._v("在一级的基础上，要求读取数据 A 时必须加 S 锁，"),a("strong",[t._v("读取完")]),t._v("马上释放 S 锁。")]),t._v(" "),a("p",[t._v("可以解决"),a("strong",[t._v("读脏数据")]),t._v("问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据")]),t._v(" "),a("p",[a("strong",[t._v("三级封锁协议")])]),t._v(" "),a("p",[t._v("在二级的基础上，要求读取数据 A 时必须加 S 锁，"),a("strong",[t._v("直到事务结束了才能释放")]),t._v(" S 锁。")]),t._v(" "),a("p",[t._v("可以"),a("strong",[t._v("解决不可重复读")]),t._v("的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119929.png",alt:"image-20211207160926440"}})]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("两段锁协议")])]),t._v(" "),a("p",[t._v("加锁和解锁分为两个阶段进行。")]),t._v(" "),a("p",[t._v("可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。")]),t._v(" "),a("p",[t._v("事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。")]),t._v(" "),a("div",{staticClass:"language-html extra-class"},[a("pre",{pre:!0,attrs:{class:"language-html"}},[a("code",[t._v("lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)\n")])])]),a("p",[t._v("但不是必要条件，例如以下操作不满足两段锁协议，但它还是可串行化调度。")]),t._v(" "),a("div",{staticClass:"language-html extra-class"},[a("pre",{pre:!0,attrs:{class:"language-html"}},[a("code",[t._v("lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C)\n")])])]),a("h5",{attrs:{id:"mysql-隐式与显式锁定"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql-隐式与显式锁定"}},[t._v("#")]),t._v(" MySQL 隐式与显式锁定")]),t._v(" "),a("p",[t._v("MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。")]),t._v(" "),a("p",[t._v("InnoDB 也可以使用特定的语句进行显示锁定：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LOCK")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("In")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SHARE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("MODE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FOR")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("h3",{attrs:{id:"mvcc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mvcc"}},[t._v("#")]),t._v(" MVCC")]),t._v(" "),a("p",[t._v("MVCC(multiple version concurrent control)是一种控制并发的方法，主要用来提高数据库的并发性能。")]),t._v(" "),a("p",[t._v("在了解MVCC时应该先了解当前读和快照读。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("当前读")]),t._v("：读取的是数据库的最新版本，并且在读取时要保证其他事务不会修该当前记录，所以会对读取的记录加锁。")]),t._v(" "),a("li",[a("strong",[t._v("快照读")]),t._v("：不加锁读取操作即为快照读，使用MVCC来读取快照中的数据，避免加锁带来的性能损耗。")])]),t._v(" "),a("p",[t._v("可以看到MVCC的作用就是在不加锁的情况下，解决数据库读写冲突问题，实现提交读和可重复读这两种隔离级别，但是不能解决丢失修改问题")]),t._v(" "),a("h5",{attrs:{id:"实现原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现原理"}},[t._v("#")]),t._v(" "),a("strong",[t._v("实现原理")])]),t._v(" "),a("p",[t._v("MVCC 的实现依赖于版本链，版本链是通过表的三个隐藏字段实现")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("DB_TRX_ID")]),t._v(" ：当前事务id，通过事务id的大小判断事务的时间顺序")]),t._v(" "),a("li",[a("code",[t._v("DB_ROLL_PRT")]),t._v("：回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接 在一起构成undo log版本链。")]),t._v(" "),a("li",[a("code",[t._v("DB_ROLL_ID")]),t._v(" ：主键，如果数据表没有主键，InnoDB会自动生成主键。")])]),t._v(" "),a("p",[t._v("版本号：")]),t._v(" "),a("ul",[a("li",[t._v("系统版本号：是一个自增的ID，每开启一个事务，系统版本号都会递增。")]),t._v(" "),a("li",[t._v("事务版本号：事务版本号就是事务开始时的系统版本号，可以通过事务版本号的大小判断事务的时间顺序。")])]),t._v(" "),a("p",[t._v("每条表记录大概是这样的：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119948.png",alt:"image-20220423191734953"}})]),t._v(" "),a("p",[t._v("使用事务更新行记录的时候，就会生成版本链，执行过程如下：")]),t._v(" "),a("ol",[a("li",[t._v("用排他锁锁住该行；")]),t._v(" "),a("li",[t._v("将该行原本的值拷贝到 undo log，作为旧版本用于回滚；")]),t._v(" "),a("li",[t._v("改当前行的值，生成一个新版本，更新事务id，使回滚指针指向旧版本的记录，这样就形成一条版本链。")])]),t._v(" "),a("p",[t._v("下面举个例子方便大家理解")]),t._v(" "),a("ul",[a("li",[t._v("初始数据如下，其中DB_TRX_ID和DB_ROLL_PTR为空。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119957.png",alt:"image-20220423192039145"}})]),t._v(" "),a("ul",[a("li",[t._v("事务A对该行数据做了修改，将age修改为12，效果如下：")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119349.png",alt:"image-20220423192145051"}})]),t._v(" "),a("ul",[a("li",[t._v("之后事务B也对该行记录做了修改，将age修改为8，效果如下：")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119416.png",alt:"image-20220423192205880"}})]),t._v(" "),a("ul",[a("li",[t._v("此时undo log有两行记录，并且通过回滚指针连在一起")])]),t._v(" "),a("p",[t._v("InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。")]),t._v(" "),a("p",[a("strong",[t._v("MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 （隔离性）特性。")])]),t._v(" "),a("h5",{attrs:{id:"read-view"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#read-view"}},[t._v("#")]),t._v(" "),a("strong",[t._v("read view")])]),t._v(" "),a("p",[a("code",[t._v("read view")]),t._v("可以理解成对数据在每个时刻的状态拍成“照片”记录下来。这样获取某时刻的数据时就还是 原来的”照片“上的数据，是不会变的。")]),t._v(" "),a("p",[t._v("在 "),a("code",[t._v("read view")]),t._v("内部维护一个活跃事务链表，表示生成 "),a("code",[t._v("read view")]),t._v("的时候还在活跃的事务。这个链表包含在创建"),a("code",[t._v("read view")]),t._v("之前还未提交的事务，不包含创建 "),a("code",[t._v("read view")]),t._v("之后提交的事务。")]),t._v(" "),a("p",[a("strong",[t._v("不同隔离级别创建read view的时机不同。")])]),t._v(" "),a("ul",[a("li",[t._v("read committed：每次执行select都会创建新的read_view，保证能读取到其他事务已经提交的修改。")]),t._v(" "),a("li",[t._v("repeatable read：在一个事务范围内，第一次select时更新这个read_view，以后不会再更新，后续所有的select都是复用之前的read_view。这样可以保证事务范围内每次读取的内容都一样，即可重复读。")])]),t._v(" "),a("p",[a("strong",[t._v("read view的记录筛选方式")])]),t._v(" "),a("p",[a("code",[t._v("DATA_TRX_ID")]),t._v(" 表示每个数据行的最新的事务ID；"),a("code",[t._v("up_limit_id")]),t._v(" 表示当前快照中的最先开始的事务；"),a("code",[t._v("low_limit_id")]),t._v("表示当前快照中的最慢开始的事务，即最后一个事务。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119338.png",alt:"image-20220423195211032"}})]),t._v(" "),a("ul",[a("li",[t._v("如果 "),a("code",[t._v("DATA_TRX_ID")]),t._v(" <"),a("code",[t._v("up_limit_id")]),t._v("：说明在创建 "),a("code",[t._v("read view")]),t._v(" 时，修改该数据行的事务已提交，该版本的记录可被当前事务读取到。")]),t._v(" "),a("li",[t._v("如果 "),a("code",[t._v("DATA_TRX_ID")]),t._v(">="),a("code",[t._v("low_limit_id")]),t._v(" ：说明当前版本的记录的事务是在创建 "),a("code",[t._v("read view")]),t._v(" 之后生成的，该版本的数据行不可以被当前事务访问。此时需要通过版本链找到上一个版本，然后重新判断该版本的记录对当前事务的可见性。")]),t._v(" "),a("li",[t._v("如果 "),a("code",[t._v("up_limit_id")]),t._v("<= "),a("code",[t._v("DATA_TRX_ID")]),t._v("<"),a("code",[t._v("low_limit_i")]),t._v("：\n"),a("ul",[a("li",[t._v("需要在活跃事务链表中查找是否存在ID为 "),a("code",[t._v("DATA_TRX_ID")]),t._v(" 的值的事务。")]),t._v(" "),a("li",[t._v("如果存在，因为在活跃事务链表中的事务是未提交的，所以该记录是不可见的。此时需要通过版本链找到上一个版本，然后重新判断该版本的可见性。")]),t._v(" "),a("li",[t._v("如果不存在，说明事务trx_id 已经提交了，这行记录是可见的。")])])])]),t._v(" "),a("p",[a("strong",[t._v("总结")]),t._v("：InnoDB 的 MVCC 是通过 "),a("code",[t._v("read view")]),t._v("和版本链实现的，版本链保存有历史版本记录，通过 read view 判断当前版本的数据是否可见，如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本。")]),t._v(" "),a("h5",{attrs:{id:"快照读和当前读"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#快照读和当前读"}},[t._v("#")]),t._v(" 快照读和当前读")]),t._v(" "),a("p",[a("strong",[t._v("表记录有两种读取方式")])]),t._v(" "),a("ul",[a("li",[t._v("快照读：读取的是快照版本。普通的SELECT就是快照读。通过MVCC来进行并发控制的，不用加锁。")]),t._v(" "),a("li",[t._v("当前读：读取的是最新版本。 "),a("code",[t._v("UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、 SELECT … FOR UPDATE")]),t._v("是当前读。")])]),t._v(" "),a("p",[t._v("快照读情况下，"),a("strong",[t._v("InnoDB通过mvcc机制避免了幻读现象。而mvcc机制无法避免当前读情况下出现的幻读现象。因为当前读每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。")])]),t._v(" "),a("p",[t._v("下面举个例子说明下：")]),t._v(" "),a("ol",[a("li",[t._v("首先，user表只有两条记录，具体如下：")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119385.png",alt:"image-20220423211812267"}})]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[a("p",[t._v("事务a和事务b同时开启事务 start transaction")])]),t._v(" "),a("li",[a("p",[t._v("事务a插入数据然后提交")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_password"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_mail"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tyson'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("事务b执行全表的update")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" user_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("事务b然后执行查询，查到了事务a中插入的数据。（下图左边是事务b，右边是事务a）")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119576.png",alt:"image-20220423212441388"}})])])]),t._v(" "),a("p",[t._v("以上就是当前读出现的幻读现象。")]),t._v(" "),a("p",[a("strong",[t._v("那么MySQL如何实现避免幻读？")])]),t._v(" "),a("ul",[a("li",[t._v("在快照读情况下，MySQL通过mvcc来避免幻读。")]),t._v(" "),a("li",[t._v("在当前读情况下，MySQL通过next-key来避免幻读（加行锁和间隙锁来实现的）。")])]),t._v(" "),a("p",[t._v("Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。")]),t._v(" "),a("p",[a("strong",[t._v("MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题")])]),t._v(" "),a("p",[t._v("next-key包括两部分：行锁和间隙锁。行锁是加在索引上的锁，间隙锁是加在索引之间的。")]),t._v(" "),a("p",[a("code",[t._v("Serializable")]),t._v("隔离级别也可以避免幻读，会锁住整张表，并发性极低，一般不会使用。")]),t._v(" "),a("h3",{attrs:{id:"面试常见问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#面试常见问题"}},[t._v("#")]),t._v(" 面试常见问题")]),t._v(" "),a("h5",{attrs:{id:"幻读是怎么被解决的？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#幻读是怎么被解决的？"}},[t._v("#")]),t._v(" 幻读是怎么被解决的？")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119983.png",alt:"在这里插入图片描述"}})]),t._v(" "),a("p",[t._v("举个例子")]),t._v(" "),a("p",[t._v("实验的数据库表 t_stu 如下，其中 id 为主键。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119860.png",alt:"在这里插入图片描述"}}),t._v(" 然后在可重复读隔离级别下，有两个事务的执行顺序如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119038.png",alt:"在这里插入图片描述"}})]),t._v(" "),a("p",[t._v("从这个实验结果可以看到，即使事务 B 中途插入了一条记录，事务 A 前后两次查询的结果集都是一样的，并没有出现所谓的幻读现象。")]),t._v(" "),a("p",[t._v("读者做的实验之所以看不到幻读现象，是因为在可重复读隔离级别下，"),a("strong",[t._v("普通的查询是快照读，是不会看到别的事务插入的数据的")]),t._v("。")]),t._v(" "),a("p",[t._v("可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是启动事务后，在执行第一个查询语句后，会创建一个视图，然后后续的查询语句都用这个视图，「快照读」读的就是这个视图的数据，视图你可以理解为版本数据，这样就使得每次查询的数据都是一样的。")]),t._v(" "),a("p",[t._v("MySQL 里除了普通查询是快照度，其他都是"),a("strong",[t._v("当前读")]),t._v("，比如update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。")]),t._v(" "),a("p",[t._v("这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且 提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。")]),t._v(" "),a("p",[t._v("另外，"),a("code",[t._v("select ... for update")]),t._v(" 这种查询语句是当前读，每次执行的时候都是读取最新的数据。")]),t._v(" "),a("p",[a("strong",[t._v("因此，要讨论「可重复读」隔离级别的幻读现象，是要建立在「当前读」的情况下。")])]),t._v(" "),a("p",[t._v("接下来，我们假设"),a("code",[t._v("select ... for update")]),t._v("当前读是不会加锁的（实际上是会加锁的），在做一遍读者那个实验。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119995.png",alt:"img"}})]),t._v(" "),a("p",[t._v("这时候，事务 B 插入的记录，就会被事务 A 的第二条查询语句查询到（因为是当前读），这样就会出现前后两次查询的结果集合不一样，这就出现了幻读。")]),t._v(" "),a("p",[t._v("所以，"),a("strong",[t._v("Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁")]),t._v("，就是记录锁和间隙锁的组合。")]),t._v(" "),a("ul",[a("li",[t._v("记录锁，锁的是记录本身；")]),t._v(" "),a("li",[t._v("间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。")])]),t._v(" "),a("p",[t._v("比如，执行这条语句的时候，会锁住，然后期间如果有其他事务在这个锁住的范围插入数据就会被阻塞。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119923.png",alt:"img"}})]),t._v(" "),a("p",[t._v("next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁。")]),t._v(" "),a("p",[t._v("需要注意的是，next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。")]),t._v(" "),a("h5",{attrs:{id:"讲一下数据库的四种隔离级别，以及具体的实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#讲一下数据库的四种隔离级别，以及具体的实现"}},[t._v("#")]),t._v(" 讲一下数据库的四种隔离级别，以及具体的实现")]),t._v(" "),a("p",[t._v("SQL 标准定义了四种越来越严格的事务隔离级别，用来解决我们上述所说的四种事务的并发一致性问题。")]),t._v(" "),a("p",[t._v("1）"),a("strong",[t._v("READ UNCOMMITTED")]),t._v(" 读取未提交：一个事务还没提交时，它做的变更就能被别的事务看到")]),t._v(" "),a("p",[t._v("上面提到过，数据库本身其实已经具备阻止丢失更新的能力，也就是说，即使是最低的隔离级别也可以阻止丢失更新问题。所以：")]),t._v(" "),a("ul",[a("li",[t._v("这个隔离级别可以阻止 丢失更新")])]),t._v(" "),a("p",[t._v("2）"),a("strong",[t._v("READ COMMITTED")]),t._v(" 读取已提交：一个事务提交之后，它做的变更才会被其他事务看到。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。")]),t._v(" "),a("ul",[a("li",[t._v("这个隔离级别可以阻止 丢失更新 + 脏读")])]),t._v(" "),a("p",[t._v("3）"),a("strong",[t._v("REPEATABLE READ")]),t._v(" 可重复读（InnoDB 存储引擎默认的隔离级别）：保证在同一个事务中多次读取同一数据的结果是一样的。当然了，在可重复读隔离级别下，未提交变更对其他事务也是不可见的。")]),t._v(" "),a("blockquote",[a("p",[t._v("书中就是这么解释的，好像也挺通俗易懂的，那为了方便下面的行文，我再给一个更简单的解释：")]),t._v(" "),a("p",[t._v("可重复读就是：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。或者简单来说，事务在执行期间看到的数据前后是一致的。")])]),t._v(" "),a("ul",[a("li",[t._v("这个隔离级别可以阻止 丢失更新 + 脏读 + 不可重复读")])]),t._v(" "),a("p",[t._v("4）"),a("strong",[t._v("SERIALIZABL")]),t._v(" 可串行化：顾名思义，强制事务串行执行，对于同一行记录，“写” 会加 “写锁”，“读” 会加 “读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。这样多个事务互不干扰，不会出现并发一致性问题")]),t._v(" "),a("ul",[a("li",[t._v("这个隔离级别可以阻止 丢失更新 + 脏读 + 不可重复读 + 幻读")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119117.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("可以看到四种隔离级别能阻止的并发一致性问题越来越多，但并不代表越高的隔离级别就越好，因为事务隔离级别越高，数据库付出的性能代价也就相应地越大。")]),t._v(" "),a("blockquote",[a("p",[t._v("另外，多提一嘴，InnoDB 存储引擎在 REPEATABLE READ 可重复读的隔离级别下，使用 Next-Key Lock 锁的算法避免了幻读的产生, 具体可以看这篇文章 "),a("a",{attrs:{href:"https://mp.weixin.qq.com/s?__biz=MzI0NDc3ODE5OQ==&mid=2247489196&idx=1&sn=50ace2f83a16d898108e01039468cf40&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"}},[t._v("幻读为什么会被 MySQL 单独拎出来解决？"),a("OutboundLink")],1),t._v("。也就是说，InnoDB 存储引擎在其默认的 REPEATABLE READ 事务隔离级别下就已经能完全保证事务的隔离性要求了，即达到了 SQL 标准的 SERIALIZABLE 隔离级别。")])]),t._v(" "),a("p",[t._v("举个例子，看下图，我们来看看在不同的隔离级别下，事务 A 对同一个字段的查询会得到哪些不同的返回结果：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119401.png",alt:"图片"}}),t._v("image-20211209104207832")]),t._v(" "),a("p",[t._v("1）READ UNCOMMITTED 读取未提交：V1 V2、V3 都是 2。事务 B 虽然还没有提交，但是修改的结果结果已经被 A 看到了")]),t._v(" "),a("p",[t._v("2）READ COMMITTED 读取已提交：V1 是 1，然后事务 B 对字段的修改提交了，能被 A 看到，所以，V2 V3 的值都是 2")]),t._v(" "),a("p",[t._v("3）REPEATABLE READ 可重复读：V1 V2 是 1，V3 是 2。回想下这句话你就懂了：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的")]),t._v(" "),a("p",[t._v("4）SERIALIZABL 可串行化：事务 B 执行 “将字段 a 的值改为 2” 的时候会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从事务 A 的角度看， V1 V2 的值是 1，V3 的值是在事务 2 提交后的，所以 V3 是 2。")]),t._v(" "),a("p",[a("strong",[t._v("四种隔离级别的具体实现")])]),t._v(" "),a("p",[t._v("读取未提交和可串行化的实现没什么好说的，一个是啥也不干，一个是直接无脑加锁避开并行化 让你啥也干不成。")]),t._v(" "),a("p",[t._v("重头戏就是读取已提交和可重复读是如何实现的。这就是我们要说的 MVCC 了，也就是面试中的超级高频题。")]),t._v(" "),a("p",[t._v("我先来简单说一下，对于这两个隔离级别，"),a("strong",[t._v("数据库会为每个事务创建一个视图 (ReadView)，访问的时候以视图的逻辑结果为准")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("在 “读取已提交” 隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的")]),t._v(" "),a("li",[t._v("在 “可重复读” 隔离级别下，这个视图是在事务启动时就创建的，整个事务存在期间都用这个视图（这就是为什么说在可重复读隔离级别下，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的）")])]),t._v(" "),a("p",[t._v("那么问题了就来了，"),a("strong",[t._v("已经执行了这么多的操作，事务该如何重新回到之前视图记录的状态")]),t._v("？"),a("strong",[t._v("数据库会通过某种手段记录这之间执行的种种操作吗")]),t._v("？")]),t._v(" "),a("p",[t._v("这就是 undo log 版本链做的事 👇")]),t._v(" "),a("p",[a("strong",[t._v("简易版")])]),t._v(" "),a("p",[t._v("数据库的四种隔离级别主要是用来解决四种并发一致性问题的，隔离级别越高，能够处理的并发一致性问题越多，相应的数据库付出的性能代价也就越高。")]),t._v(" "),a("p",[t._v("最低的隔离级别是读取未提交，一个事务还没提交时，它做的变更就能被别的事务看到：可以解决丢失更新问题（所谓丢失更新问题，就是指一个事务的更新操作会被另一个事务的更新操作所覆盖）；")]),t._v(" "),a("p",[t._v("然后是读取已提交，一个事务提交之后，它做的变更才会被其他事务看到：可以解决丢失更新和脏读问题（所谓脏读，就是一个事务读到了另外一个事务未提交的数据）；")]),t._v(" "),a("p",[t._v("然后是 InnoDB 默认的隔离级别可重复读，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的：可以解决丢失更新、脏读和不可重复读问题（所谓不可重复读，就是指第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据是不一样的）。另外，InnoDB 的这个默认隔离级别，会通过 Next-Lock key 来解决幻读问题，所以其实是可以达到 SQL 标准的可串行化隔离级别的；")]),t._v(" "),a("p",[t._v("最后是可串行化，强制事务串行执行，对于同一行记录，“写” 会加 “写锁”，“读” 会加 “读锁”，当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。这样可以避免并发一致性问题，解决丢失更新、脏读、不可重复读和幻读问题（所谓幻读，和不可重复读差不多，不过幻读侧重于记录数量的增减，不可重复读侧重于记录的修改）")]),t._v(" "),a("p",[t._v("对于读取已提交和可重复读这两个隔离级别来说，其底层实现就是多版本并发控制 MVCC。")]),t._v(" "),a("p",[t._v("具体来说，对于这两个隔离级别，数据库会为每个事务创建一个视图 (ReadView)，访问的时候以视图的逻辑结果为准。通过 undo log 版本链使得事务可以回滚到视图记录的状态。")]),t._v(" "),a("p",[a("strong",[t._v("而这两个隔离级别的区别就在于，它们生成 ReadView 的时机是不同的：")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("在 “读取已提交” 隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的")])]),t._v(" "),a("li",[a("strong",[t._v("在 “可重复读” 隔离级别下，这个视图是在事务启动时就创建的，整个事务存在期间都用这个视图")])])]),t._v(" "),a("p",[a("strong",[t._v("undo log 版本链")])]),t._v(" "),a("p",[t._v("在 MySQL 中，每条记录在更新的时候都会同时记录一条回滚操作（也就是 undo log），当前记录上的最新值，通过回滚操作，都可以得到前一个状态的值。")]),t._v(" "),a("p",[t._v("简单理解，"),a("strong",[t._v("undo log 就是每次操作的反向操作")]),t._v("，比如比如当前事务执行了一个插入 id = 100 的记录的操作，那么 undo log 中存储的就是删除 id = 100 的记录的操作。")]),t._v(" "),a("p",[t._v("也就是说，B+ 索引树上对应的记录只会有一个最新版本，但是 InnoDB 可以"),a("strong",[t._v("根据 undo log 得到数据的历史版本")]),t._v("。"),a("strong",[t._v("同一条记录在系统中可以存在多个版本")]),t._v("，就是数据库的"),a("strong",[t._v("多版本并发控制")]),t._v("（MVCC）")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119409.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("那么，还有个问题，undo log 是如何和某条行记录产生联系的呢？换句话说，我怎么能通过这条行记录找到它拥有的 undo log 呢？")]),t._v(" "),a("p",[t._v("具体来说，"),a("strong",[t._v("InnoDB 存储引擎中每条行记录其实都拥有两个隐藏的字段："),a("code",[t._v("trx_id")]),t._v(" 和 "),a("code",[t._v("roll_pointer")])]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("trx_id")]),t._v(" 就是最近更新这条行记录的事务 ID")]),t._v(" "),a("li",[a("code",[t._v("roll_pointer")]),t._v(" 就是指向之前生成的 undo log 的指针")])]),t._v(" "),a("p",[t._v('掏出我们的 user 表，来举个例子，假设 id = 100 的事务 A 插入一条行记录（id = 1, username = "Jack", age = 18），那么，这行记录的两个隐藏字段 '),a("code",[t._v("trx_id = 100")]),t._v(" 和 "),a("code",[t._v("roll_pointer")]),t._v(" 指向一个空的 undo log，因为在这之前并没有事务操作 id = 1 的这行记录。如图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119745.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("然后，id = 200 的事务 B 修改了这条行记录，把 age 从 18 修改成了 20，于是，这条行记录的 "),a("code",[t._v("trx_id")]),t._v(" 就变成了 200，"),a("code",[t._v("rooll_pointer")]),t._v(" 就指向事务 A 生成的 undo log ：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119628.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("接着，id = 300 的事务 C 再次修改了这条行记录，把 age 从 20 修改成了 30，如下图：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119664.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("可以看到，每次修改行记录都会更新 trx_id 和 roll_pointer 这两个隐藏字段，之前的多个数据快照对应的 undo log 会通过 roll_pointer 指针串联起来，从而形成一个"),a("strong",[t._v("版本链")]),t._v("。")]),t._v(" "),a("p",[t._v("那么问题又来了，一个记录会被一堆事务进行修改，一个记录上会存在许许多多的 undo log，"),a("strong",[t._v("那么对于其中某一个事务来说，它能看见哪些 undo log")]),t._v("？或者说，"),a("strong",[t._v("对于其中某一个事务来说，它能够根据哪些 undo log 执行回滚操作")]),t._v("？")]),t._v(" "),a("p",[t._v("让我们来详细解释一下这个视图（ReadView）机制 👇")]),t._v(" "),a("p",[a("strong",[t._v("ReadView 机制")])]),t._v(" "),a("p",[a("strong",[t._v("ReadView 机制就是用来判断当前事务能够看见哪些版本的")]),t._v("，一个 ReadView 主要包含如下几个部分：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("m_ids")]),t._v("：生成 ReadView 时有哪些事务在执行但是还没提交的（称为 “"),a("strong",[t._v("活跃事务")]),t._v("”），这些活跃事务的 id 就存在这个字段里")]),t._v(" "),a("li",[a("code",[t._v("min_trx_id")]),t._v("：m_ids 里最小的值")]),t._v(" "),a("li",[a("code",[t._v("max_trx_id")]),t._v("：生成 ReadView 时 InnoDB 将分配给下一个事务的 ID 的值（事务 ID 是递增分配的，越后面申请的事务 ID 越大）")]),t._v(" "),a("li",[a("code",[t._v("creator_trx_id")]),t._v("：当前创建 ReadView 事务的 ID")])]),t._v(" "),a("p",[t._v("接下来，再掏出 user 表，通过一个例子来理解下 ReaView 机制是如何做到判断当前事务能够看见哪些版本的：")]),t._v(" "),a("p",[t._v('假设表中已经被之前的事务 A（id = 100）插入了一条行记录（id = 1, username = "Jack", age = 18），如图所示：')]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119745.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("接下来，有两个事务 B（id = 200） 和 C（id = 300）过来"),a("strong",[t._v("并发执行")]),t._v("，事务 B 想要更新（update）这行 id = 1 的记录，而事务 C（select）想要查询这行数据，这两个事务都执行了相应的操作但是还没有进行提交：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119698.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("如果现在事务 B 开启了一个 ReadView，在这个 ReadView 里面：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("m_ids")]),t._v(" 就包含了当前的活跃事务的 id，即事务 B 和事务 C 这两个 id，200 和 300")]),t._v(" "),a("li",[a("code",[t._v("min_trx_id")]),t._v(" 就是 200")]),t._v(" "),a("li",[a("code",[t._v("max_trx_id")]),t._v(" 是下一个能够分配的事务的 id，那就是 301")]),t._v(" "),a("li",[a("code",[t._v("creator_trx_id")]),t._v(" 是当前创建 ReadView 事务 B 的 id 200")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119901.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("现在事务 B 进行第一次查询（select 操作不会生成 undo log 的哈），会"),a("strong",[t._v("把这行记录的隐藏字段 "),a("code",[t._v("trx_id")]),t._v(" 和 ReadView 的 "),a("code",[t._v("min_trx_id")]),t._v(" 进行下判断")]),t._v("，此时，发现 trx_id 是 100，小于 ReadView 里的 "),a("code",[t._v("min_trx_id")]),t._v("（200），这说明在事务 B 开始之前，修改这行记录的事务 A 已经提交了，所以"),a("strong",[t._v("开始于事务 A 提交之后的事务 B、是可以查到事务 A 对这行记录的更新的")]),t._v("。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("row.trx_id < ReadView.min_trx_id\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119401.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("接着事务 C 过来修改这行记录，把 age = 18 改成了 age = 20，所以这行记录的 "),a("code",[t._v("trx_id")]),t._v(" 就变成了 300，同时 "),a("code",[t._v("roll_pointer")]),t._v(" 指向了事务 C 修改之前生成的 undo log：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119924.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("那这个时候事务 B 再次进行查询操作，会发现"),a("strong",[t._v("这行记录的 "),a("code",[t._v("trx_id")]),t._v("（300）大于 ReadView 的 "),a("code",[t._v("min_trx_id")]),t._v("（200），并且小于 "),a("code",[t._v("max_trx_id")]),t._v("（301）")]),t._v("。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("row.trx_id > ReadView.min_trx_id && row.trx_id < max_trx_id\n")])])]),a("p",[t._v("这说明一个问题，就是更新这行记录的事务很有可能也存在于 ReadView 的 m_ids（活跃事务）中。所以事务 B 会去判断下 ReadView 的 m_ids 里面是否存在 "),a("code",[t._v("trx_id = 300")]),t._v(" 的事务，显然是存在的，这就表示这个 id = 300 的事务是跟自己（事务 B）在同一时间段并发执行的事务，也就说明这行 age = 20 的记录事务 B 是不能查询到的。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119370.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("既然无法查询，那该咋整？事务 B 这次的查询操作能够查到啥呢？")]),t._v(" "),a("p",[t._v("没错，undo log 版本链")]),t._v(" "),a("p",[t._v("这时事务 B 就会顺着这行记录的 roll_pointer 指针往下找，就会找到最近的一条 "),a("code",[t._v("trx_id = 100")]),t._v(" 的 undo log，而自己的 id 是 200，即说明这个 trx_id = 100 的 undo log 版本必然是在事务 B 开启之前就已经提交的了。所以事务 B 的这次查询操作读到的就是这个版本的数据即 age = 18。")]),t._v(" "),a("p",[t._v("通过上述的例子，我们得出的结论是，"),a("strong",[t._v("通过 undo log 版本链和 ReadView 机制，可以保证一个事务不会读到并发执行的另一个事务的更新")]),t._v("。")]),t._v(" "),a("p",[t._v("那自己修改的值，自己能不能读到呢？")]),t._v(" "),a("p",[t._v("这当然是废话，肯定可以读到呀。上面的例子我们只涉及到了 ReadView 中的前三个字段，而 "),a("code",[t._v("creator_trx_id")]),t._v(" 就与自己读自己的修改有关，所以这里还是图解出来让大家更进一步理解下 ReadView 机制：")]),t._v(" "),a("p",[t._v("假设事务 C 的修改已经提交了，然后事务 B 更新了这行记录，把 age = 20 改成了 age = 66，如下图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119327.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("然后，事务 B 再来查询这条记录，发现 "),a("code",[t._v("trx_id = 200")]),t._v(" 与 ReadView 里的 "),a("code",[t._v("creator_trx_id = 200")]),t._v(" 一样，这就说明这是我自己刚刚修改的啊，当然可以被查询到。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("row.trx_id = ReadView.creator_trx_id\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119279.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("那如果在事务 B 的执行期间，突然开了一个 id = 500 的事务 D，然后更新了这行记录的 age = 88 并且还提交了，然后事务 B 再去读这行记录，能读到吗？")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119406.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("答案是不能的。")]),t._v(" "),a("p",[t._v("因为这个时候事务 B 再去查询这行记录，就会发现 "),a("code",[t._v("trx_id = 500")]),t._v(" 大于 ReadView 中的 "),a("code",[t._v("max_trx_id = 301")]),t._v("，这说明事务 B 执行期间，有另外一个事务更新了数据，所以不能查询到另外一个事务的更新。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("row.trx_id > ReadView.max_trx_id\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119533.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("那通过上述的例子，我们得出的结论是，"),a("strong",[t._v("通过 undo log 版本链和 ReadView 机制，可以保证一个事务只可以读到该事务自己修改的数据或该事务开始之前的数据")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引"}},[t._v("#")]),t._v(" 索引")]),t._v(" "),a("h3",{attrs:{id:"索引是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引是什么"}},[t._v("#")]),t._v(" 索引是什么")]),t._v(" "),a("p",[t._v("索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，是存储引擎用于提高数据库表的访问速度的一种数据结构。")]),t._v(" "),a("h3",{attrs:{id:"索引的优缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引的优缺点"}},[t._v("#")]),t._v(" 索引的优缺点")]),t._v(" "),a("p",[t._v("优点：")]),t._v(" "),a("ul",[a("li",[t._v("加快数据查找的速度，大大减少了服务器需要扫描的数量")]),t._v(" "),a("li",[t._v("为用来排序或者是分组的字段添加索引，可以加快分组和排序的速度")]),t._v(" "),a("li",[t._v("加速表与表之间的连接")]),t._v(" "),a("li",[t._v("将随机IO变成顺序IO\n"),a("ul",[a("li",[t._v("尽可能的降低磁盘的寻址时间，也就是局部性原理，就是很大一部分数据在未来的一段时间被连续访问")]),t._v(" "),a("li",[t._v("减少IO的次数，一次IO能搞定的事，不使用3次IO")])])])]),t._v(" "),a("p",[t._v("缺点：")]),t._v(" "),a("ul",[a("li",[t._v("建立索引需要占用物理空间")]),t._v(" "),a("li",[t._v("会降低表的增删改的效率，因为每次对表记录进行增删改，需要进行动态维护索引，导致增删改时间变长")])]),t._v(" "),a("h3",{attrs:{id:"索引的分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引的分类"}},[t._v("#")]),t._v(" 索引的分类")]),t._v(" "),a("p",[t._v("从"),a("strong",[t._v("物理结构上")]),t._v(" 分为两类：聚集索引和非聚集索引,辅助索引（二级索引） 聚集索引是指 索引的键值的逻辑顺序决定了表中相应行的物理顺序。")]),t._v(" "),a("p",[t._v("注意：一个表中只能有一个聚集索引。")]),t._v(" "),a("p",[a("strong",[t._v("按照数据结构分类：")])]),t._v(" "),a("ul",[a("li",[a("p",[t._v("B TREE索引：最常见的索引类型，大部分索引都支持B树索引。")])]),t._v(" "),a("li",[a("p",[t._v("HASH索引：只有Memory引擎支持，使用场景简单。")])]),t._v(" "),a("li",[a("p",[t._v("R-tree索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少。")])]),t._v(" "),a("li",[a("p",[t._v("Full-text（全文索引）：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从MySQL 5.6版本开始支持全文索引。")])]),t._v(" "),a("li",[a("p",[t._v("MyISAM、InnoDB、Memory三种存储引擎对各种索引类型的支持：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("索引")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("InnoDB引擎")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("MyISAM引擎")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("Memory引擎")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("B TREE索引")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("HASH索引")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("R-tree索引")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("Full-text")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("5.6版本后支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("支持")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不支持")])])])])])]),t._v(" "),a("p",[a("strong",[t._v("应用分类")])]),t._v(" "),a("h5",{attrs:{id:"主键"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#主键"}},[t._v("#")]),t._v(" 主键")]),t._v(" "),a("p",[t._v("如果你在创建索引的时候，使用的是主键这个值，那么就是主键索引，primary key")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" table_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ADD")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("column_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("InnoDB创建聚簇索引的具体规则如下：")])]),t._v(" "),a("ol",[a("li",[t._v("在表上定义主键PRIMARY KEY，InnoDB将主键索引用作聚簇索引。")]),t._v(" "),a("li",[t._v("如果表没有定义主键，InnoDB会选择第一个不为NULL的唯一索引列用作聚簇索引。")]),t._v(" "),a("li",[t._v("如果以上两个都没有，InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引。该ROWID字段会在插入新行时自动递增。")])]),t._v(" "),a("p",[t._v("除聚簇索引之外的所有索引都称为辅助索引。在InnoDB中，辅助索引中的叶子节点存储的数据是该行的主键值都。 在检索时，InnoDB使用此主键值在聚簇索引中搜索行记录")]),t._v(" "),a("h5",{attrs:{id:"唯一"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#唯一"}},[t._v("#")]),t._v(" 唯一")]),t._v(" "),a("p",[t._v("唯一索引 类似于普通索引，索引列的值必须唯一")]),t._v(" "),a("p",[t._v("唯一索引和主键索引的区别就是，唯一索引允许出现空值，而主键索引不能为空")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unique")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" index_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("column")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("或者创建表时指定")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unique")]),t._v(" index_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("column")]),t._v("\n")])])]),a("p",[a("strong",[t._v("主键索引与唯一索引的区别：")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。")])]),t._v(" "),a("li",[a("p",[t._v("主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。")])]),t._v(" "),a("li",[a("p",[t._v("唯一性索引列允许空值，而主键列不允许为空值。")])]),t._v(" "),a("li",[a("p",[t._v("主键索引在创建时，已经默认为非空值+ 唯一索引了。")])]),t._v(" "),a("li",[a("p",[t._v("一个表最多只能创建一个主键索引，但可以创建多个唯一索引。")])]),t._v(" "),a("li",[a("p",[t._v("主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。")])]),t._v(" "),a("li",[a("p",[t._v("主键可以被其他表引用为外键，而唯一索引不能")])])]),t._v(" "),a("h5",{attrs:{id:"普通"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#普通"}},[t._v("#")]),t._v(" 普通")]),t._v(" "),a("p",[t._v("当我们需要建立索引的字段，既不是主键索引，也不是唯一索引")]),t._v(" "),a("p",[t._v("那么就可以创建一个普通索引")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v("  index_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("column")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("或者创建表时指定")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" index_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("column")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h5",{attrs:{id:"组合"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#组合"}},[t._v("#")]),t._v(" 组合")]),t._v(" "),a("p",[t._v("目前，在业务不是特别复杂的时候，可能使用一个列作为索引，或者直接采用主键索引即可，但是如果业务变得复杂的时候，就需要用到组合索引，通过对多个列建立索引。")]),t._v(" "),a("p",[t._v("组合索引的用处，假设我现在表有个多个字段：id、name、age、gender，然后我经常使用以下的查询条件")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xx'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" age "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x\n")])])]),a("p",[t._v("这个时候，我们就可以通过组合 name 和 age 来建立一个组合索引，加快查询效率，建立成组合索引后，我的索引将包含两个key值")]),t._v(" "),a("p",[t._v("在多个字段上创建索引，遵循"),a("strong",[t._v("最左匹配")]),t._v("原则")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alter")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("add")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" index_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("最左前缀匹配原则")]),t._v("和联合索引的索引存储结构和检索方式是有关系的。 在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列 只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。")]),t._v(" "),a("p",[t._v("组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到"),a("strong",[t._v("范围查询")]),t._v("(>、 <、between、like)就停止匹配")]),t._v(" "),a("p",[a("strong",[t._v("组合索引创建原则")])]),t._v(" "),a("ol",[a("li",[t._v("频繁出现在where条件中的列，建议创建组合索引。")]),t._v(" "),a("li",[t._v("频繁出现在order by和group by语句中的列，建议按照顺序去创建组合索引。 order by a,b 需要组合索引列顺序（a,b）。如果索引的顺序是（b,a），是用不到索引的。")]),t._v(" "),a("li",[t._v("常出现在select语句中的列，也建议创建组合索引。")]),t._v(" "),a("li",[t._v("对于第1种情况和第3种情况，组合索引创建的顺序对其来说是等价的，这种情况下组合索引中的顺序是很重要的。由于组合索引会使用到最左前缀原则，使用频繁的列在创建索引时排在前面。")])]),t._v(" "),a("p",[a("strong",[t._v("思考题")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" c\n")])])]),a("p",[t._v("可以考虑建立（a,c）联合索引：select * from t where a=1 and b>2 order by c 这样")]),t._v(" "),a("p",[t._v("a等值查询的时候c已经是排好序的了。这种情况实际比的是b的区分度和c的区分度，如果b的区分度较差，建议用ac。c的区分度较差，建议用ab")]),t._v(" "),a("h5",{attrs:{id:"全文"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#全文"}},[t._v("#")]),t._v(" 全文")]),t._v(" "),a("p",[t._v("全文索引：只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时， 如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。")]),t._v(" "),a("p",[t._v("lunce、solr和ElasticSearch就是做全文检索的，里面涉及到了倒排索引的概念，mysql很少使用全文索引。")]),t._v(" "),a("p",[t._v("要用来查找文本中的关键字，不是直接与索引中的值相比较，像是一个搜索引擎，配合 match against 使用，现在只有char，varchar，text上可以创建索引，在数据量比较大时，先将数据放在一个没有全文索引的表里，然后在利用create index创建全文索引，比先生成全文索引在插入数据快很多。")]),t._v(" "),a("h5",{attrs:{id:"前缀"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前缀"}},[t._v("#")]),t._v(" 前缀")]),t._v(" "),a("p",[t._v("在文本类型如"),a("code",[t._v("CHAR")]),t._v(","),a("code",[t._v("VARCHAR")]),t._v(","),a("code",[t._v("TEXT")]),t._v("类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" table_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ADD")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v(" index_name "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("column1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("什么情况下使用前缀索引")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("字符串列(varchar,char,text等)，需要进行全字段匹配或者前匹配。也就是=‘xxx’ 或者 like ‘xxx%'")]),t._v(" "),a("li",[t._v("字符串本身可能比较长，而且前几个字符就开始不相同。比如我们对中国人的姓名使用前缀索引就没啥意义，因为中国人名字都很短，另外对收件地址使用前缀索引也不是很实用，因为一方面收件地址一般都是以XX省开头，也就是说前几个字符都是差不多的，而且收件地址进行检索一般都是like ’%xxx%’，不会用到前匹配。相反对外国人的姓名可以使用前缀索引，因为其字符较长，而且前几个字符的选择性比较高。同样电子邮件也是一个可以使用前缀索引的字段。")]),t._v(" "),a("li",[t._v("前一半字符的索引选择性就已经接近于全字段的索引选择性。如果整个字段的长度为20，索引选择性为0.9，而我们对前10个字符建立前缀索引其选择性也只有0.5，那么我们需要继续加大前缀字符的长度，但是这个时候前缀索引的优势已经不明显，没有太大的建前缀索引的必要了。")])]),t._v(" "),a("h3",{attrs:{id:"索引的使用与否"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引的使用与否"}},[t._v("#")]),t._v(" 索引的使用与否")]),t._v(" "),a("h5",{attrs:{id:"何时使用索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#何时使用索引"}},[t._v("#")]),t._v(" 何时使用索引")]),t._v(" "),a("p",[t._v("MySQL每次只使用一个索引，与其说数据库查询只能用一个索引，倒不如说，和全表扫描比起来，去分析两个索引 B+树更耗费时间，所以where A=a and B=b 这种查询使用（A，B）的组合索引最佳，B+树根据（A，B）来排序。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("多表join关联查询，on字段两边的字段都要创建索引")])]),t._v(" "),a("li",[a("p",[t._v("频繁出现在where 条件判断，order排序，group by分组字段")])]),t._v(" "),a("li",[a("p",[t._v("select 频繁查询的列，考虑是否需要创建联合索引（覆盖索引，不回表）")])]),t._v(" "),a("li",[a("p",[t._v("主键，unique字段")])]),t._v(" "),a("li",[a("p",[t._v("和其他表做连接的字段需要加索引")])]),t._v(" "),a("li",[a("p",[t._v("在where 里使用 >, >=, = , <, <=, is null 和 between等字段。")])]),t._v(" "),a("li",[a("p",[t._v("使用不以通配符开始的like，where A like ‘China%’")])]),t._v(" "),a("li",[a("p",[t._v("聚合函数里面的 MIN()， MAX()的字段")])]),t._v(" "),a("li",[a("p",[t._v("尽量创建组合索引，而不是单列索引。")]),t._v(" "),a("ul",[a("li",[t._v("1个组合索引等同于多个索引效果，节省空间。")]),t._v(" "),a("li",[t._v("可以使用覆盖索引创建原则：组合索引应该把把频繁的列，区分度高的值放在前面。频繁使用代表索引的利用率高， 区分度高代表筛选粒度大，可以尽量缩小筛选范围。")])])])]),t._v(" "),a("h5",{attrs:{id:"何时不使用索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#何时不使用索引"}},[t._v("#")]),t._v(" 何时不使用索引")]),t._v(" "),a("ul",[a("li",[t._v("表记录太少")]),t._v(" "),a("li",[t._v("数据重复且分布平均的字段（只有很少数据的列）；")]),t._v(" "),a("li",[t._v("经常插入、删除、修改的表要减少索引")]),t._v(" "),a("li",[a("code",[t._v("text")]),t._v("，"),a("code",[t._v("image")]),t._v(" 等类型不应该建立索引，这些列的数据量大（加入"),a("code",[t._v("text")]),t._v("的前10个字符唯一，也可以对"),a("code",[t._v("text")]),t._v("前10个字符建立索引）")]),t._v(" "),a("li",[t._v("MySQL能估计出全表扫描比使用索引更快的时候，不使用索引")]),t._v(" "),a("li",[t._v("区分度低的字段，不要建索引。")]),t._v(" "),a("li",[t._v("在"),a("code",[t._v("InnoDB")]),t._v("存储引擎中，主键索引建议使用自增的长整型，避免使用很长的字段")]),t._v(" "),a("li",[t._v("不建议用无序的值作为索引。例如身份证、UUID")])]),t._v(" "),a("h5",{attrs:{id:"索引何时失效"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引何时失效"}},[t._v("#")]),t._v(" 索引何时失效")]),t._v(" "),a("ul",[a("li",[t._v("组合索引为使用最左前缀，例如组合索引（A，B），where B = b 不会使用索引")]),t._v(" "),a("li",[t._v('like未使用最左前缀，where A  like "%China"')]),t._v(" "),a("li",[t._v("搜索一个索引而在另一个索引上做 order by， where A = a order by B，只会使用A上的索引，因为查询只使用一个索引。")]),t._v(" "),a("li",[t._v("or会使索引失效。如果查询字段相同，也可以使用索引。例如  where A = a1 or A = a2（生效），where A=a or B = b （失效）")]),t._v(" "),a("li",[t._v("不要进行这些操作：计算、函数、自动/手动类型转换，不然会导致索引失效而转向全表扫描,在索引列上的操作，函数upper()等，or、！ = （<>）,not in 等")]),t._v(" "),a("li",[t._v("索引字段上不要使用不等")]),t._v(" "),a("li",[t._v("索引字段上不要判断null")]),t._v(" "),a("li",[t._v("索引字段字符串要加单引号,不会进行自动类型转换")])]),t._v(" "),a("h3",{attrs:{id:"技术名词"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#技术名词"}},[t._v("#")]),t._v(" 技术名词")]),t._v(" "),a("h5",{attrs:{id:"回表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#回表"}},[t._v("#")]),t._v(" 回表")]),t._v(" "),a("p",[t._v("除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键值而非磁盘地址。")]),t._v(" "),a("p",[t._v("根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为回表查询")]),t._v(" "),a("p",[t._v("首先我们需要知道，我们建立几个索引，就会生成几棵B+Tree，但是带有原始数据行的B+Tree只有一棵，另外一棵树上的叶子节点带的是主键值。")]),t._v(" "),a("p",[t._v("例如，我们通过主键建立了主键索引，然后在叶子节点上存放的是我们的数据")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119459.png",alt:"image-20200629094621998"}})]),t._v(" "),a("p",[t._v("当我们创建了两个索引时，一个是主键，一个是name，它还会在生成一棵B+Tree，这棵树的叶子节点存放的是主键，当我们通过name进行查找的时候，会得到一个主键，然后在通过主键再去上面的这个主键B+Tree中进行查找，我们称这个操作为 =="),a("strong",[t._v("回表")]),t._v("==")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119096.png",alt:"image-20200629094800800"}})]),t._v(" "),a("p",[t._v("当我们的SQL语句使用的是下面这种的时候，它会查找第一颗树，直接返回我们的数据")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from tb where id = 1\n")])])]),a("p",[t._v("当我们使用下面这种查询的时候，它会先查找第二棵树得到我们的主键，然后拿着主键再去查询第一棵树")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from tb  where name = 'gang'\n")])])]),a("p",[t._v("回表就是通过普通列的索引进行检索，然后再去主键列进行检索，这个操作就是回表")]),t._v(" "),a("p",[t._v("但是我们在使用检索的时候，尽量避免回表，因为这会造成两次B+Tree的查询，假设一次B+Tree查询需要三次IO操作，那么查询两次B+Tree就需要六次IO操作。")]),t._v(" "),a("h5",{attrs:{id:"索引覆盖"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引覆盖"}},[t._v("#")]),t._v(" 索引覆盖")]),t._v(" "),a("p",[a("strong",[t._v("覆盖索引")]),t._v("（covering index ，或称为索引覆盖）即从非主键索引中就能查到的记录，而不需要查询主键索引中的记录，避免了回表的产生减少了树的搜索次数，显著提升性能。")]),t._v(" "),a("p",[t._v("对于使用了覆盖索引的查询，在查询前面使用"),a("code",[t._v("explain")]),t._v("，输出的extra列会显示为 "),a("code",[t._v("using index")]),t._v(" 。")]),t._v(" "),a("p",[a("strong",[t._v("哪些场景适合使用索引覆盖来优化SQL")])]),t._v(" "),a("ul",[a("li",[t._v("全表count查询优化")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select count(age) from user;\n")])])]),a("p",[t._v("使用索引覆盖优化：创建age字段索引")]),t._v(" "),a("ul",[a("li",[t._v("列查询回表优化")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select id,age,name from user where age = 10;\n")])])]),a("p",[t._v("使用索引覆盖：建组合索引idx_age_name(age,name)即可")]),t._v(" "),a("ul",[a("li",[t._v("分页查询")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select id,age,name from user order by age limit\n")])])]),a("p",[t._v("因为name字段不是索引，所以在分页查询需要进行回表查询\n使用索引覆盖：建组合索引idx_age_name(age,name)")]),t._v(" "),a("h5",{attrs:{id:"最左匹配"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#最左匹配"}},[t._v("#")]),t._v(" 最左匹配")]),t._v(" "),a("p",[t._v("这里提到的 "),a("strong",[t._v("最左匹配")]),t._v(" 和 "),a("strong",[t._v("索引下推")]),t._v(" 都是针对于组合索引的。")]),t._v(" "),a("p",[t._v("例如，我们有这样一个索引")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("name  age：组合索引\n")])])]),a("p",[t._v("必须要先匹配name，才能匹配到age。这个我们就被称为最左匹配")]),t._v(" "),a("p",[t._v("例如下面的几条SQL语句，那些语句不会使用组合索引")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("where name = ? and age = ?\nwhere name = ?\nwhere age = ?\nwhere age = ? and name = ?\n")])])]),a("p",[t._v("根据最左匹配原则，我们的 3 不会使用组合索引的。")]),t._v(" "),a("p",[t._v("那为什么4的顺序不一样，也会使用组合索引呢？")]),t._v(" "),a("p",[t._v("其实内部的优化器会进行调整，例如下面的一个连表操作")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from tb1 join tb2 on tb1.id = tb2.id\n")])])]),a("p",[t._v("其实在加载表的时候，并不一定是先加载tb1，在加载tb2，而是可能根据表的大小决定的，小的表优先加载进内存中。")]),t._v(" "),a("h5",{attrs:{id:"索引条件下推icp"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引条件下推icp"}},[t._v("#")]),t._v(" 索引条件下推ICP")]),t._v(" "),a("p",[t._v("在说索引下推的时候，我们首先在举两个例子")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from tb1 where name = ? and age = ?\n")])])]),a("p",[t._v("在mysq 5.6之前，会先根据name去存储引擎中拿到所有的数据，然后在server层对age进行数据过滤")]),t._v(" "),a("p",[t._v("在mysql5.6之后，根据name 和 age两个列的值去获取数据，直到把数据返回。")]),t._v(" "),a("p",[t._v("通过对比能够发现，第一个的效率低，第二个的效率高，因为整体的IO量少了，原来是把数据查询出来，在server层进行筛选，而现在在存储引擎层面进行筛选，然后返回结果。我们把这个过程就称为 "),a("strong",[t._v("索引下推")])]),t._v(" "),a("p",[t._v("ICP的目的是为了减少回表次数，可用于 InnoDB 和 MyISAM 表，对于InnoDB表ICP仅用于辅助索引（非聚簇索引）。")]),t._v(" "),a("p",[a("strong",[t._v("不使用ICP，不满足最左前缀的索引条件的比较是在存储引擎层进行的，非索引条件的比较是在Server 层进行的。 使用ICP，所有的索引条件的比较是在存储引擎层进行的，非索引条件的比较是在Server层进行的。")])]),t._v(" "),a("p",[t._v("对比使用ICP和不使用ICP，可以看到使用ICP可以有效减少回表查询次数和返回给服务层的记录数，从 而减少了磁盘IO次数和服务层与存储引擎的交互次数。")]),t._v(" "),a("h3",{attrs:{id:"索引匹配方式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引匹配方式"}},[t._v("#")]),t._v(" 索引匹配方式")]),t._v(" "),a("p",[a("strong",[t._v("全值匹配")])]),t._v(" "),a("p",[t._v("全值匹配指的是和索引中所有的列进行匹配")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select * from staffs where name = 'July' and age = 23 and pos = 'dev'\n")])])]),a("p",[t._v("而我们建立了一个 包含  name、age、pos的组合索引，使用上面的SQL语句，就会进行全值匹配")]),t._v(" "),a("p",[a("strong",[t._v("匹配最左前缀")])]),t._v(" "),a("p",[t._v("只匹配前面的几列")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select * from staffs where name = 'July' and age = 23\n")])])]),a("p",[t._v("这个时候，只使匹配了前面两个列，而没有使用第三个列")]),t._v(" "),a("p",[t._v("现在我们使用下面的SQL语句进行验证，但我们输出值只包含ID的时候")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select id from staffs where id = \n")])])]),a("p",[t._v("我们查看其任务计划，在某尾有 Extra字段，如果是Using index 表示是使用了覆盖索引")]),t._v(" "),a("p",[t._v("然后我们在查看下面这条SQL语句")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select * from staffs where id = 1\n")])])]),a("p",[t._v("通过查看任务计划，发现extra字段是NULL，说明没有使用覆盖索引")]),t._v(" "),a("p",[a("strong",[t._v("匹配列前缀")])]),t._v(" "),a("p",[t._v("可以匹配某一列值的开头部分")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select * from staffs where name = 'J%'\nexplain select * from staffs where name = '%y'\n")])])]),a("p",[a("strong",[t._v("匹配范围值")])]),t._v(" "),a("p",[t._v("可以查找某个范围的数据")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("explain select * from staffs where name > 'Mary'\n")])])]),a("p",[t._v("精确匹配某一列并范围匹配另外一列")]),t._v(" "),a("p",[t._v("可以查询某一列的全部和第二列的部分")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('explain select * from staffs where name = "July" and age > 25\n')])])]),a("p",[a("strong",[t._v("只访问索引的查询")])]),t._v(" "),a("p",[t._v("查询的时候值需要访问索引，不需要访问数据行，本质上就是索引覆盖")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('explain select name,age,pos from staffs where name="July" and age=25 and pos = "dev"\n')])])]),a("h4",{attrs:{id:"哈希索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#哈希索引"}},[t._v("#")]),t._v(" 哈希索引")]),t._v(" "),a("p",[t._v("基于哈希的实现，只有精确匹配索引所有的列的查询才有效，在mysql中，只有memory的存储引擎显式支持哈希索引，哈希索引自身只需存储对应的hash值，索引索引的结构十分紧凑，这让哈希索引查找的速度非常快。")]),t._v(" "),a("p",[a("strong",[t._v("哈希索引的限制")])]),t._v(" "),a("ul",[a("li",[t._v("哈希索引值包含哈希值和行指针，而不存储字段值。索引不能使用索引中的值来避免读取行")]),t._v(" "),a("li",[t._v("哈希索引数据并不是按照索引值顺序存储的，所以无法进行排序")]),t._v(" "),a("li",[t._v("哈希索引不支持部分列匹配查找，哈希索引是使用索引列的全部内容来计算哈希值")]),t._v(" "),a("li",[t._v("哈希索引支持等值比较查询，也不支持任何范围查询")]),t._v(" "),a("li",[t._v("访问哈希索引的数据非常快，除非有很多哈希冲突，当出现哈希冲突的时候，存储引擎必须遍历链表中的所有行指针，逐行进行比较，知道找到所有符合条件的行")]),t._v(" "),a("li",[t._v("哈希冲突比较多的话，维护的代价也会很高")])]),t._v(" "),a("h3",{attrs:{id:"b树和b-树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#b树和b-树"}},[t._v("#")]),t._v(" B树和B+树")]),t._v(" "),a("p",[t._v("B树")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119240.png",alt:"image-20220424151900363"}})]),t._v(" "),a("p",[a("strong",[t._v("B树的缺点：")])]),t._v(" "),a("ul",[a("li",[t._v("B树不支持范围查询的快速查找，如果我们想要查找15和26之间的数据，查找到15之后，需要回 到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。")]),t._v(" "),a("li",[t._v("如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中 可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。")])]),t._v(" "),a("p",[t._v("B+树")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("B树：非叶子节点和叶子节点都会存储数据。")])]),t._v(" "),a("li",[a("p",[t._v("B+树：只有叶子节点才会存储数据，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶 子节点形成了一个双向有序链表。")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119274.png",alt:"image-20220424152210119"}})]),t._v(" "),a("h3",{attrs:{id:"聚簇索引和非聚簇索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#聚簇索引和非聚簇索引"}},[t._v("#")]),t._v(" 聚簇索引和非聚簇索引")]),t._v(" "),a("h5",{attrs:{id:"聚簇索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#聚簇索引"}},[t._v("#")]),t._v(" 聚簇索引")]),t._v(" "),a("p",[t._v("聚簇索引不是一种单独的索引类型，而是"),a("strong",[t._v("一种数据的存储方式，聚簇索引的顺序，就是数据在硬盘上的物理顺序")]),t._v("。")]),t._v(" "),a("p",[a("strong",[t._v("聚簇索引的优点")])]),t._v(" "),a("ul",[a("li",[t._v("数据访问更快，因为聚簇索引将索引和数据保存在一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快")]),t._v(" "),a("li",[t._v("聚簇索引对主键的排序和范围查找速度非常快")])]),t._v(" "),a("p",[a("strong",[t._v("聚簇索引的缺点")])]),t._v(" "),a("ul",[a("li",[t._v("插入速度严重依赖于排序，按照主键的顺序插入是最快的方式，否者会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列作为主键")]),t._v(" "),a("li",[t._v("更新主键的代价很高，因为将会导致被更新的行移动，因此，对于InnoDB表，我们一般定义主键不可更新")]),t._v(" "),a("li",[t._v("二级索引访问需要两次索引查找，第一次找到主键值，第二次 根据主键值查找行数据，一般我们需要尽量避免出现索引的二次查找，这个时候，用到的就是"),a("strong",[t._v("索引的覆盖")])])]),t._v(" "),a("h5",{attrs:{id:"非聚簇索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#非聚簇索引"}},[t._v("#")]),t._v(" 非聚簇索引")]),t._v(" "),a("p",[t._v("非聚簇索引也被称为辅助索引，辅助索引在我们访问数据的时候总是需要两次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到主键值，然后在通过主键值找到数据行的数据页，在通过数据页中的Page Directory找到数据行。")]),t._v(" "),a("p",[t._v("InnoDB辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，还包含了行数据的聚簇索引建。辅助索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个辅助索引。在InnoDB中有时也称为辅助索引为二级索引")]),t._v(" "),a("h3",{attrs:{id:"索引常见问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引常见问题"}},[t._v("#")]),t._v(" 索引常见问题")]),t._v(" "),a("h5",{attrs:{id:"为什么索引结构默认使用b-tree，而不是b-tree，hash，二叉树，红黑树？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么索引结构默认使用b-tree，而不是b-tree，hash，二叉树，红黑树？"}},[t._v("#")]),t._v(" 为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树？")]),t._v(" "),a("p",[t._v("B-tree： 从两个方面来回答")]),t._v(" "),a("ul",[a("li",[t._v("B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对"),a("code",[t._v("IO读写次数就降低")]),t._v("了。")]),t._v(" "),a("li",[t._v("由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在"),a("code",[t._v("区间查询")]),t._v("的情况，所以通常B+树用于数据库索引。")])]),t._v(" "),a("p",[t._v("Hash：")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("虽然可以快速定位，但是没有顺序，IO复杂度高；")])]),t._v(" "),a("li",[a("p",[t._v("基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；")])]),t._v(" "),a("li",[a("p",[t._v("适合"),a("strong",[t._v("等值查询")]),t._v("，如=、in()、<=>，不支持范围查询 ；")])]),t._v(" "),a("li",[a("p",[t._v("因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成排序")])]),t._v(" "),a("li",[a("p",[t._v("Hash索引在查询等值时非常快 ；")])]),t._v(" "),a("li",[a("p",[t._v("因为Hash索引始终索引的"),a("strong",[t._v("所有列的全部内容")]),t._v("，所以不支持部分索引列的匹配查找 ；")])]),t._v(" "),a("li",[a("p",[t._v("如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。")])])]),t._v(" "),a("p",[t._v("二叉树： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。")]),t._v(" "),a("p",[t._v("红黑树： 树的高度随着数据量增加而增加，IO代价高。")]),t._v(" "),a("h5",{attrs:{id:"b树和b-树的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#b树和b-树的区别"}},[t._v("#")]),t._v(" B树和B+树的区别")]),t._v(" "),a("p",[t._v("B树和B+树最主要的区别主要有两点：")]),t._v(" "),a("ul",[a("li",[t._v("B树中的内部节点和叶子节点均存放键和值，而B+树的内部节点只有键没有值，叶子节点存放所有 的键和值。")]),t._v(" "),a("li",[t._v("B＋树的叶子节点是通过相连在一起的，方便顺序检索。")])]),t._v(" "),a("h5",{attrs:{id:"为什么是b-树而不是b树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么是b-树而不是b树"}},[t._v("#")]),t._v(" 为什么是B+树而不是B树")]),t._v(" "),a("p",[t._v("上面我们提到的B+树所完成的工作，B树也能完成？为什么MySQL中的索引大多使用B+树而不是B树呢？有以下几个原因：")]),t._v(" "),a("ul",[a("li",[t._v("首先B+树的"),a("strong",[t._v("空间利用率更高")]),t._v("（非叶节点没有data域），可减少IO次数，磁盘读写所耗费的代价更低；")]),t._v(" "),a("li",[t._v("B+树的"),a("strong",[t._v("查询效率更加地稳定")]),t._v("，B树搜索在非叶子节点还是叶子节点结束都有可能，越靠近根节点，查找效率越快；而B+树无论查找的是什么数据，最终都需要从根节点一直走向叶节点，所有查找所经过的次数都是一样的；")]),t._v(" "),a("li",[t._v("B+树能"),a("strong",[t._v("同时支持随机检索和顺序检索")]),t._v("，而B树只适合随机检索，顺序检索的效率比B+树低；")]),t._v(" "),a("li",[t._v("增删文件时，B+树的效率更高，因为所有的data都在叶子节点中，而B树删减节点时还需要分裂，中间节点向上等操作；")])]),t._v(" "),a("p",[a("strong",[t._v("那Hash索引呢？")])]),t._v(" "),a("p",[t._v("Hash索引更容易理解，底层就是Hash表，调用一次hash函数就可以直接确定相应键值，之后进行回表查询实际数据，按理说Hash索引比B+树还高效？为什么不使用Hash索引呢？原因有以下几点：")]),t._v(" "),a("ul",[a("li",[t._v("Hash索引"),a("strong",[t._v("不支持区间查找")]),t._v("，类似"),a("code",[t._v("select * form table where age > 10")]),t._v("这种查找，对于Hash来说，XX；")]),t._v(" "),a("li",[t._v("Hash索引"),a("strong",[t._v("不支持模糊查询")]),t._v("，像"),a("code",[t._v("JoinX")]),t._v("和"),a("code",[t._v("JoinA")]),t._v("之间没有关联性，原因在于Hash函数的不可预测；")]),t._v(" "),a("li",[t._v("Hash索引在等值查询上很快，但是"),a("strong",[t._v("却不稳定")]),t._v("，hash索引还有一个重要的问题，hash碰撞，"),a("strong",[t._v("当发生hash碰撞时，某个键值大量重复时，效率变得极差")]),t._v("；")])]),t._v(" "),a("h5",{attrs:{id:"为什么mysql-innoddb中组合索引中范围查询后的条件索引会失效？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么mysql-innoddb中组合索引中范围查询后的条件索引会失效？"}},[t._v("#")]),t._v(" 为什么mysql innodDB中组合索引中范围查询后的条件索引会失效？")]),t._v(" "),a("p",[t._v("表建立联合索引(a,b,c)，查询条件a=1,b>2,c=3，此时为什么c条件的索引会失效？")]),t._v(" "),a("p",[t._v("inno db的联合索引是按照字段顺序进行组合的。")]),t._v(" "),a("p",[t._v("例子中，(a,b,c)的可以理解为索引键则为a_b_c，对于查询的a=1,b>2,c=3。字段a肯定会用到，因为能够定位到具体的值，对于b也会用到，因为b之前的a值是指定的；但是对于c=3，那么就没有办法使用到，因为c之前的a/b值是不固定。")]),t._v(" "),a("p",[t._v("例如存在索引数据(a=1,b=3,c=3)，(a=1,b=4,c=0)，(a=1,b=4,c=3)，(a=1,b=4,c=0)是位于中间的，但是却是不满足条件的，但是没有办法通过索引进行过滤，所以字段c并不能够参与到索引刷选中。")]),t._v(" "),a("h5",{attrs:{id:"为什么一个节点为一页16k就够了（一棵树可以存放多少行数据）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么一个节点为一页16k就够了（一棵树可以存放多少行数据）"}},[t._v("#")]),t._v(" 为什么一个节点为一页16K就够了（一棵树可以存放多少行数据）")]),t._v(" "),a("p",[t._v("1、数据持久化存储磁盘里，磁盘的最小单元是扇区，"),a("code",[t._v("一个扇区的大小是 512个字节")]),t._v("；")]),t._v(" "),a("p",[t._v("2、文件系统的最小单元是块，"),a("code",[t._v("一个块的大小是 4K")]),t._v("；")]),t._v(" "),a("p",[t._v("3、InnoDB存储引擎，有自己的最小单元，称之为页，"),a("code",[t._v("一个页的大小是16K")]),t._v("。")]),t._v(" "),a("p",[t._v("页是 InnoDB 磁盘管理的最小单位，在 InnoDB 存储引擎中，默认每个页的大小为 16KB。而页里面存放的东西就是一行一行的记录")]),t._v(" "),a("p",[t._v("在实际生产环境中，InnoDB 中一棵 B+ 树索引一般是 "),a("strong",[t._v("2 ~ 3 层")]),t._v("，可以存放约 "),a("strong",[t._v("两千万行")]),t._v(" 的数据")]),t._v(" "),a("p",[t._v("回到文题，我们先从简单的入手，假设 B+ 树只有两层，即一个根节点和若干个叶子节点，如下图：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119159.webp",alt:"图片"}})]),t._v(" "),a("p",[a("strong",[t._v("那么对于这棵 B+ 树能够存放多少行数据，其实问的就是这棵 B+ 树的非叶子节点中存放的数据量")]),t._v("，可以通过下面这个简单的公式来计算：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("这棵B+树的存储总记录数 = 根节点指针数 * 每个叶子节点存放的行记录数")])])]),t._v(" "),a("p",[t._v("每个叶子节点存放的行记录数就是每页存放的记录数，由于各个数据表中的字段数量都不一样，这里我们就不深究叶子节点的存储结构了，简单按照一行记录的数据大小为 1k 来算的话（实际上现在很多互联网业务数据记录大小通常就是 1K 左右），一页或者说一个叶子节点可以存放 16 行这样的数据。")]),t._v(" "),a("p",[a("strong",[t._v("那么 B+ 数的根节点（非叶子节点）能够存储多少数据呢？")])]),t._v(" "),a("p",[t._v("非叶子节点里面存的是主键值 + 指针，我们假设主键的类型是 BigInt，长度为 8 字节，而指针大小在 InnoDB 中设置为 6 字节，这样一共 14 字节。")]),t._v(" "),a("p",[t._v("为了方便行文，这里我们把一个主键值 + 一个指针称为一个单元，这样的话，一页或者说一个非叶子节点能够存放 16384 / 14=1170 个这样的单元。")]),t._v(" "),a("p",[t._v("也就是说一个非叶子节点中能够存放 1170 个指针，即对应 1170 个叶子节点，所以对于这样一棵高度为 2 的 B+ 树，能存放 1170（一个非叶子节点中的指针数） * 16（一个叶子节点中的行数）= 18720 行数据。")]),t._v(" "),a("p",[t._v("当然，这样分析其实不是很严谨，按照 《MySQL 技术内幕：InnoDB 存储引擎》中的定义，InnoDB 数据页结构包含如下几个部分：")]),t._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119125.webp",alt:"图片"}}),t._v(" "),a("p",[t._v("OK，分析完高度为 2 的 B+ 树，同样的道理，我们来看高度为 3 的：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119251.webp",alt:"图片"}})]),t._v(" "),a("p",[t._v("根页（page10）可以存放 1170 个指针，然后第二层的每个页（page:11,12,13）也都分别可以存放1170个指针。这样一共可以存放 "),a("code",[t._v("1170 * 1170")]),t._v(" 个指针，即对应的有 "),a("code",[t._v("1170 * 1170")]),t._v(" 个非叶子节点，所以一共可以存放 "),a("code",[t._v("1170 * 1170 * 16 = 21902400")]),t._v(" 行记录。")]),t._v(" "),a("blockquote",[a("p",[t._v("千万级的数据存储只需要约3层B+树，查询数据时，每加载一页（page）代表一次IO。所以说，根据主键id索引查询约3次IO便可以找到目标结果。")])]),t._v(" "),a("h2",{attrs:{id:"锁"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#锁"}},[t._v("#")]),t._v(" 锁")]),t._v(" "),a("h3",{attrs:{id:"什么是数据库的锁"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是数据库的锁"}},[t._v("#")]),t._v(" 什么是数据库的锁")]),t._v(" "),a("p",[t._v("当数据库有并发事务的时候，保证数据访问顺序的机制称为锁机制。")]),t._v(" "),a("h3",{attrs:{id:"数据库的锁与隔离级别的关系？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库的锁与隔离级别的关系？"}},[t._v("#")]),t._v(" 数据库的锁与隔离级别的关系？")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("隔离级别")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("实现方式")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("未提交读")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("总是读取最新的数据，无需加锁")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("提交读")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("读取数据时加共享锁，读取数据后释放共享锁")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("可重复读")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("读取数据时加共享锁，事务结束后释放共享锁")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("串行化")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("锁定整个范围的键，一直持有锁直到事务结束")])])])]),t._v(" "),a("h3",{attrs:{id:"数据库锁的类型有哪些"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库锁的类型有哪些"}},[t._v("#")]),t._v(" 数据库锁的类型有哪些")]),t._v(" "),a("p",[a("strong",[t._v("按照锁的粒度可以将MySQL锁分为三种：")])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"center"}},[t._v("MySQL锁类别")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("资源开销")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("加锁速度")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("是否会出现死锁")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("锁的粒度")]),t._v(" "),a("th",{staticStyle:{"text-align":"center"}},[t._v("并发度")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("表级锁")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("小")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("快")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不会")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("大")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("低")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("行级锁")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("大")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("慢")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("会")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("小")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("高")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"center"}},[t._v("页面锁")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("一般")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("一般")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("不会")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("一般")]),t._v(" "),a("td",{staticStyle:{"text-align":"center"}},[t._v("一般")])])])]),t._v(" "),a("p",[t._v("MyISAM默认采用表级锁，InnoDB默认采用行级锁。")]),t._v(" "),a("p",[a("strong",[t._v("从锁的类别上区别可以分为共享锁和排他锁")])]),t._v(" "),a("ul",[a("li",[t._v("共享锁：共享锁又称读锁，简写为S锁，一个事务对一个数据对象加了S锁，可以对这个数据对象进行读取操作，但不能进行更新操作。并且在加锁期间其他事务只能对这个数据对象加S锁，不能加X锁；")]),t._v(" "),a("li",[t._v("排他锁：排他锁又称为写锁，简写为X锁，一个事务对一个数据对象加了X锁，可以对这个对象进行读取和更新操作，加锁期间，其他事务不能对该数据对象进行加X锁或S锁。")])]),t._v(" "),a("h3",{attrs:{id:"mysql中innodb引擎的行锁模式及其是如何实现的？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql中innodb引擎的行锁模式及其是如何实现的？"}},[t._v("#")]),t._v(" MySQL中InnoDB引擎的行锁模式及其是如何实现的？")]),t._v(" "),a("p",[a("strong",[t._v("行锁模式")])]),t._v(" "),a("p",[t._v("在存在行锁和表锁的情况下，一个事务想对某个表加X锁时，需要先检查是否有其他事务对这个表加了锁 或对这个表的某一行加了锁，对表的每一行都进行检测一次这是非常低效率的，为了解决这种问题，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁，两种意向锁都是表锁。")]),t._v(" "),a("ul",[a("li",[t._v("意向共享锁：简称IS锁，一个事务打算给数据行加共享锁前必须先获得该表的IS锁。")]),t._v(" "),a("li",[t._v("意向排他锁：简称IX锁，一个事务打算给数据行加排他锁前必须先获得该表的IX锁")])]),t._v(" "),a("p",[t._v("有了意向锁，一个事务想对某个表加X锁，只需要检查是否有其他事务对这个表加了X/IX/S/IS锁即可")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119696.png",alt:"image-20220424173948834"}})]),t._v(" "),a("p",[t._v("行锁实现方式：INnoDB的行锁是通过给索引上的索引项加锁实现的，如果没有索引，InnoDB将通过隐 藏的聚簇索引来对记录进行加锁")]),t._v(" "),a("p",[a("strong",[t._v("InnoDB行锁")]),t._v("是通过给索引上的"),a("strong",[t._v("索引项加锁")]),t._v("来实现的，因此InnoDB这种行锁实现特点意味着："),a("strong",[t._v("只有通过索引条件检索的数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！")])]),t._v(" "),a("p",[a("strong",[t._v("InnoDB行锁主要分三种情况：")])]),t._v(" "),a("ul",[a("li",[t._v("Record lock：对索引项加锁")]),t._v(" "),a("li",[t._v("Grap lock：对索引之间的“间隙”、第一条记录前的“间隙”或最后一条后的间隙加锁。")]),t._v(" "),a("li",[t._v("Next-key lock：前两种放入组合，对记录及前面的间隙加锁。")])]),t._v(" "),a("p",[t._v("InnoDB行锁的特性：如果不通过索引条件检索数据，那么InnoDB将对表中所有记录加锁，实际产生的效果和表锁是一样的。")]),t._v(" "),a("h5",{attrs:{id:"记录锁-record-locks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#记录锁-record-locks"}},[t._v("#")]),t._v(" 记录锁(Record Locks)")]),t._v(" "),a("ol",[a("li",[t._v("记录锁, 仅仅锁住索引记录的一行，在单条索引记录上加锁。")]),t._v(" "),a("li",[t._v("record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。")])]),t._v(" "),a("p",[t._v("所以说当一条sql没有走任何索引时，那么将会在每一条聚合索引后面加X锁，这个类似于表锁，但原理 上和表锁应该是完全不同的。")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("-- 加记录共享锁\nselect * from t1_simple where id = 1 lock in share mode;\n-- 加记录排它锁\nselect * from t1_simple where id = 1 for update;\n")])])]),a("h5",{attrs:{id:"间隙锁-gap-locks）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#间隙锁-gap-locks）"}},[t._v("#")]),t._v(" 间隙锁(Gap Locks）")]),t._v(" "),a("ol",[a("li",[t._v("区间锁, 仅仅锁住一个索引区间（开区间，不包括双端端点）。")]),t._v(" "),a("li",[t._v("在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。")]),t._v(" "),a("li",[t._v("间隙锁可用于防止幻读，保证索引间的不会被插入数据")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119933.png",alt:"image-20220426140418265"}})]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("session1:\nbegin;\nselect * from t1_simple where id > 4 for update;\n---------------------------------------------------------\nsession2:\ninsert into t1_simple values (7,100); --阻塞\ninsert into t1_simple values (3,100); --成功\n\n")])])]),a("h5",{attrs:{id:"临键锁-next-key-locks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#临键锁-next-key-locks"}},[t._v("#")]),t._v(" 临键锁(Next-Key Locks)")]),t._v(" "),a("ol",[a("li",[t._v("record lock + gap lock, 左开右闭区间，例如（5,8]。")]),t._v(" "),a("li",[t._v("默认情况下，innodb使用next-key locks来锁定记录。select … for update")]),t._v(" "),a("li",[t._v("但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。")]),t._v(" "),a("li",[t._v("Next-Key Lock在不同的场景中会退化:")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119788.png",alt:"image-20220426140715920"}})]),t._v(" "),a("p",[t._v("当前数据库中的记录信息：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("mysql> select * from t1_simple;\n+-----+---------+\n| id | pubtime |\n+-----+---------+\n| 10 | 1 |\n| 13 | 1 |\n| 4 | 3 |\n| 11 | 4 |\n| 8 | 5 |\n| 12 | 9 |\n| 1 | 10 |\n| 100 | 20 |\n| 6 | 100 |\n+-----+---------+\n")])])]),a("p",[t._v("session1执行：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("begin;\nselect * from t1_simple where pubtime = 20 for update;\n-- 间隙锁区间(10,20],(20,100]\n")])])]),a("p",[t._v("session2执行：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("insert into t1_simple values (16, 19); --阻塞\nselect * from t1_simple where pubtime = 20 for update; --阻塞\ninsert into t1_simple values (16, 50); --阻塞\ninsert into t1_simple values (16, 101); --成功\n")])])]),a("h4",{attrs:{id:"行锁加锁规则"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#行锁加锁规则"}},[t._v("#")]),t._v(" 行锁加锁规则")]),t._v(" "),a("p",[t._v("1）主键索引")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("等值查询")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("命中记录，加记录锁。")])]),t._v(" "),a("li",[a("p",[t._v("未命中记录，加间隙锁。")])])])]),t._v(" "),a("li",[a("p",[t._v("范围查询")]),t._v(" "),a("ul",[a("li",[t._v("没有命中任何一条记录时，加间隙锁。")]),t._v(" "),a("li",[t._v("命中1条或者多条，包含where条件的临键区间，加临键锁")])])])]),t._v(" "),a("p",[t._v("2）辅助索引")]),t._v(" "),a("ul",[a("li",[t._v("等值查询\n"),a("ul",[a("li",[t._v("命中记录，命中记录的辅助索引项+主键索引项加记录锁，辅助索引项两侧加间隙锁。")]),t._v(" "),a("li",[t._v("未命中记录，加间隙锁")])])]),t._v(" "),a("li",[t._v("范围查询\n"),a("ul",[a("li",[t._v("没有命中任何一条记录时，加间隙锁。")]),t._v(" "),a("li",[t._v("命中1条或者多条，包含where条件的临键区间加临键锁。命中记录的id索引项加记录锁。")])])])]),t._v(" "),a("p",[a("strong",[t._v("MVCC不能解决幻读问题，在可重复读隔离级别下，使用MVCC+Next-Key Locks可以解决幻读问题")])]),t._v(" "),a("h3",{attrs:{id:"行锁原理分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#行锁原理分析"}},[t._v("#")]),t._v(" 行锁原理分析")]),t._v(" "),a("p",[t._v("待补充，因为太多了，而且应该不考，作为了解")]),t._v(" "),a("h3",{attrs:{id:"什么是数据库的乐观锁和悲观锁，如何实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是数据库的乐观锁和悲观锁，如何实现"}},[t._v("#")]),t._v(" 什么是数据库的乐观锁和悲观锁，如何实现")]),t._v(" "),a("p",[a("strong",[t._v("乐观锁")]),t._v("：系统假设数据的更新在大多数时候是不会产生冲突的，所以数据库只在更新操作提交的时候对 数据检测冲突，如果存在冲突，则数据更新失败。")]),t._v(" "),a("p",[t._v("乐观锁实现方式：一般通过版本号和CAS算法实现。")]),t._v(" "),a("p",[a("strong",[t._v("悲观锁")]),t._v("：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。通俗讲就是每次去拿数据的时候 都认为别人会修改，所以每次在拿数据的时候都会上锁。")]),t._v(" "),a("p",[t._v("悲观锁的实现方式：通过数据库的锁机制实现，对查询语句添加for updata。")]),t._v(" "),a("h3",{attrs:{id:"什么是死锁？如何避免"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是死锁？如何避免"}},[t._v("#")]),t._v(" 什么是死锁？如何避免")]),t._v(" "),a("p",[t._v("死锁是指两个或者两个以上进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。在MySQL中，MyISAM是一次获得所需的全部锁，要么全部满足，要么等待，所以不会出现死锁。 在InnoDB存储引擎中，除了单个SQL组成的事务外，锁都是逐步获得的，所以存在死锁问题。")]),t._v(" "),a("p",[a("strong",[t._v("死锁的例子")])]),t._v(" "),a("p",[t._v("每个事务执行两条SQL，分别持有了一把锁，然后加另一把锁，产生死锁")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119953.png",alt:"image-20220424190501820"}})]),t._v(" "),a("h3",{attrs:{id:"如何避免mysql发生死锁或锁冲突（优化锁的方式）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何避免mysql发生死锁或锁冲突（优化锁的方式）"}},[t._v("#")]),t._v(" 如何避免MySQL发生死锁或锁冲突（优化锁的方式）")]),t._v(" "),a("ul",[a("li",[t._v("如果不同的程序并发存取多个表，尽量以相同的顺序访问表。")]),t._v(" "),a("li",[t._v("在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录")]),t._v(" "),a("li",[t._v("在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁")]),t._v(" "),a("li",[t._v("尽量使用较低的隔离级别")]),t._v(" "),a("li",[t._v("尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会")]),t._v(" "),a("li",[t._v("合理选择事务的大小，小事务发生锁冲突的概率更低")]),t._v(" "),a("li",[t._v("尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。")]),t._v(" "),a("li",[t._v("不要申请超过实际需要的锁级别，查询时尽量不要显示加锁")]),t._v(" "),a("li",[t._v("对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。")]),t._v(" "),a("li",[t._v("数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别")])]),t._v(" "),a("h2",{attrs:{id:"日志"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#日志"}},[t._v("#")]),t._v(" 日志")]),t._v(" "),a("p",[t._v("MySQL日志主要包括查询日志、慢查询日志、事务日志、错误日志、二进制日志等。其中比较重要的是 "),a("code",[t._v("bin log")]),t._v("（二进制日志）和 "),a("code",[t._v("redo log")]),t._v("（重做日志）和 "),a("code",[t._v("undo log")]),t._v("（回滚日志）。")]),t._v(" "),a("h3",{attrs:{id:"bin-log"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bin-log"}},[t._v("#")]),t._v(" bin log")]),t._v(" "),a("p",[t._v("二进制日志（bin log）是MySQL数据库级别的文件，记录对MySQL数据库执行修改的所有操作，不会记录select和show语句，主要用于恢复数据库和同步数据库。")]),t._v(" "),a("h3",{attrs:{id:"redo-log"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redo-log"}},[t._v("#")]),t._v(" redo log")]),t._v(" "),a("p",[t._v("重做日志（redo log）是Innodb引擎级别，用来记录Innodb存储引擎的事务日志，不管事务是否提交都会记录下来，用于数据恢复。当数据库发生故障，InnoDB存储引擎会使用redo log恢复到发生故障前的时刻，以此来保证数据的完整性。将参数 innodb_flush_log_at_tx_commit 设置为1，那么在执行 commit时会将redo log同步写到磁盘。")]),t._v(" "),a("p",[t._v("系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。")]),t._v(" "),a("h3",{attrs:{id:"undo-log"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#undo-log"}},[t._v("#")]),t._v(" undo log")]),t._v(" "),a("p",[t._v("除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它保留了记录修改前的内容。通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，"),a("strong",[t._v("实现MVCC")]),t._v("。")]),t._v(" "),a("h3",{attrs:{id:"bin-log和redo-log有什么区别？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bin-log和redo-log有什么区别？"}},[t._v("#")]),t._v(" bin log和redo log有什么区别？")]),t._v(" "),a("ul",[a("li",[t._v("bin log会记录所有日志记录，包括innoDB、MyISAM等存储引擎的日志；redo log只记录innoDB 自身的事务日志。")]),t._v(" "),a("li",[t._v("bin log只在事务提交前写入到磁盘，一个事务只写一次；而在事务进行过程，会有redo log不断写入磁盘。")]),t._v(" "),a("li",[t._v("binlog 是逻辑日志，记录的是SQL语句的原始逻辑；redo log 是物理日志，记录的是在某个数据页上做了什么修改。")])]),t._v(" "),a("h4",{attrs:{id:"如何解决-bin-log-与-redo-log-的一致性问题（3种问法）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何解决-bin-log-与-redo-log-的一致性问题（3种问法）"}},[t._v("#")]),t._v(" 如何解决 bin log 与 redo log 的一致性问题（3种问法）")]),t._v(" "),a("p",[a("strong",[t._v("为什么说 redo log 具有崩溃恢复的能力")])]),t._v(" "),a("p",[t._v("前面我们说过，MySQL Server 层拥有的 bin log 只能用于归档，不足以实现崩溃恢复（crash-safe），需要借助 InnoDB 引擎的 redo log 才能拥有崩溃恢复的能力。所谓崩溃恢复就是：即使在数据库宕机的情况下，也不会出现操作一半的情况")]),t._v(" "),a("p",[t._v("至于为什么说 redo log 具有崩溃恢复的能力，而 bin log 没有，我们先来简单看一下这两种日志有哪些不同点：")]),t._v(" "),a("p",[t._v("1）"),a("strong",[t._v("适用对象不同")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("bin log 是 MySQL 的 Server 层实现的，所有引擎都可以使用")]),t._v(" "),a("li",[t._v("而 redo log 是 InnoDB 引擎特有的")])]),t._v(" "),a("p",[t._v("2）"),a("strong",[t._v("写入内容不同")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("bin log 是逻辑日志，记录的是这个语句的原始逻辑，比如 “给 id = 1 这一行的 age 字段加 1”")]),t._v(" "),a("li",[t._v("redo log 是物理日志，记录的是 “在某个数据页上做了什么修改”")])]),t._v(" "),a("p",[t._v("3）"),a("strong",[t._v("写入方式不同")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("bin log 是可以追加写入的。“追加写” 是指 bin log 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志")]),t._v(" "),a("li",[t._v("redo log 是循环写的，空间固定会被用完")])]),t._v(" "),a("p",[t._v("可以看到，redo log 和 bin log 的一个很大的区别就是，一个是循环写，一个是追加写。也就是说 redo log 只会记录未刷入磁盘的日志，已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。")]),t._v(" "),a("p",[t._v("而 bin log 是追加日志，保存的是全量的日志。这就会导致一个问题，那就是没有标志能让 InnoDB 从 bin log 中判断哪些数据已经刷入磁盘了，哪些数据还没有。")]),t._v(" "),a("p",[t._v("举个例子，bin log 记录了两条日志：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[t._v("记录 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("：给 id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" 这一行的 age 字段加 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n记录 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("：给 id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" 这一行的 age 字段加 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("p",[t._v("假设在记录 1 刷盘后，记录 2 未刷盘时，数据库崩溃。重启后，只通过 bin log 数据库是无法判断这两条记录哪条已经写入磁盘，哪条没有写入磁盘，不管是两条都恢复至内存，还是都不恢复，对 id = 1 这行数据来说，都是不对的。")]),t._v(" "),a("p",[t._v("但 redo log 不一样，只要刷入磁盘的数据，都会从 redo log 中被抹掉，数据库重启后，直接把 redo log 中的数据都恢复至内存就可以了。")]),t._v(" "),a("p",[t._v("这就是为什么说 redo log 具有崩溃恢复的能力，而 bin log 不具备。")]),t._v(" "),a("p",[a("strong",[t._v("redo log 两阶段提交")])]),t._v(" "),a("p",[t._v("前面我们介绍过一条 SQL 查询语句的执行过程，简单回顾：")]),t._v(" "),a("ol",[a("li",[t._v("MySQL 客户端与服务器间建立连接，客户端发送一条查询给服务器；")]),t._v(" "),a("li",[t._v("服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果；否则进入下一阶段；")]),t._v(" "),a("li",[t._v("服务器端进行 SQL 解析、预处理，生成合法的解析树；")]),t._v(" "),a("li",[t._v("再由优化器生成对应的执行计划；")]),t._v(" "),a("li",[t._v("执行器根据优化器生成的执行计划，调用相应的存储引擎的 API 来执行，并将执行结果返回给客户端")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119805.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("对于更新语句来说，这套流程同样也是要走一遍的，不同的是，更新流程还涉及两个重要的日志模块 bin log 和 redo log。")]),t._v(" "),a("p",[t._v("以下面这条简单的 SQL 语句为例，我们来解释下执行器和 InnoDB 存储引擎在更新时做了哪些事情：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" age "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" age "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("ol",[a("li",[a("p",[t._v("执行器：找存储引擎取到 id = 1 这一行记录")])]),t._v(" "),a("li",[a("p",[t._v("存储引擎：根据主键索引树找到这一行，如果 id = 1 这一行所在的数据页本来就在内存池（Buffer Pool）中，就直接返回给执行器；否则，需要先从磁盘读入内存池，然后再返回")])]),t._v(" "),a("li",[a("p",[t._v("执行器：拿到存储引擎返回的行记录，把 age 字段加上 1，得到一行新的记录，然后再调用存储引擎的接口写入这行新记录")])]),t._v(" "),a("li",[a("p",[t._v("存储引擎：将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 "),a("code",[t._v("prepare")]),t._v(" 状态。然后告知执行器执行完成了，随时可以提交事务")]),t._v(" "),a("blockquote",[a("p",[t._v("注意不要把这里的提交事务和我们 sql 语句中的提交事务 commit 命令搞混了哈，我们这里说的提交事务，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，commit 命令就执行成功了。")])])]),t._v(" "),a("li",[a("p",[t._v("执行器：生成这个操作的 bin log，并把 bin log 写入磁盘")])]),t._v(" "),a("li",[a("p",[t._v("执行器：调用存储引擎的提交事务接口")])]),t._v(" "),a("li",[a("p",[t._v("存储引擎：把刚刚写入的 redo log 状态改成提交（"),a("code",[t._v("commit")]),t._v("）状态，更新完成")])])]),t._v(" "),a("p",[t._v("如下图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119747.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("可以看到，"),a("strong",[t._v("所谓两阶段提交，其实就是把 redo log 的写入拆分成了两个步骤：prepare 和 commit")]),t._v("。")]),t._v(" "),a("p",[t._v("所以，为什么要这样设计呢？这样设计怎么就能够实现崩溃恢复呢？")]),t._v(" "),a("p",[t._v("根据两阶段提交，"),a("strong",[t._v("崩溃恢复时的判断规则")]),t._v("是这样的：")]),t._v(" "),a("ol",[a("li",[t._v("如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交")]),t._v(" "),a("li",[t._v("如果 redo log 里面的事务处于 prepare 状态，则判断对应的事务 binlog 是否存在并完整")])]),t._v(" "),a("ul",[a("li",[t._v("a. 如果 binlog 存在并完整，则提交事务；")]),t._v(" "),a("li",[t._v("b. 否则，回滚事务。")])]),t._v(" "),a("p",[t._v("当然，这样说小伙伴们肯定没法理解，下面来看几个实际的例子：")]),t._v(" "),a("p",[t._v("如下图所示，假设数据库在写入 redo log(prepare) 阶段之后、写入 binlog 之前，发生了崩溃，此时 redo log 里面的事务处于 prepare 状态，binlog 还没写（对应 2b），所以崩溃的时候，这个事务会回滚。")]),t._v(" "),a("blockquote",[a("p",[t._v("Why？")]),t._v(" "),a("p",[t._v("因为 binlog 还没有写入，之后从库进行同步的时候，无法执行这个操作，但是实际上主库已经完成了这个操作，所以为了主备一致，在主库上需要回滚这个事务")])]),t._v(" "),a("p",[t._v("并且，由于 binlog 还没写，所以也就不会传到备库，从而避免主备不一致的情况。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119155.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("而如果数据库在写入 binlog 之后，redo log 状态修改为 commit 前发生崩溃，此时 redo log 里面的事务仍然是 prepare 状态，binlog 存在并完整（对应 2a），所以即使在这个时刻数据库崩溃了，事务仍然会被正常提交。")]),t._v(" "),a("blockquote",[a("p",[t._v("Why？")]),t._v(" "),a("p",[t._v("因为 binlog 已经写入成功了，这样之后就会被从库同步过去，但是实际上主库并没有完成这个操作，所以为了主备一致，在主库上需要提交这个事务。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119563.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("所以，其实可以看出来，"),a("strong",[t._v("处于 prepare 阶段的 redo log 加上完整的 bin log，就能保证数据库的崩溃恢复了")]),t._v("。")]),t._v(" "),a("p",[t._v("可能有同学就会问了，MySQL 咋知道 bin log 是不是完整的？")]),t._v(" "),a("p",[t._v("简单来说，一个事务的 binlog 是有完整格式的（这个我们在后面的文章中会详细解释）：")]),t._v(" "),a("ul",[a("li",[t._v("statement 格式的 bin log，最后会有 COMMIT")]),t._v(" "),a("li",[t._v("row 格式的 bin log，最后会有 XID event")])]),t._v(" "),a("p",[t._v("而对于 bin log 可能会在中间出错的情况，MySQL 5.6.2 版本以后引入了 "),a("code",[t._v("binlog-checksum")]),t._v(" 参数，用来验证 bin log 内容的正确性。")]),t._v(" "),a("p",[t._v("思考一个问题，"),a("strong",[t._v("两阶段提交是必要的吗？可不可以先 redo log 写完，再写 bin log 或者反过来？")])]),t._v(" "),a("p",[t._v("1）对于先写完 redo log 后写 bin log 的情况：")]),t._v(" "),a("p",[t._v("假设在 redo log 写完，bin log 还没有写完的时候，MySQL 崩溃。主库中的数据确实已经被修改了，但是这时候 bin log 里面并没有记录这个语句。因此，从库同步的时候，就会丢失这个更新，和主库不一致。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119560.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("2）对于先写完 binlog 后写 redo log 的情况：")]),t._v(" "),a("p",[t._v("如果在 bin log 写完，redo log 还没写的时候，MySQL 崩溃。因为 binlog 已经写入成功了，这样之后就会被从库同步过去，但是实际上 redo log 还没写，主库并没有完成这个操作，所以从库相比主库就会多执行一个事务，导致主备不一致")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119370.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("这题目的三种问法")]),t._v(" "),a("ul",[a("li",[t._v("问法 1：如何解决 bin log 与 redo log 的一致性问题？")]),t._v(" "),a("li",[t._v("问法 2：一条 SQL 更新语句是如何执行的？")]),t._v(" "),a("li",[t._v("问法 3：讲一下 redo log / redo log 两阶段提交原理")])]),t._v(" "),a("p",[t._v("简易回答：")]),t._v(" "),a("p",[t._v("所谓两阶段提交，其实就是把 redo log 的写入拆分成了两个步骤：prepare 和 commit。")]),t._v(" "),a("p",[t._v("首先，存储引擎将执行更新好的新数据存到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 "),a("code",[t._v("prepare")]),t._v(" 状态。然后告知执行器执行完成了，随时可以提交事务")]),t._v(" "),a("p",[t._v("然后执行器生成这个操作的 bin log，并把 bin log 写入磁盘")]),t._v(" "),a("p",[t._v("最后执行器调用存储引擎的提交事务接口，存储引擎把刚刚写入的 redo log 状态改成提交（"),a("code",[t._v("commit")]),t._v("）状态，更新完成")]),t._v(" "),a("p",[t._v("如果数据库在写入 redo log(prepare) 阶段之后、写入 binlog 之前，发生了崩溃：")]),t._v(" "),a("p",[t._v("此时 redo log 里面的事务处于 prepare 状态，binlog 还没写，之后从库进行同步的时候，无法执行这个操作，那如果我们在主库上继续执行这个操作的话就会导致主备不一致，MySQL 崩溃时会在主库上回滚这个事务")]),t._v(" "),a("p",[t._v("而如果数据库在写入 binlog 之后，redo log 状态修改为 commit 前发生崩溃，此时 redo log 里面的事务仍然是 prepare 状态，binlog 存在并完整，这样之后就会被从库同步过去，但是实际上主库并没有完成这个操作，所以为了主备一致，即使在这个时刻数据库崩溃了，主库上事务仍然会被正常提交。")]),t._v(" "),a("h2",{attrs:{id:"数据库优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库优化"}},[t._v("#")]),t._v(" 数据库优化")]),t._v(" "),a("h3",{attrs:{id:"如何优化where子句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何优化where子句"}},[t._v("#")]),t._v(" 如何优化WHERE子句")]),t._v(" "),a("ul",[a("li",[t._v("不要在where子句中使用!=和<>进行不等于判断，这样会导致放弃索引进行全表扫描。")]),t._v(" "),a("li",[t._v("不要在where子句中使用null或空值判断，尽量设置字段为not null。")]),t._v(" "),a("li",[t._v("尽量使用union all代替or")]),t._v(" "),a("li",[t._v("在where和order by涉及的列建立索引")]),t._v(" "),a("li",[t._v("尽量减少使用in或者not in，会进行全表扫描")]),t._v(" "),a("li",[t._v("在where子句中使用参数会导致全表扫描")]),t._v(" "),a("li",[t._v("避免在where子句中对字段及进行表达式或者函数操作会导致存储引擎放弃索引进而全表扫描")])]),t._v(" "),a("h3",{attrs:{id:"如何避免mysql发生死锁或锁冲突（优化锁的方式）-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何避免mysql发生死锁或锁冲突（优化锁的方式）-2"}},[t._v("#")]),t._v(" 如何避免MySQL发生死锁或锁冲突（优化锁的方式）")]),t._v(" "),a("ul",[a("li",[t._v("如果不同的程序并发存取多个表，尽量以相同的顺序访问表。")]),t._v(" "),a("li",[t._v("在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录")]),t._v(" "),a("li",[t._v("在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁")]),t._v(" "),a("li",[t._v("尽量使用较低的隔离级别")]),t._v(" "),a("li",[t._v("尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会")]),t._v(" "),a("li",[t._v("合理选择事务的大小，小事务发生锁冲突的概率更低")]),t._v(" "),a("li",[t._v("尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。")]),t._v(" "),a("li",[t._v("不要申请超过实际需要的锁级别，查询时尽量不要显示加锁")]),t._v(" "),a("li",[t._v("对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。")]),t._v(" "),a("li",[t._v("数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别")])]),t._v(" "),a("h3",{attrs:{id:"大表如何优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大表如何优化"}},[t._v("#")]),t._v(" 大表如何优化")]),t._v(" "),a("ul",[a("li",[t._v("限定数据的范围：避免不带任何限制数据范围条件的查询语句。务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内")]),t._v(" "),a("li",[t._v("读写分离：主库负责写，从库负责读。")]),t._v(" "),a("li",[t._v("垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。")]),t._v(" "),a("li",[t._v("水平分表：在同一个数据库内，把一个表的数据按照一定规则拆分到多个表中。")]),t._v(" "),a("li",[t._v("对单表进行优化：对表中的字段、索引、查询SQL进行优化。")]),t._v(" "),a("li",[t._v("添加缓存")])]),t._v(" "),a("h3",{attrs:{id:"超大分页怎么处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#超大分页怎么处理"}},[t._v("#")]),t._v(" 超大分页怎么处理?")]),t._v(" "),a("p",[t._v("数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于"),a("code",[t._v("select * from table where age > 20 limit 1000000")]),t._v(",10 这种查询其实也是有可以优化的余地的. 这条语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为"),a("code",[t._v("select * from table where id in (select id from table where age > 20 limit 1000000,10)")]),t._v(".这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快。")]),t._v(" "),a("p",[t._v("解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可")]),t._v(" "),a("h3",{attrs:{id:"mysql数据库cpu飙升到100-的话怎么处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql数据库cpu飙升到100-的话怎么处理"}},[t._v("#")]),t._v(" MySQL数据库cpu飙升到100%的话怎么处理")]),t._v(" "),a("p",[t._v("当 cpu 飙升到 100%时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。")]),t._v(" "),a("p",[t._v("如果是 mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。")]),t._v(" "),a("p",[t._v("一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。")]),t._v(" "),a("p",[t._v("也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等")]),t._v(" "),a("h3",{attrs:{id:"如何优化查询过程中的数据访问"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何优化查询过程中的数据访问"}},[t._v("#")]),t._v(" 如何优化查询过程中的数据访问")]),t._v(" "),a("ul",[a("li",[t._v("访问数据太多导致查询性能下降")]),t._v(" "),a("li",[t._v("确定应用程序是否在检索大量超过需要的数据，可能是太多行或列")]),t._v(" "),a("li",[t._v("确认MySQL服务器是否在分析大量不必要的数据行")]),t._v(" "),a("li",[t._v("查询不需要的数据。解决办法：使用limit解决")]),t._v(" "),a("li",[t._v("多表关联返回全部列。解决办法：指定列名")]),t._v(" "),a("li",[t._v("总是返回全部列。解决办法：避免使用SELECT *")]),t._v(" "),a("li",[t._v("重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存")]),t._v(" "),a("li",[t._v("是否在扫描额外的记录。解决办法： 使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。")]),t._v(" "),a("li",[t._v("改变数据库和表的结构，修改数据表范式")]),t._v(" "),a("li",[t._v("重写SQL语句，让优化器可以以更优的方式执行查询。")])]),t._v(" "),a("h3",{attrs:{id:"数据库结构优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库结构优化"}},[t._v("#")]),t._v(" 数据库结构优化")]),t._v(" "),a("p",[t._v("一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。")]),t._v(" "),a("p",[t._v("需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。")]),t._v(" "),a("ol",[a("li",[a("p",[a("strong",[t._v("将字段很多的表分解成多个表")])]),t._v(" "),a("p",[t._v("对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。")]),t._v(" "),a("p",[t._v("因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("增加中间表")])]),t._v(" "),a("p",[t._v("对于需要经常联合查询的表，可以建立中间表以提高查询效率。")]),t._v(" "),a("p",[t._v("通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("增加冗余字段")])]),t._v(" "),a("p",[t._v("设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。")]),t._v(" "),a("p",[t._v("表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。")])])]),t._v(" "),a("p",[a("strong",[t._v("注意")]),t._v("：")]),t._v(" "),a("p",[t._v("冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。")]),t._v(" "),a("p",[t._v("在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。")]),t._v(" "),a("p",[t._v("慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？")]),t._v(" "),a("p",[t._v("所以优化也是针对这三个方向来的，")]),t._v(" "),a("ul",[a("li",[t._v("首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。")]),t._v(" "),a("li",[t._v("分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。")]),t._v(" "),a("li",[t._v("如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。")])]),t._v(" "),a("h2",{attrs:{id:"数据库读写分离、主从复制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库读写分离、主从复制"}},[t._v("#")]),t._v(" 数据库读写分离、主从复制")]),t._v(" "),a("h3",{attrs:{id:"主从复制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#主从复制"}},[t._v("#")]),t._v(" 主从复制")]),t._v(" "),a("p",[t._v("主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。")]),t._v(" "),a("p",[t._v("因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。")]),t._v(" "),a("p",[t._v("主从复制的原理：")]),t._v(" "),a("p",[t._v("主从复制主要有三个线程："),a("strong",[t._v("binlog线程")]),t._v("，"),a("strong",[t._v("I/O线程")]),t._v("，"),a("strong",[t._v("SQL线程")]),t._v("。")]),t._v(" "),a("ul",[a("li",[t._v("binlog线程：负责将主服务器上的数据更改写入到二进制日志（Binary log）中。")]),t._v(" "),a("li",[t._v("I/O线程：负责从主服务器上读取二进制日志（Binary log），并写入从服务器的中继日志（Relay  log）中。")]),t._v(" "),a("li",[t._v("SQL线程：负责读取中继日志，解析出主服务器中已经执行的数据更改并在从服务器中重放")])]),t._v(" "),a("p",[t._v("复制过程如下")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119525.png",alt:"image-20220425142048304"}})]),t._v(" "),a("p",[t._v("Binary log：主数据库的二进制日志")]),t._v(" "),a("p",[t._v("Relay log：从服务器的中继日志")]),t._v(" "),a("ol",[a("li",[t._v("Master在每个事务更新数据完成之前，将操作记录写入到binlog中。")]),t._v(" "),a("li",[t._v("Slave从库连接Master主库，并且Master有多少个Slave就会创建多少个binlog dump线程。当 Master节点的binlog发生变化时，binlog dump会通知所有的Slave，并将相应的binlog发送给 Slave。")]),t._v(" "),a("li",[t._v("I/O线程接收到binlog内容后，将其写入到中继日志（Relay log）中。")]),t._v(" "),a("li",[t._v("SQL线程读取中继日志，并在从服务器中重放。")])]),t._v(" "),a("p",[t._v("简易图：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119539.png",alt:"image-20220425142352312"}})]),t._v(" "),a("p",[t._v("主从复制的作用：")]),t._v(" "),a("ul",[a("li",[t._v("高可用和故障转移")]),t._v(" "),a("li",[t._v("负载均衡")]),t._v(" "),a("li",[t._v("数据备份")]),t._v(" "),a("li",[t._v("升级测试")])]),t._v(" "),a("h3",{attrs:{id:"mysql主从同步延时问题如何解决？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql主从同步延时问题如何解决？"}},[t._v("#")]),t._v(" MySQL主从同步延时问题如何解决？")]),t._v(" "),a("p",[a("strong",[t._v("原因")])]),t._v(" "),a("p",[t._v("当主服务器有大并发的更新操作，但是从服务器的里面读取binlog的线程仅有一个，当某个sql在从服务器上执行的时间稍长或者由于某个sql要进行锁表就会导致，主服务器的sql大量积压，未被同步到从服务器里，这就导致了主从不一致，也就是主从延迟。")]),t._v(" "),a("p",[t._v("MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题。")]),t._v(" "),a("ul",[a("li",[t._v("半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。")]),t._v(" "),a("li",[t._v("并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。")])]),t._v(" "),a("h3",{attrs:{id:"mysql的全复制、半复制、异步复制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql的全复制、半复制、异步复制"}},[t._v("#")]),t._v(" mysql的全复制、半复制、异步复制")]),t._v(" "),a("p",[a("strong",[t._v("异步复制")])]),t._v(" "),a("p",[t._v("mysql默认的就是异步复制。主库在执行完客户端提交的事务后会立即将结果返回给客户端，并不关心从库是否已经 接收并处理。主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只是通知 Dump 线程发送这些新的 Binlog， 然后主库就会继续处理提交操作，并不保证这些 Binlog 传到任何一个从库节点上。这样就会存在一个问题，如果主库出现故障，此时主库已经提交的事务可能并没有传到从库上，可能导致数据丢失。")]),t._v(" "),a("p",[a("strong",[t._v("全复制")])]),t._v(" "),a("p",[t._v("当主库提交事务之后，所有的从库节点必须收到、APPLY并且提交这些事务，然后主库线程才能继续做后续操作。因 为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。")]),t._v(" "),a("p",[a("strong",[t._v("半同步复制")])]),t._v(" "),a("p",[t._v("介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到 relay log 中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一 定程度的延迟。")]),t._v(" "),a("p",[t._v("半同步复制的出现，就是为了保证在任何时刻主备数据一致的问题。相对于异步复制，半同步复制要求执行的每一个 事务，都要求至少有一个备库成功接收后，才返回给用户。实现原理也很简单，主库本地执行完毕后，等待备库的响 应消息（包含最新备库接收到的binlog（file，pos）），接收到备库响应消息后，再返回给用户，这样一个事务才算真正完成。在主库实例上，有一个专门的线程（ack_receiver）接收备库的响应消息，并以通知机制告知主库备库已 经接收的日志，可以继续执行。")]),t._v(" "),a("p",[t._v("安装一个插件，然后设置mysql的参数即可。")]),t._v(" "),a("h3",{attrs:{id:"mysql半同步复制的特点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql半同步复制的特点"}},[t._v("#")]),t._v(" mysql半同步复制的特点")]),t._v(" "),a("p",[t._v("（1）从库会在连接到主库时告诉主库，它是不是配置了半同步。 （2）如果半同步复制在主库端开启，并且至少有 一个半同步复制的从库节点，那么此时主库的事务线程在提交时会被阻塞并等待，结果有两种可能：（a）至少一个从库节点通知它已经收到了所有这个事务的Binlog事件；（b）一直等待直到超过配置的某一个时间点为止，此时， 半同步复制将自动关闭，转换为异步复制。 （3）从库节点只有在接收到某一个事务的所有 Binlog，将其写入到 Relay Log 文件之后，才会通知对应主库上面的等待线程。 （4）如果在等待过程中，等待时间已经超过了配置的超时时间，没有任何一个从节点通知当前事务，那么此时主库会自动转换为异步复制，当至少一个半同步从节点赶上来时，主库便会自动转换为半同步方式的复制。 （5）半同步复制必须是在主库和从库两端都开启时才行，如果在主库 上没打开，或者在主库上开启了而在从库上没有开启，主库都会使用异步方式复制。")]),t._v(" "),a("h3",{attrs:{id:"读写分离"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#读写分离"}},[t._v("#")]),t._v(" 读写分离")]),t._v(" "),a("p",[a("strong",[t._v("读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。")]),t._v(" 这样的话，就能够小幅提升写性能，大幅提升读性能。")]),t._v(" "),a("p",[t._v("读写分离主要依赖于主从复制，主从复制为读写分离服务")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119847.png",alt:"image-20220425161941389"}})]),t._v(" "),a("p",[t._v("一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。")]),t._v(" "),a("p",[a("strong",[t._v("读写分离会带来什么问题？如何解决？")])]),t._v(" "),a("p",[t._v("读写分离对于提升数据库的并发非常有效，但是，同时也会引来一个问题：主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 "),a("strong",[t._v("主从同步延迟")]),t._v(" 。")]),t._v(" "),a("p",[a("strong",[t._v("1.强制将读请求路由到主库处理。")])]),t._v(" "),a("p",[t._v("既然你从库的数据过期了，那我就直接从主库读取嘛！这种方案虽然会增加主库的压力，但是，实现起来比较简单，也是我了解到的使用最多的一种方式。")]),t._v(" "),a("p",[t._v("比如 "),a("code",[t._v("Sharding-JDBC")]),t._v(" 就是采用的这种方案。通过使用 Sharding-JDBC 的 "),a("code",[t._v("HintManager")]),t._v(" 分片键值管理器，我们可以强制使用主库。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HintManager")]),t._v(" hintManager "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HintManager")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getInstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhintManager"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("setMasterRouteOnly")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续JDBC操作")]),t._v("\n")])])]),a("p",[t._v("对于这种方案，你可以将那些必须获取最新数据的读请求都交给主库处理。")]),t._v(" "),a("p",[a("strong",[t._v("2.延迟读取。")])]),t._v(" "),a("p",[t._v("还有一些朋友肯定会想既然主从同步存在延迟，那我就在延迟之后读取啊，比如主从同步延迟 0.5s,那我就 1s 之后再读取数据。这样多方便啊！方便是方便，但是也很扯淡。")]),t._v(" "),a("p",[t._v("不过，如果你是这样设计业务流程就会好很多：对于一些对数据比较敏感的场景，你可以在完成写请求之后，避免立即进行请求操作。比如你支付成功之后，跳转到一个支付成功的页面，当你点击返回之后才返回自己的账户。")]),t._v(" "),a("p",[t._v("读写分离的优势：")]),t._v(" "),a("ul",[a("li",[t._v("主服务器负责写，从服务器负责读，缓解了锁的竞争")]),t._v(" "),a("li",[t._v("从服务器可以使用MyISAM，提升查询性能及节约系统开销")]),t._v(" "),a("li",[t._v("增加冗余，提高可用性")])]),t._v(" "),a("p",[a("strong",[t._v("如何实现读写分离？")])]),t._v(" "),a("p",[t._v("不论是使用哪一种读写分离具体的实现方案，想要实现读写分离一般包含如下几步：")]),t._v(" "),a("ol",[a("li",[t._v("部署多台数据库，选择一种的一台作为主数据库，其他的一台或者多台作为从数据库。")]),t._v(" "),a("li",[t._v("保证主数据库和从数据库之间的数据是实时同步的，这个过程也就是我们常说的"),a("strong",[t._v("主从复制")]),t._v("。")]),t._v(" "),a("li",[t._v("系统将写请求交给主数据库处理，读请求交给从数据库处理。")])]),t._v(" "),a("p",[t._v("落实到项目本身的话，常用的方式有两种：")]),t._v(" "),a("p",[a("strong",[t._v("1.代理方式")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/461112716e30db118f4c784adc6e2ff7.png",alt:"读写分离-代理层"}})]),t._v(" "),a("p",[t._v("我们可以在应用和数据中间加了一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。")]),t._v(" "),a("p",[t._v("提供类似功能的中间件有 "),a("strong",[t._v("MySQL Router")]),t._v("（官方）、"),a("strong",[t._v("Atlas")]),t._v("（基于 MySQL Proxy）、"),a("strong",[t._v("Maxscale")]),t._v("、"),a("strong",[t._v("MyCat")]),t._v("。")]),t._v(" "),a("p",[a("strong",[t._v("2.组件方式")])]),t._v(" "),a("p",[t._v("在这种方式中，我们可以通过引入第三方组件来帮助我们读写请求。")]),t._v(" "),a("p",[t._v("这也是我比较推荐的一种方式。这种方式目前在各种互联网公司中用的最多的，相关的实际的案例也非常多。如果你要采用这种方式的话，推荐使用 "),a("code",[t._v("sharding-jdbc")]),t._v(" ，直接引入 jar 包即可使用，非常方便。同时，也节省了很多运维的成本。")]),t._v(" "),a("p",[t._v("你可以在 shardingsphere 官方找到"),a("a",{attrs:{href:"https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/",target:"_blank",rel:"noopener noreferrer"}},[t._v("sharding-jdbc 关于读写分离的操作"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"分库分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表"}},[t._v("#")]),t._v(" 分库分表")]),t._v(" "),a("p",[t._v("关系型数据库以MySQL为例，单机的存储能力、连接数是有限的，它自身就很容易会成为系统的瓶颈。 当单表数据量在百万以里时，我们还可以通过添加从库、优化索引提升性能。一旦数据量朝着千万以上 趋势增长，再怎么优化数据库，很多操作性能仍下降严重。为了减少数据库的负担，提升数据库响应速度，缩短查询时间，这时候就需要进行 分库分表 。")]),t._v(" "),a("p",[a("strong",[t._v("遇到下面几种场景可以考虑分库分表：")])]),t._v(" "),a("ul",[a("li",[t._v("单表的数据达到千万级别以上，数据库读写速度比较缓慢（分表）。")]),t._v(" "),a("li",[t._v("数据库中的数据占用的空间越来越大，备份时间越来越长（分库）。")]),t._v(" "),a("li",[t._v("应用的并发量太大（分库）。")])]),t._v(" "),a("h3",{attrs:{id:"垂直拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#垂直拆分"}},[t._v("#")]),t._v(" "),a("strong",[t._v("垂直拆分")])]),t._v(" "),a("h5",{attrs:{id:"垂直分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#垂直分表"}},[t._v("#")]),t._v(" 垂直分表")]),t._v(" "),a("p",[t._v("垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。一般会将常用的字段放到一个表中，将不常用的字段放到另一个表中。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119083.png",alt:"image-20220106132229699"}})]),t._v(" "),a("p",[t._v("垂直分表的优势：")]),t._v(" "),a("ul",[a("li",[t._v("避免IO竞争减少锁表的概率。因为大的字段效率更低，第一数据量大，需要的读取时间长。第二， 大字段占用的空间更大，单页内存储的行数变少，会使得IO操作增多。")]),t._v(" "),a("li",[t._v("可以更好地提升热门数据的查询效率。")]),t._v(" "),a("li",[t._v("针对不同的数据，可以实现冷热分离，动静分离")])]),t._v(" "),a("p",[a("strong",[t._v("缺点：")])]),t._v(" "),a("ul",[a("li",[t._v("提升了开发的复杂度，由于业务的隔离性，很多表无法直接访问，必须通过接口方式聚合数据")]),t._v(" "),a("li",[t._v("分布式事务管理难度增加")]),t._v(" "),a("li",[t._v("数据库还是存在单表数据量过大的问题，并未根本上解决，需要配合水平切分")])]),t._v(" "),a("p",[t._v("数据库是以行为单位将数据加载到内存中，这样拆分以后核心表大多是访问频率较高的字段，而且字段长度也都较短，可以加载更多数据到内存中，增加查询的命中率，减少磁盘IO，以此来提升数据库性 能。")]),t._v(" "),a("h5",{attrs:{id:"垂直分库"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#垂直分库"}},[t._v("#")]),t._v(" 垂直分库")]),t._v(" "),a("p",[t._v("垂直分库是基于业务分类的，和我们常听到的微服务治理观念很相似，每一个独立的服务都拥有自己的数据库，需要不同业务的数据需接口调用。而垂直分库也是按照业务分类进行划分，每个业务有独立数据库，这个比较好理解")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119108.png",alt:"image-20220425130520033"}})]),t._v(" "),a("p",[t._v("垂直分库的优势：")]),t._v(" "),a("ul",[a("li",[t._v("降低业务中的耦合，方便对不同的业务进行分级管理。")]),t._v(" "),a("li",[t._v("可以提升IO、数据库连接数、解决单机硬件资源的瓶颈问题。")])]),t._v(" "),a("p",[t._v("垂直拆分（分库、分表）的缺点：")]),t._v(" "),a("ul",[a("li",[t._v("主键出现冗余，需要管理冗余列")]),t._v(" "),a("li",[t._v("事务的处理变得复杂")]),t._v(" "),a("li",[t._v("仍然存在单表数据量过大的问题")])]),t._v(" "),a("h3",{attrs:{id:"水平拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#水平拆分"}},[t._v("#")]),t._v(" "),a("strong",[t._v("水平拆分")])]),t._v(" "),a("p",[t._v("前边说了垂直切分还是会存在单表数据量过大的问题，当我们的应用已经无法在细粒度的垂直切分时， 依旧存在单库读写、存储性能瓶颈，这时就要配合水平切分一起了。")]),t._v(" "),a("p",[t._v("水平切分将一张大数据量的表，切分成多个表结构相同，而每个表只占原表一部分数据，然后按不同的条件分散到多个数据库中。")]),t._v(" "),a("p",[t._v("假如一张 order 表有2000万数据，水平切分后出来四个表， "),a("code",[t._v("order_1")]),t._v(" 、 "),a("code",[t._v("order_2")]),t._v(" 、"),a("code",[t._v("order_3")]),t._v(" 、"),a("code",[t._v("order_4")]),t._v("，每张表数据500万，以此类推。")]),t._v(" "),a("p",[t._v("水平切分又分有 "),a("strong",[t._v("库内分表")]),t._v(" 和 "),a("strong",[t._v("分库分表")])]),t._v(" "),a("h5",{attrs:{id:"水平分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#水平分表"}},[t._v("#")]),t._v(" 水平分表")]),t._v(" "),a("p",[t._v("库内分表虽然将表拆分，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题， 并没有将拆分后的表分布到不同机器的库上，还在竞争同一个物理机的CPU、内存、网络IO。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119141.png",alt:"image-20220425131054990"}})]),t._v(" "),a("h5",{attrs:{id:"水平分库（分库分表）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#水平分库（分库分表）"}},[t._v("#")]),t._v(" 水平分库（分库分表）")]),t._v(" "),a("h5",{attrs:{id:"分库分表则是将切分出来的子表，分散到不同的数据库中，从而使得单个表的数据量变小，达到分布式的效果。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表则是将切分出来的子表，分散到不同的数据库中，从而使得单个表的数据量变小，达到分布式的效果。"}},[t._v("#")]),t._v(" 分库分表则是将切分出来的子表，分散到不同的数据库中，从而使得单个表的数据量变小，达到分布式的效果。")]),t._v(" "),a("p",[t._v("优点：")]),t._v(" "),a("ul",[a("li",[t._v("解决高并发时单库数据量过大的问题，提升系统稳定性和负载能力")]),t._v(" "),a("li",[t._v("水平分表的表结构一致，横向扩展时，业务端可以做到无感知无改动，业务系统改造的工作量不是很大。")])]),t._v(" "),a("p",[t._v("缺点：")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("路由规则复杂，难以抽象")])]),t._v(" "),a("li",[a("p",[t._v("跨分片的事务一致性难以保证")])]),t._v(" "),a("li",[a("p",[t._v("跨库的join关联查询性能较差")])]),t._v(" "),a("li",[a("p",[t._v("扩容的难度和维护量较大，（拆分成几千张子表想想都恐怖）")])])]),t._v(" "),a("p",[t._v("在系统设计时应根据业务耦合来确定垂直分库和垂直分表的方案，在数据访问压力不是特别大时应考虑缓存、读写分离等方法，若数据量很大，或持续增长可考虑水平分库分表，水平拆分所涉及的逻辑比较 复杂，常见的方案有客户端架构和代理架构")]),t._v(" "),a("h3",{attrs:{id:"分表时，什么是我们需要考虑的内容？怎么样才能制定一个完善的分库分表方案？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分表时，什么是我们需要考虑的内容？怎么样才能制定一个完善的分库分表方案？"}},[t._v("#")]),t._v(" 分表时，什么是我们需要考虑的内容？怎么样才能制定一个完善的分库分表方案？")]),t._v(" "),a("h5",{attrs:{id:"_1-方案可持续性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-方案可持续性"}},[t._v("#")]),t._v(" 1.方案可持续性")]),t._v(" "),a("p",[t._v("前期业务数据量级不大，流量较低的时候，我们无需分库分表，也不建议分库分表。但是一旦我们要对业务进行分库分表设计时，就一定要考虑到分库分表方案的可持续性。那何为可持续性？其实就是：业务数据量级和业务流量未来进一步升高达到新的量级的时候，我们的分库分表方案可以持续使用。一个通俗的案例，假定当前我们分库分表的方案为 10 库 100 表，那么未来某个时间点，若 10 个库仍然无法应对用户的流量压力，或者 10 个库的磁盘使用即将达到物理上限时，我们的方案能够进行平滑扩容。在后文中我们将介绍下目前业界常用的"),a("strong",[t._v("翻倍扩容法")]),t._v("和"),a("strong",[t._v("一致性Hash 扩容法")]),t._v("。")]),t._v(" "),a("h5",{attrs:{id:"_2-数据偏斜问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据偏斜问题"}},[t._v("#")]),t._v(" 2.数据偏斜问题")]),t._v(" "),a("p",[t._v("一个良好的分库分表方案，它的数据应该是需要比较均匀的分散在各个库表中的。如果我们进行一个拍脑袋式的分库分表设计，很容易会遇到以下类似问题：")]),t._v(" "),a("ul",[a("li",[t._v("某个数据库实例中，部分表的数据很多，而其他表中的数据却寥寥无几，业务上的表现经常是延迟忽高忽低，飘忽不定。")]),t._v(" "),a("li",[t._v("数据库集群中，部分集群的磁盘使用增长特别块，而部分集群的磁盘增长却很缓慢。每个库的增长步调不一致，这种情况会给后续的扩容带来步调不一致，无法统一操作的问题。")])]),t._v(" "),a("p",[t._v("这边我们定义分库分表最大数据偏斜率为："),a("code",[t._v("（数据量最大样本-数据量最小样本）/数据量最小样本")]),t._v("。一般来说，如果我们的最大数据偏斜率在 5% 以内是可以接受的。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119146.png",alt:"image-20220426145336345"}})]),t._v(" "),a("h3",{attrs:{id:"引入分库分表之后，会给系统带来什么挑战呢？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#引入分库分表之后，会给系统带来什么挑战呢？"}},[t._v("#")]),t._v(" "),a("strong",[t._v("引入分库分表之后，会给系统带来什么挑战呢？")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("join 操作")]),t._v(" ： 同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。")]),t._v(" "),a("li",[a("strong",[t._v("事务问题")]),t._v(" ：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。")]),t._v(" "),a("li",[a("strong",[t._v("分布式 id")]),t._v(" ：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何为不同的数据节点生成全局唯一主键呢？这个时候，我们就需要为我们的系统引入分布式 id 了。")])]),t._v(" "),a("h3",{attrs:{id:"数据该往哪个库的表存？（常见路由策略）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据该往哪个库的表存？（常见路由策略）"}},[t._v("#")]),t._v(" 数据该往哪个库的表存？（常见路由策略）")]),t._v(" "),a("p",[t._v("水平分表的方案不同，主要来源于路由策略的不同。接下来讨论一下几种不同的路由策略")]),t._v(" "),a("h5",{attrs:{id:"range分库分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#range分库分表"}},[t._v("#")]),t._v(" Range分库分表")]),t._v(" "),a("p",[t._v("顾名思义，就是通过一定的范围，将表数据分配到不同的库中。比如：")]),t._v(" "),a("ol",[a("li",[t._v("通过uid，1-1000，1001-2000为范围分不同的库")]),t._v(" "),a("li",[t._v("根据地区，华南，华中，华东分别在不同的库")]),t._v(" "),a("li",[t._v("根据时间，每个季度的数据都在新库")])]),t._v(" "),a("p",[t._v("样的分库分表看似简单，但也存在一些致命的缺陷，比如:")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("数据热点问题")]),t._v("，如果根据时间分表，我们可以认为最新的数据被查询的概率也最大，那么大量的查询都会落在最新的那张表上，没有均匀的分布查询流量")]),t._v(" "),a("li",[a("strong",[t._v("新表追加问题")]),t._v("，一般我们线上运行的应用程序是没有数据库的建库建表权限的，故我们需要提前将新的库表提前建立，防止线上故障。这点非常容易被遗忘，尤其是稳定跑了几年没有迭代任务，或者人员又交替频繁的模块。")])]),t._v(" "),a("h5",{attrs:{id:"hash取模分库分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash取模分库分表"}},[t._v("#")]),t._v(" Hash取模分库分表")]),t._v(" "),a("h6",{attrs:{id:"标准的二次分片法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#标准的二次分片法"}},[t._v("#")]),t._v(" "),a("strong",[t._v("标准的二次分片法")])]),t._v(" "),a("p",[t._v("这是最经典的hash分片规则，并且能够兼容后期的扩容方案。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[t._v("publicstatic "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ShardCfg")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("shard2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" userId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ① 算Hashint ")]),t._v("\n    hash "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" userId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashCode")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ② 总分片数int ")]),t._v("\n    sumSlot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DB_CNT "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" TBL_CNT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ③ 分片序号")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" slot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Math")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("abs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" sumSlot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ④ 重新修改二次求值方案int ")]),t._v("\n    dbIdx "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" slot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" TBL_CNT "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" tblIdx "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" slot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" TBL_CNT "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    returnnew "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ShardCfg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dbIdx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tblIdx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("根据以上算法，假设我们分10个库100张表，他的分配情况如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119249.png",alt:"image-20220426191049644"}})]),t._v(" "),a("p",[t._v("通过翻倍扩容后，我们的表序号一定维持不变，库序号可能还是在原来库，也可能平移到了新库中(原库序号加上原分库数)，完全符合我们需要的扩容持久性方案。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119355.png",alt:"image-20220426191146902"}})]),t._v(" "),a("p",[t._v("方案缺点：")]),t._v(" "),a("ol",[a("li",[t._v("翻倍扩容法前期操作性高，但是后续如果分库数已经是大几十的时候，每次翻倍扩容都非常耗费资源。")]),t._v(" "),a("li",[t._v("连续的分片键 Hash 值大概率会散落在相同的库中，某些业务可能容易存在库热点（例如新生成的用户 Hash 相邻且递增，且新增用户又是高概率的活跃用户，那么一段时间内生成的新用户都会集中在相邻的几个库中）。")])]),t._v(" "),a("h6",{attrs:{id:"路由关系记录表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#路由关系记录表"}},[t._v("#")]),t._v(" 路由关系记录表")]),t._v(" "),a("p",[t._v("该方案还是通过常规的 Hash 算法计算表序号，而计算库序号时，则从路由表读取数据。因为在每次数据查询时，都需要读取路由表，故我们需要将分片键和库序号的对应关系记录同时维护在缓存中以提升性能。优点：1.我们可以给每个库设置权重，根据库数据的负载动态调整权重。2.理论上后续进行扩容的时候，仅需要挂载上新的数据库节点，将权重配置成较大值即可，无需进行任何的数据迁移即可完成。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119473.png",alt:"image-20220426191349109"}})]),t._v(" "),a("p",[t._v("缺点：")]),t._v(" "),a("ol",[a("li",[t._v("每次读取数据需要访问路由表，虽然使用了缓存，但是还是有一定的性能损耗。")]),t._v(" "),a("li",[t._v("路由关系表的存储方面，有些场景并不合适。例如上述案例中用户 id 的规模大概是在 10 亿以内，我们用单库百表存储该关系表即可。但如果例如要用文件 MD5 摘要值作为分片键，因为样本集过大，无法为每个 md5 值都去指定关系（当然我们也可以使用 md5 前 N 位来存储关系）。")])]),t._v(" "),a("h3",{attrs:{id:"主键生成问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#主键生成问题"}},[t._v("#")]),t._v(" "),a("strong",[t._v("主键生成问题")])]),t._v(" "),a("p",[t._v("由于我们一般用主键作为分片键，在不同表中，如果用主键id自增的方式，会导致主键重复的问题。所以需要引入全局id生成器，具体的id生成器方案，大家感兴趣可自行查阅资料。")]),t._v(" "),a("h3",{attrs:{id:"非分片键查询问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#非分片键查询问题"}},[t._v("#")]),t._v(" "),a("strong",[t._v("非分片键查询问题")])]),t._v(" "),a("p",[t._v("大多数场景，我们都是用主键作为分片键，这样路由的规则只和主键相关。我们通过主键查询，很容易就路由到对应的表查询要想要的数据。像这样")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119680.png",alt:"image-20220426191905593"}})]),t._v(" "),a("p",[t._v("但还有百分之20的请求，可能需要查询uid下的所有所有任务数据。而相同uid可能被分到了不同的库，我们需要聚合所有库的查询，然后返回给前端，这样多次数据库连接非常麻烦，且低效。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119614.png",alt:"image-20220426191918606"}})]),t._v(" "),a("p",[t._v("我们可能会尝试用uid作为分片键，这样相同uid肯定会在同一个库。我们只需要查询一个库就能获取想要的所有数据，看起来很棒，像这样")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119626.png",alt:"image-20220426191928497"}})]),t._v(" "),a("p",[t._v("但是这样会导致我们用主键查询的时候，完全找不到对应的路由关系了。这样的改造就是因小失大，得不偿失。那么怎么同时能够查询主键，又能够根据uid查询呢？")]),t._v(" "),a("h5",{attrs:{id:"映射关系表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#映射关系表"}},[t._v("#")]),t._v(" "),a("strong",[t._v("映射关系表")])]),t._v(" "),a("p",[t._v("还是用uid进行分片，将主键和需要查询的uid做一个映射关系表，这样需要查询主键的时候，先去映射表找到对应的uid，再通过uid，就能路由到对应的表了。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119686.png",alt:"image-20220426192002968"}})]),t._v(" "),a("h5",{attrs:{id:"基因法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基因法"}},[t._v("#")]),t._v(" 基因法")]),t._v(" "),a("p",[t._v("或者我们可以截取uid的尾部几位作为特征基因，嵌入主键中。用主键的这部分基因进行分片。这样就像uid寄生了主键一样。看似用主键分片，实际上还是用uid分片。两者都能通过路由规则查询的方式路由到对应的表。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119777.png",alt:"image-20220426192127411"}})]),t._v(" "),a("h5",{attrs:{id:"es查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#es查询"}},[t._v("#")]),t._v(" ES查询")]),t._v(" "),a("p",[t._v("那么在传统的商品表中，我们不仅需要查询商户id，还会查询sku，spu，这么多的查询条件，基因法还能有效么？这样的情况下，我们最好是能通过canal，将所有数据聚合进es数据库中，整理出olap供业务端多条件，多场景的查询功能。")]),t._v(" "),a("h3",{attrs:{id:"扩容方案"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#扩容方案"}},[t._v("#")]),t._v(" 扩容方案")]),t._v(" "),a("p",[t._v("扩容方案，是在我们最初做分库分表就该思考好的问题。如果当初没有一个合理的规划，那么当数据量又一次达到负荷，这个锅就会被传递给下一位接手的同事。")]),t._v(" "),a("h5",{attrs:{id:"翻倍扩容法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#翻倍扩容法"}},[t._v("#")]),t._v(" "),a("strong",[t._v("翻倍扩容法")])]),t._v(" "),a("p",[t._v('翻倍扩容法的主要思维是每次扩容，库的数量均翻倍处理，而翻倍的数据源通常是由原数据源通过主从复制方式得到的从库升级成主库提供服务的方式。故有些文档将其称作"从库升级法"。理论上，经过翻倍扩容法后，我们会多一倍的数据库用来存储数据和应对流量，原先数据库的磁盘使用量也将得到一半空间的释放。如下图所示：')]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119935.png",alt:"image-20220426192541414"}})]),t._v(" "),a("p",[t._v("**时间点 t1：**为每个节点都新增从库，开启主从同步进行数据同步。**时间点 t2：**主从同步完成后，对主库进行禁写。")]),t._v(" "),a("blockquote",[a("p",[t._v("此处禁写主要是为了保证数据的正确性。若不进行禁写操作，在以下两个时间窗口期内将出现数据不一致的问题：")]),t._v(" "),a("ul",[a("li",[t._v("断开主从后，若主库不禁写，主库若还有数据写入，这部分数据将无法同步到从库中。")]),t._v(" "),a("li",[t._v("应用集群识别到分库数翻倍的时间点无法严格一致，在某个时间点可能两台应用使用不同的分库数，运算到不同的库序号，导致错误写入。")])])]),t._v(" "),a("p",[t._v("**时间点 t3：**同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。**时间点t4：**从库升级为集群节点，业务应用识别到新的分库数后，将应用新的路由算法。")]),t._v(" "),a("blockquote",[a("p",[t._v("一般情况下，我们将分库数的配置放到配置中心中，当上述三个步骤完成后，我们修改分库数进行翻倍，应用生效后，应用服务将使用新的配置。这里需要注意的是，业务应用接收到新的配置的时间点不一定一致，所以必定存在一个时间窗口期，该期间部分机器使用原分库数，部分节点使用新分库数。这也正是我们的禁写操作一定要在此步完成后才能放开的原因。")])]),t._v(" "),a("p",[t._v("**时间点 t5：**确定所有的应用均接受到库总数的配置后，放开原主库的禁写操作，此时应用完全恢复服务。**启动离线的定时任务，**清除各库中的约一半冗余数据。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119488.gif",alt:"微信图片_20220426192714"}})]),t._v(" "),a("p",[t._v("缺点也很明显，就是每次扩容都是翻倍，多次翻倍后，会浪费不少数据库资源")]),t._v(" "),a("h5",{attrs:{id:"一致性-hash-扩容"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一致性-hash-扩容"}},[t._v("#")]),t._v(" "),a("strong",[t._v("一致性 Hash 扩容")])]),t._v(" "),a("p",[t._v("一致性hash的原理可以参考网上的资料")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119039.png",alt:"image-20220426192810737"}})]),t._v(" "),a("p",[t._v("我们一般会有个配置，将一部分虚拟节点映射到对应的真实的库里。当某个库压力过大时，我们只需要针对需要扩容的库，把这一部分虚拟节点分给另一个新的库，灵活的进行扩容。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119435.png",alt:"image-20220426192829675"}})]),t._v(" "),a("p",[t._v("主要步骤如下：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("时间点 t1")]),t._v("：针对需要扩容的数据库节点增加从节点，开启主从同步进行数据同步。")]),t._v(" "),a("li",[a("strong",[t._v("时间点 t2")]),t._v("：完成主从同步后，对原主库进行禁写。此处原因和翻倍扩容法类似，需要保证新的从库和原来主库中数据的一致性。")]),t._v(" "),a("li",[a("strong",[t._v("时间点 t3")]),t._v("：同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。")]),t._v(" "),a("li",[a("strong",[t._v("时间点 t4")]),t._v("：修改一致性 Hash 范围的配置，并使应用服务重新读取并生效。")]),t._v(" "),a("li",[a("strong",[t._v("时间点 t5")]),t._v("：确定所有的应用均接受到新的一致性 Hash 范围配置后，放开原主库的禁写操作，此时应用完全恢复服务。")]),t._v(" "),a("li",[t._v("启动离线的定时任务，清除冗余数据。")])]),t._v(" "),a("h3",{attrs:{id:"分库分表有没有什么比较推荐的方案？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表有没有什么比较推荐的方案？"}},[t._v("#")]),t._v(" 分库分表有没有什么比较推荐的方案？")]),t._v(" "),a("p",[t._v("比较常见的包括：")]),t._v(" "),a("ul",[a("li",[t._v("cobar")]),t._v(" "),a("li",[t._v("TDDL")]),t._v(" "),a("li",[t._v("atlas")]),t._v(" "),a("li",[t._v("sharding-jdbc")]),t._v(" "),a("li",[t._v("mycat")])]),t._v(" "),a("p",[a("strong",[t._v("cobar")])]),t._v(" "),a("p",[t._v("阿里 b2b 团队开发和开源的，属于 proxy 层方案。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。")]),t._v(" "),a("p",[a("strong",[t._v("TDDL")])]),t._v(" "),a("p",[t._v("淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。")]),t._v(" "),a("p",[a("strong",[t._v("atlas")])]),t._v(" "),a("p",[t._v("360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。")]),t._v(" "),a("p",[a("strong",[t._v("ShardingSphere 项目（包括 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar）")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://images.xiaozhuanlan.com/photo/2021/3f162082cc6d23c632e451190e79a469.image",alt:"img"}})]),t._v(" "),a("p",[t._v("当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。")]),t._v(" "),a("p",[a("strong",[t._v("mycat")])]),t._v(" "),a("p",[t._v("基于 cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 sharding jdbc 来说，年轻一些，经历的锤炼少一些。")]),t._v(" "),a("h3",{attrs:{id:"分库分表后，数据怎么迁移呢"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表后，数据怎么迁移呢"}},[t._v("#")]),t._v(" 分库分表后，数据怎么迁移呢")]),t._v(" "),a("p",[t._v("分库分表之后，我们如何将老库（单库单表）的数据迁移到新库（分库分表后的数据库系统）呢？")]),t._v(" "),a("p",[t._v("比较简单同时也是非常常用的方案就是"),a("strong",[t._v("停机迁移")]),t._v("，写个脚本将单表数据写到新库。比如你在凌晨 2 点，系统使用的人数非常少的时候，挂一个公告说系统要维护升级预计 1 小时。然后，你写一个脚本将单表的数据写到新库。")]),t._v(" "),a("p",[t._v("如果你不想停机迁移数据的话，也可以考虑"),a("strong",[t._v("双写方案")]),t._v("。双写方案是针对那种不能停机迁移的场景，实现起来要稍微麻烦一些。具体原理是这样的：")]),t._v(" "),a("ul",[a("li",[t._v("对于程序层面呢，我们对老库的更新操作，同时也要写入分库分表后的数据库系统。这样就能保证，咱们新库里的数据是最新的。")]),t._v(" "),a("li",[t._v("另外，我们还要写一个脚本将老单机数据库的数据写入到分库分表后的数据库系统。")]),t._v(" "),a("li",[t._v("另外，我们还要写一个脚本来检查新库数据的准确性以及是否有遗漏的数据。")]),t._v(" "),a("li",[t._v("最后，如果老库完全迁移到新库，我们再把程序中的相关代码改过来就可以了。")])]),t._v(" "),a("p",[t._v("双写访问需要我们改动程序段的代码，没有一种不停机并且不用怎么改动程序员端代码的方法呢？")]),t._v(" "),a("p",[t._v("我们可以利用数据库同步工具 canal 来获取老库的 binlog 并解析，我们根据解析的结果将数据写入到新库中去。")]),t._v(" "),a("p",[a("strong",[t._v("TiDB")])]),t._v(" "),a("p",[t._v("另外的话，除了这分库分表种解决方案之外，目前还有很多公司使用了目前比较火的一个开源的分布式关系型数据库 "),a("strong",[t._v("TiDB")]),t._v("。")]),t._v(" "),a("p",[t._v("对于，TiDB 来说根本不用担心数据库存储压力，可以为我们节省很多事情。")]),t._v(" "),a("p",[t._v("并且，TiDB 天然支持水平扩容或者缩容、金融级高可用，并且，兼容 MySQL 5.7 协议和 MySQL 生态。非常适合高可用、强一致要求较高、数据规模较大等各种应用场景。")]),t._v(" "),a("h3",{attrs:{id:"分库分表后，id键如何处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表后，id键如何处理"}},[t._v("#")]),t._v(" 分库分表后，ID键如何处理")]),t._v(" "),a("p",[t._v("分库分表后不能每个表的ID都是从1开始，所以需要一个全局ID，设置全局ID主要有以下几种方法：")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("UUID：优点：本地生成ID，不需要远程调用；全局唯一不重复。缺点：占用空间大，不适合作为索引。")])]),t._v(" "),a("li",[a("p",[t._v("数据库自增ID：在分库分表表后使用数据库自增ID，需要一个专门用于生成主键的库，每次服务接收到请求，先向这个库中插入一条没有意义的数据，获取一个数据库自增的ID，利用这个ID去分库分表中写数据。优点：简单易实现。缺点：在高并发下存在瓶颈。系统结构如下图")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119140.png",alt:""}})])]),t._v(" "),a("li",[a("p",[t._v("Redis生成ID：优点：不依赖数据库，性能比较好。缺点：引入新的组件会使得系统复杂度增加")])]),t._v(" "),a("li",[a("p",[t._v("Twitter的snowflake算法：是一个64位的long型的ID，其中有1bit是不用的，41bit作为毫秒数， 10bit作为工作机器ID，12bit作为序列号。")]),t._v(" "),a("p",[t._v("1bit：第一个bit默认为0，因为二进制中第一个bit为1的话为负数，但是ID不能为负数.")]),t._v(" "),a("p",[t._v("41bit：表示的是时间戳，单位是毫秒。")]),t._v(" "),a("p",[t._v("10bit：记录工作机器ID，其中5个bit表示机房ID，5个bit表示机器ID。")]),t._v(" "),a("p",[t._v("12bit：用来记录同一毫秒内产生的不同ID。")])]),t._v(" "),a("li",[a("p",[t._v("美团的Leaf分布式ID生成系统，美团点评分布式ID生成系统")])])]),t._v(" "),a("p",[a("a",{attrs:{href:"https://tech.meituan.com/2017/04/21/mt-leaf.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Leaf——美团点评分布式ID生成系统 - 美团技术团队 (meituan.com)"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"分布式事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分布式事务"}},[t._v("#")]),t._v(" 分布式事务")]),t._v(" "),a("h3",{attrs:{id:"_1、分布式事务基础理论"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、分布式事务基础理论"}},[t._v("#")]),t._v(" 1、"),a("strong",[t._v("分布式事务基础理论")])]),t._v(" "),a("h5",{attrs:{id:"_1-cap-理论"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-cap-理论"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(1) CAP 理论")])]),t._v(" "),a("p",[t._v("CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能能同时满足以下三点中的两个：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("一致性（Consistence）")]),t._v(" : 所有节点访问同一份最新的数据副本")]),t._v(" "),a("li",[a("strong",[t._v("可用性（Availability）")]),t._v(": 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。")]),t._v(" "),a("li",[a("strong",[t._v("分区容错性（Partition tolerance）")]),t._v(" : 分布式系统出现网络分区的时候，仍然能够对外提供服务。")])]),t._v(" "),a("blockquote",[a("p",[t._v("分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。")])]),t._v(" "),a("p",[t._v("CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。因此，"),a("strong",[t._v("分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。")])]),t._v(" "),a("p",[a("strong",[t._v("为啥无同时保证 CA 呢？")])]),t._v(" "),a("p",[t._v("举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。")]),t._v(" "),a("p",[a("strong",[t._v("选择的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。")])]),t._v(" "),a("p",[a("strong",[t._v("CAP 实际应用案例")])]),t._v(" "),a("p",[t._v("我这里以注册中心来探讨一下 CAP 的实际应用。考虑到很多小伙伴不知道注册中心是干嘛的，这里简单以 Dubbo 为例说一说。下图是 Dubbo 的架构图。"),a("strong",[t._v("注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？")])]),t._v(" "),a("p",[t._v("注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119325.png",alt:"img"}})]),t._v(" "),a("p",[t._v("常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos...。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("ZooKeeper 保证的是 CP。")]),t._v(" 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。")]),t._v(" "),a("li",[a("strong",[t._v("Eureka 保证的则是 AP。")]),t._v(" Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。")]),t._v(" "),a("li",[a("strong",[t._v("Nacos 不仅支持 CP 也支持 AP。")])])]),t._v(" "),a("p",[a("strong",[t._v("总结")])]),t._v(" "),a("ul",[a("li",[t._v("在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。")]),t._v(" "),a("li",[t._v("在系统发生“分区”的情况下，CAP 理论只能满足 CP 或者 AP。要注意的是，这里的前提是系统发生了“分区”")]),t._v(" "),a("li",[t._v("如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。")])]),t._v(" "),a("p",[t._v("总结："),a("strong",[t._v("如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。")])]),t._v(" "),a("h5",{attrs:{id:"_2-base-理论"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-base-理论"}},[t._v("#")]),t._v(" (2) BASE 理论")]),t._v(" "),a("p",[a("strong",[t._v("BASE")]),t._v(" 是 "),a("strong",[t._v("Basically Available（基本可用）")]),t._v(" 、"),a("strong",[t._v("Soft-state（软状态）")]),t._v(" 和 "),a("strong",[t._v("Eventually Consistent（最终一致性）")]),t._v(" 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。")]),t._v(" "),a("p",[a("strong",[t._v("BASE 理论的核心思想")])]),t._v(" "),a("p",[t._v("即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。")]),t._v(" "),a("blockquote",[a("p",[t._v("也就是牺牲数据的强一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。")])]),t._v(" "),a("p",[a("strong",[t._v("BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。")])]),t._v(" "),a("p",[a("strong",[t._v("为什么这样说呢？")])]),t._v(" "),a("p",[t._v("CAP 理论这节我们也说过了：")]),t._v(" "),a("blockquote",[a("p",[t._v("如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，"),a("strong",[t._v("如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。")])])]),t._v(" "),a("p",[t._v("因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方")]),t._v(" "),a("p",[a("strong",[t._v("BASE")]),t._v(" "),a("strong",[t._v("理论三要素")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119387.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[t._v("1. 基本可用")])]),t._v(" "),a("p",[t._v("基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。")]),t._v(" "),a("p",[a("strong",[t._v("什么叫允许损失部分可用性呢？")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("响应时间上的损失")]),t._v(": 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。")]),t._v(" "),a("li",[a("strong",[t._v("系统功能上的损失")]),t._v("：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。")])]),t._v(" "),a("p",[a("strong",[t._v("2. 软状态")])]),t._v(" "),a("p",[t._v("软状态指允许系统中的数据存在中间状态（"),a("strong",[t._v("CAP 理论中的数据不一致")]),t._v("），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。")]),t._v(" "),a("p",[a("strong",[t._v("3. 最终一致性")])]),t._v(" "),a("p",[t._v("最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性")]),t._v(" "),a("blockquote",[a("p",[t._v("分布式一致性的 3 种级别：")]),t._v(" "),a("p",[a("strong",[t._v("强一致性")]),t._v(" ：系统写入了什么，读出来的就是什么。")]),t._v(" "),a("p",[a("strong",[t._v("弱一致性")]),t._v(" ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。")]),t._v(" "),a("p",[a("strong",[t._v("最终一致性")]),t._v(" ：弱一致性的升级版。，系统会保证在一定时间内达到数据一致的状态，"),a("strong",[t._v("业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。")])])]),t._v(" "),a("p",[t._v("总结")]),t._v(" "),a("p",[t._v("BASE 理论这块的话还可以结合分布式事务来谈。相关阅读："),a("a",{attrs:{href:"https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247494827&idx=1&sn=aa5d7401d53b1ca61b5e49462262bd22&chksm=cea1a360f9d62a761dff15a682f69fcacdd5b70a8afc4e1114cc7f6704b31d9aa3ad82ae5233&token=934329621&lang=zh_CN&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("阿里终面：分布式事务原理")]),a("OutboundLink")],1)]),t._v(" "),a("p",[a("strong",[t._v("ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。")])]),t._v(" "),a("h5",{attrs:{id:"_3-一致性的-3-种级别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-一致性的-3-种级别"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(3) 一致性的 3 种级别")])]),t._v(" "),a("p",[t._v("我们可以把对于系统一致性的要求分为下面 3 种级别：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119561.png",alt:"img"}})]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("强一致性")]),t._v(" ：系统写入了什么，读出来的就是什么。")]),t._v(" "),a("li",[a("strong",[t._v("弱一致性")]),t._v(" ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。")]),t._v(" "),a("li",[a("strong",[t._v("最终一致性")]),t._v(" ：弱一致性的升级版。系统会保证在一定时间内达到数据一致的状态，")])]),t._v(" "),a("p",[t._v("业界比较推崇是 "),a("strong",[t._v("最终一致性")]),t._v("，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。")]),t._v(" "),a("h5",{attrs:{id:"_4-柔性事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-柔性事务"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(4) 柔性事务")])]),t._v(" "),a("p",[t._v("互联网应用最关键的就是要保证高可用， 计算式系统几秒钟之内没办法使用都有可能造成数百万的损失。在此场景下，一些大佬们在 CAP 理论和 BASE 理论的基础上，提出了 "),a("strong",[t._v("柔性事务")]),t._v(" 的概念。")]),t._v(" "),a("p",[a("strong",[t._v("柔性事务追求的是最终一致性。")])]),t._v(" "),a("p",[t._v("实际上，柔性事务就是"),a("strong",[t._v("BASE 理论+业务实践")]),t._v("。 柔性事务追求的目标是：我们根据自身业务特性，通过适当的方式来保证系统数据的最终一致性。像"),a("strong",[t._v("TCC")]),t._v("、"),a("strong",[t._v("Saga")]),t._v("、"),a("strong",[t._v("MQ事务")]),t._v("、"),a("strong",[t._v("本地消息表")]),t._v(" 就属于柔性事务")]),t._v(" "),a("h5",{attrs:{id:"_5-刚性事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-刚性事务"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(5) 刚性事务")])]),t._v(" "),a("p",[t._v("与柔性事务相对的就是 "),a("strong",[t._v("刚性事务")]),t._v(" 了。前面我们说了，"),a("strong",[t._v("柔性事务追求的是最终一致性")]),t._v(" 。那么，与之对应，刚性事务追求的就是 "),a("strong",[t._v("强一致性")]),t._v("。像"),a("strong",[t._v("2PC")]),t._v(" 、"),a("strong",[t._v("3PC")]),t._v(" 就属于刚性事务。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119837.png",alt:"img"}})]),t._v(" "),a("h3",{attrs:{id:"_2、分布式事务解决方案"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、分布式事务解决方案"}},[t._v("#")]),t._v(" "),a("strong",[t._v("2、分布式事务解决方案")])]),t._v(" "),a("p",[t._v("分布式事务的解决方案有很多，比如："),a("strong",[t._v("2PC")]),t._v("、"),a("strong",[t._v("3PC")]),t._v("、"),a("strong",[t._v("TCC")]),t._v("、"),a("strong",[t._v("本地消息表")]),t._v("、"),a("strong",[t._v("MQ 事务")]),t._v("（Kafka 和 RocketMQ 都提供了事务相关功能） 、"),a("strong",[t._v("Saga")]),t._v(" 等等。这些方案的适用场景有所区别，我们需要根据具体的场景选择适合自己项目的解决方案。")]),t._v(" "),a("h5",{attrs:{id:"_1-2pc（两阶段提交协议）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2pc（两阶段提交协议）"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(1) 2PC（两阶段提交协议）")])]),t._v(" "),a("p",[t._v("2PC（Two-Phase Commit）这三个字母的含义:")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("2")]),t._v(" -> 指代事务提交的 2 个阶段")]),t._v(" "),a("li",[a("strong",[t._v("P")]),t._v("-> Prepare (准备阶段)")]),t._v(" "),a("li",[a("strong",[t._v("C")]),t._v(" ->Commit（提交阶段）")])]),t._v(" "),a("p",[t._v("2PC 将事务的提交过程分为 2 个阶段："),a("strong",[t._v("准备阶段")]),t._v(" 和 "),a("strong",[t._v("提交阶段")])]),t._v(" "),a("p",[a("strong",[t._v("准备阶段(Prepare)")])]),t._v(" "),a("p",[t._v("准备阶段的核心是“询问”事务参与者执行本地数据库事务操作是否成功")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("事务协调者/管理者")]),t._v(" 向所有参与者发送消息询问：“你是否可以执行事务操作呢？”，并等待其答复。")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 接收到消息之后，开始执行本地数据库事务预操作比如写 redo log/undo log 日志。但是 ，此时并不会提交事务！")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 如果执行本地数据库事务操作成功，那就回复：“就绪”，否则就回复：“未就绪”。")])]),t._v(" "),a("p",[a("strong",[t._v("提交阶段(Commit)")])]),t._v(" "),a("p",[t._v("提交阶段的核心是“询问”事务参与者提交事务是否成功。")]),t._v(" "),a("p",[t._v("当所有事务参与者都是“就绪”状态的话：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("事务协调者/管理者")]),t._v(' 向所有参与者发送消息："你们可以提交事务啦！"（'),a("strong",[t._v("commit 消息")]),t._v("）")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 接收到 "),a("strong",[t._v("commit 消息")]),t._v(" 后执行 "),a("strong",[t._v("提交本地数据库事务")]),t._v(" 操作，执行完成之后 "),a("strong",[t._v("释放整个事务期间所占用的资源")]),t._v("。")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 回复：“事务已经提交” （"),a("strong",[t._v("ack 消息")]),t._v("）。")]),t._v(" "),a("li",[a("strong",[t._v("事务协调者/管理者")]),t._v(" 收到所有 "),a("strong",[t._v("事务参与者")]),t._v(" 的 "),a("strong",[t._v("ack 消息")]),t._v(" 之后，整个分布式事务过程正式结束。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119404.png",alt:"img"}})]),t._v(" "),a("p",[t._v("当任一事务参与者是“未就绪”状态的话：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("事务协调者/管理者")]),t._v(" 向所有参与者发送消息：“你们可以执行回滚操作了！”（"),a("strong",[t._v("rollback 消息")]),t._v("）。")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 接收到 "),a("strong",[t._v("rollback 消息")]),t._v(" 后执行 "),a("strong",[t._v("本地数据库事务回滚")]),t._v(" 执行完成之后 "),a("strong",[t._v("释放整个事务期间所占用的资源")]),t._v("。")]),t._v(" "),a("li",[a("strong",[t._v("事务参与者")]),t._v(" 回复：“事务已经回滚” （"),a("strong",[t._v("ack 消息")]),t._v("）。")]),t._v(" "),a("li",[a("strong",[t._v("事务协调者/管理者")]),t._v(" 收到所有 "),a("strong",[t._v("事务参与者")]),t._v(" 的 "),a("strong",[t._v("ack 消息")]),t._v(" 之后，取消事务。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119114.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[t._v("总结")])]),t._v(" "),a("p",[t._v("简单总结一下 "),a("strong",[t._v("2PC")]),t._v(" 两阶段中比较重要的一些点：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("准备阶段")]),t._v(" 的主要目的是测试 "),a("strong",[t._v("事务参与者")]),t._v(" 能否执行 "),a("strong",[t._v("本地数据库事务")]),t._v(" 操作（!!!注意：这一步并不会提交事务）。")]),t._v(" "),a("li",[a("strong",[t._v("提交阶段")]),t._v(" 中 "),a("strong",[t._v("事务协调者/管理者")]),t._v(" 会根据 "),a("strong",[t._v("准备阶段")]),t._v(" 中 "),a("strong",[t._v("事务参与者")]),t._v(" 的消息来决定是执行事务提交还是回滚操作。")]),t._v(" "),a("li",[a("strong",[t._v("提交阶段")]),t._v(" 之后一定会结束当前的分布式事务")])]),t._v(" "),a("p",[a("strong",[t._v("2PC 的优点：")])]),t._v(" "),a("ul",[a("li",[t._v("实现起来非常简单，各大主流数据库比如 MySQL、Oracle 都有自己实现。")]),t._v(" "),a("li",[t._v("针对的是数据强一致性。不过，仍然可能存在数据不一致的情况。")])]),t._v(" "),a("p",[a("strong",[t._v("2PC 存在的问题：")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("同步阻塞")]),t._v(" ：事务参与者会在正式提交事务之前会一直占用相关的资源。比如用户小明转账给小红，那其他事务也要操作用户小明或小红的话，就会阻塞。")]),t._v(" "),a("li",[a("strong",[t._v("数据不一致")]),t._v(" ：由于网络问题或者事务协调者/管理者宕机都有可能会造成数据不一致的情况。比如在第2阶段（提交阶段），部分网络出现问题导致部分参与者收不到")]),t._v(" "),a("li",[a("strong",[t._v("单点问题")]),t._v(" ： 事务协调者/管理者在其中也是一个很重要的角色，如果事务协调者/管理者在准备(Prepare)阶段完成之后挂掉的话，事务参与者就会一直卡在提交(Commit)阶段")])]),t._v(" "),a("h5",{attrs:{id:"_2-3pc（三阶段提交协议）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3pc（三阶段提交协议）"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(2) 3PC（三阶段提交协议）")])]),t._v(" "),a("p",[t._v("3PC 是人们在 2PC 的基础上做了一些优化得到的。3PC 把 2PC 中的 "),a("strong",[t._v("准备阶段(Prepare)")]),t._v(" 做了进一步细化，分为 2 个阶段：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("询问阶段(CanCommit)")]),t._v(" ：这一步 不会执行事务操作，只会询问事务参与者能否执行本地数据库事操作。")]),t._v(" "),a("li",[a("strong",[t._v("准备阶段(PreCommit)")]),t._v(" ：当所有事物参与者都返回“可执行”之后， 事务参与者才会执行本地数据库事务预操作比如写 redo log/undo log 日志")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119290.png",alt:"img"}})]),t._v(" "),a("p",[t._v("除此之外，3PC 还引入了 "),a("strong",[t._v("超时机制")]),t._v(" 来避免事务参与者一直阻塞占用资源。")]),t._v(" "),a("h5",{attrs:{id:"_3-tcc（补偿事务）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-tcc（补偿事务）"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(3) TCC（补偿事务）")])]),t._v(" "),a("p",[t._v("TCC 属于目前比较火的一种柔性事务解决方案。简单来说，TCC 是 Try、Confirm、Cancel 三个词的缩写，它分为三个阶段：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("Try（尝试）阶段")]),t._v(" : 尝试执行。完成业务检查，并预留好必需的业务资源。")]),t._v(" "),a("li",[a("strong",[t._v("Confirm（确认）阶段")]),t._v(" ：确认执行。当所有事务参与者的 Try 阶段执行成功就会执行 Confirm ，Confirm 阶段会处理 Try 阶段预留的业务资源。否则，就会执行 Cancel 。")]),t._v(" "),a("li",[a("strong",[t._v("Cancel（取消）阶段")]),t._v(" ：取消执行，释放 Try 阶段预留的业务资源。")])]),t._v(" "),a("p",[t._v("我们拿转账场景来说：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("Try（尝试）阶段")]),t._v(" : 在转账场景下，Try 要做的事情是就是检查账户余额是否充足，预留的资源就是转账资金。")]),t._v(" "),a("li",[a("strong",[t._v("Confirm（确认）阶段")]),t._v(" ： 如果 Try 阶段执行成功的话，Confirm 阶段就会执行真正的扣钱操作。")]),t._v(" "),a("li",[a("strong",[t._v("Cancel（取消）阶段")]),t._v(" ：释放 Try 阶段预留的转账资金。")])]),t._v(" "),a("p",[t._v("一般情况下，当我们使用TCC模式的时候,需要自己实现 try, confirm, cancel 这三个方法，来达到最终一致性。也就是说，正常情况下会执行 try, confirm，如下图所示。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119413.png",alt:"img"}})]),t._v(" "),a("p",[t._v("出现异常的话会执行 try, cancel ，如下图所示")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119530.png",alt:"img"}})]),t._v(" "),a("p",[t._v("因此，"),a("strong",[t._v("TCC 模式不需要依赖于底层数据资源的事务支持，但是需要我们手动实现更多的代码")]),t._v("，属于 "),a("strong",[t._v("侵入业务代码")]),t._v(" 的一种分布式解决方案。")]),t._v(" "),a("p",[t._v("针对 TCC 的实现，业界也有一些不错的开源框架。不同的框架对于 TCC 的实现可能略有不同，不过大致思想都一样。")]),t._v(" "),a("ol",[a("li",[a("a",{attrs:{href:"https://github.com/liuyangming/ByteTCC",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("ByteTCC")]),a("OutboundLink")],1),t._v(" : ByteTCC 是基于 Try-Confirm-Cancel（TCC）机制的分布式事务管理器的实现。 相关阅读："),a("a",{attrs:{href:"https://www.bytesoft.org/how-to-impl-tcc/",target:"_blank",rel:"noopener noreferrer"}},[t._v("关于如何实现一个 TCC 分布式事务框架的一点思考"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://seata.io/zh-cn/index.html",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("Seata")]),a("OutboundLink")],1),t._v(" :Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。")]),t._v(" "),a("li",[a("a",{attrs:{href:"https://gitee.com/shuaiqiyu/hmily",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("Hmily")]),a("OutboundLink")],1),t._v(" : 金融级分布式事务解决方案。")])]),t._v(" "),a("h5",{attrs:{id:"_4-mq-事务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-mq-事务"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(4) MQ 事务")])]),t._v(" "),a("p",[t._v("RocketMQ 、 Kafka、Pulsar 、QMQ都提供了事务相关的功能。事务允许事件流应用将消费，处理，生产消息整个过程定义为一个原子操作。")]),t._v(" "),a("p",[t._v("这里我们拿 RocketMQ 来说（图源：《消息队列高手课》）。相关阅读："),a("a",{attrs:{href:"https://rocketmq.apache.org/docs/transaction-example/",target:"_blank",rel:"noopener noreferrer"}},[t._v("RocketMQ 事务消息参考文档"),a("OutboundLink")],1),t._v(" 。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119268.png",alt:"img"}})]),t._v(" "),a("ol",[a("li",[t._v("MQ 发送方（比如物流服务）在消息队列上开启一个事务，然后发送一个“半消息”给 MQ Server/Broker。事务提交之前，半消息对于 MQ 订阅方/消费者（比如第三方通知服务）不可见")]),t._v(" "),a("li",[t._v("“半消息”发送成功的话，MQ 发送方就开始执行本地事务。")]),t._v(" "),a("li",[t._v("MQ 发送方的本地事务执行成功的话，“半消息”变成正常消息，可以正常被消费。MQ 发送方的本地事务执行失败的话，会直接回滚。")])]),t._v(" "),a("p",[t._v("从上面的流程中可以看出，MQ 的事务消息使用的是两阶段提交（2PC），简单来说就是咱先发送半消息，等本地事务执行成功之后，半消息才变为正常消息。")]),t._v(" "),a("ul",[a("li",[t._v("优点：消息数据独立存储，独立伸缩，降低业务系统和消息系统之间的耦合。对最终一致性时间敏感度较高，降低业务被动方的实现成本。兼容所有实现JMS标准的MQ中间件，确保业务数据可靠的前提下，实现业务的最终一致性，理想状态下是准实时的一致性。")])]),t._v(" "),a("p",[a("strong",[t._v("如果 MQ 发送方提交或者回滚事务消息时失败怎么办？")])]),t._v(" "),a("p",[t._v("RocketMQ 中的 Broker 会定期去 MQ 发送方上反查这个事务的本地事务的执行情况，并根据反查结果决定提交或者回滚这个事务。事务反查机制的实现依赖于我们业务代码实现的对应的接口，比如你要查看创建物流信息的本地事务是否执行成功的话，直接在数据库中查询对应的物流信息是否存在即可。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119207.png",alt:"img"}})]),t._v(" "),a("p",[a("strong",[t._v("如果正常消息没有被正确消费怎么办呢？")])]),t._v(" "),a("p",[t._v("消息消费失败的话，RocketMQ 会自动进行消费重试。如果超过最大重试次数这个消息还是没有正确消费，RocketMQ 就会认为这个消息有问题，然后将其放到 "),a("strong",[t._v("死信队列")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119162.png",alt:"img"}})]),t._v(" "),a("p",[t._v("进入死信队列的消费一般需要人工处理，手动排查问题。")]),t._v(" "),a("p",[a("strong",[t._v("QMQ")]),t._v("  的事务消息就没有 RocketMQ 实现的那么复杂了，它借助了数据库自带的事务功能。其核心思想其实就是 eBay 提出的 "),a("strong",[t._v("本地消息表")]),t._v(" 方案，将分布式事务拆分成本地事务进行处理。")]),t._v(" "),a("p",[t._v("我们维护一个本地消息表用来存放消息发送的状态，保存消息发送情况到本地消息表的操作和业务操作要在一个事务里提交。这样的话，业务执行成功代表消息表也写入成功。")]),t._v(" "),a("p",[t._v("然后，我们再单独起一个线程定时轮询消息表，把没处理的消息发送到消息中间件。")]),t._v(" "),a("p",[t._v("消息发送成功后，更新消息状态为成功或者直接删除消息。")]),t._v(" "),a("p",[t._v("RocketMQ 的事务消息方案中，如果消息队列挂掉，数据库事务就无法执行了，整个应用也就挂掉了。")]),t._v(" "),a("p",[t._v("QMQ 的事务消息方案中，即使消息队列挂了也不会影响数据库事务的执行。")]),t._v(" "),a("p",[t._v("因此，QMQ 实现的方案能更加适应于大多数业务。不过，这种方法同样适用于其他消息队列，只能说 QMQ 封装的更好，开箱即用罢了！")]),t._v(" "),a("h5",{attrs:{id:"_5-saga"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-saga"}},[t._v("#")]),t._v(" "),a("strong",[t._v("(5) Saga")])]),t._v(" "),a("p",[t._v("Saga 绝对可以说是历史非常悠久了，Saga 属于长事务解决方案，其核心思想史将长事务拆分为多个本地短事务（本地短事务序列）。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119212.png",alt:"img"}})]),t._v(" "),a("ul",[a("li",[t._v("长事务 —> T1,T2 ~ Tn 个本地短事务")]),t._v(" "),a("li",[t._v("每个短事务都有一个补偿动作 —> C1,C2 ~ Cn")])]),t._v(" "),a("p",[t._v("下图来自于 "),a("a",{attrs:{href:"https://docs.microsoft.com/zh-cn/azure/architecture/reference-architectures/saga/saga",target:"_blank",rel:"noopener noreferrer"}},[t._v("微软技术文档—Saga 分布式事务"),a("OutboundLink")],1),t._v(" 。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119341.png",alt:"img"}})]),t._v(" "),a("p",[t._v("如果 T1,T2 ~ Tn 这些短事务都能顺利完成的话，整个事务也就顺利结束，否则，将采取恢复模式。")]),t._v(" "),a("p",[a("strong",[t._v("反向恢复")])]),t._v(" "),a("ul",[a("li",[t._v("简介：如果 Ti 短事务提交失败，则补偿所有已完成的事务（一直执行 Ci 对 Ti 进行补偿）")]),t._v(" "),a("li",[t._v("执行顺序：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。")])]),t._v(" "),a("p",[a("strong",[t._v("正向恢复")])]),t._v(" "),a("ul",[a("li",[t._v("简介：如果 Ti 短事务提交失败，则一直对 Ti 进行重试，直至成功为止。")]),t._v(" "),a("li",[t._v("执行顺序：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。")])]),t._v(" "),a("p",[t._v("和 TCC 类似，Saga 正向操作与补偿操作都需要业务开发者自己实现，因此也属于 "),a("strong",[t._v("侵入业务代码")]),t._v(" 的一种分布式解决方案。和 TCC 很大的一点不同是 Saga 没有Try动作，它的本地事务 Ti 直接被提交。因此，性能非常高！")]),t._v(" "),a("p",[t._v("理论上来说，补偿操作一定能够执行成功。不过，当网络出现问题或者服务器宕机的话，补偿操作也会执行失败。这种情况下，往往需要我们进行人工干预。并且，为了能够提高容错性（比如 Saga 系统本身也可能会崩溃），保证所有的短事务都得以提交或补偿，我们还需要将这些操作通过日志记录下来（Saga log，类似于数据库的日志机制）。这样，Saga 系统恢复之后，我们就知道短事务执行到哪里了或者补偿操作执行到哪里了。")]),t._v(" "),a("p",[t._v("另外，因为 Saga 没有进行“Try” 动作预留资源，所以不能保证隔离性。这也是 Saga 比较大的一个缺点。")]),t._v(" "),a("p",[t._v("针对 Saga 的实现，业界也有一些不错的开源框架。不同的框架对于 Saga 的实现可能略有不同，不过大致思想都一样。")]),t._v(" "),a("ol",[a("li",[a("a",{attrs:{href:"https://github.com/apache/servicecomb-pack",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("ServiceComb Pack")]),a("OutboundLink")],1),t._v(" ：微服务应用的数据最终一致性解决方案。")]),t._v(" "),a("li",[a("a",{attrs:{href:"https://seata.io/zh-cn/index.html",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("Seata")]),a("OutboundLink")],1),t._v(" : Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。SQL注入")])]),t._v(" "),a("h2",{attrs:{id:"数据库安全"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库安全"}},[t._v("#")]),t._v(" 数据库安全")]),t._v(" "),a("p",[t._v("数据库安全最常见的就是SQL注入")]),t._v(" "),a("p",[t._v("SQL 注入（SQL Injection）是发生在 Web 程序中数据库层的安全漏洞，是网站存在最多也是最简单的漏洞。主要原因是程序对用户输入数据的合法性没有判断和处理，导致攻击者可以在 Web 应用程序中事先定义好的 SQL 语句中添加额外的 SQL 语句，在管理员不知情的情况下实现非法操作，以此来实现欺骗数据库服务器执行非授权的任意查询，从而进一步获取到数据信息。")]),t._v(" "),a("p",[t._v("简而言之，SQL 注入就是在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。")]),t._v(" "),a("p",[t._v("SQL 注入已经成为互联网世界 Web 应用程序的最大风险，我们有必要从开发、测试、上线等各个环节对其进行防范。下面介绍 SQL 注入的原理及避免 SQL 注入的一些方法。")]),t._v(" "),a("h3",{attrs:{id:"sql注入的原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sql注入的原理"}},[t._v("#")]),t._v(" SQL注入的原理")]),t._v(" "),a("p",[t._v("SQL 注入的原理主要有以下 4 点：")]),t._v(" "),a("h5",{attrs:{id:"_1）恶意拼接查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1）恶意拼接查询"}},[t._v("#")]),t._v(" 1）恶意拼接查询")]),t._v(" "),a("p",[t._v("我们知道，SQL 语句可以查询、插入、更新和删除数据，且使用分号来分隔不同的命令。例如：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT * FROM users WHERE user_id = $user_id\n")])])]),a("p",[t._v("其中，user_id 是传入的参数，如果传入的参数值为“1234; DELETE FROM users”，那么最终的查询语句会变为：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT * FROM users WHERE user_id = 1234; DELETE FROM users\n")])])]),a("p",[t._v("如果以上语句执行，则会删除 users 表中的所有数据。")]),t._v(" "),a("h5",{attrs:{id:"_2）利用注释执行非法命令。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2）利用注释执行非法命令。"}},[t._v("#")]),t._v(" 2）利用注释执行非法命令。")]),t._v(" "),a("p",[t._v("SQL 语句中可以插入注释。例如：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT COUNT(*) AS 'num' FROM game_score WHERE game_id=24411 AND version=$version\n")])])]),a("p",[t._v("如果 version 包含了恶意的字符串"),a("code",[t._v("'-1' OR 3 AND SLEEP(500)--")]),t._v("，那么最终查询语句会变为：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT COUNT(*) AS 'num' FROM game_score WHERE game_id=24411 AND version='-1' OR 3 AND SLEEP(500)--\n")])])]),a("p",[t._v("以上恶意查询只是想耗尽系统资源，SLEEP(500) 将导致 SQL 语句一直运行。如果其中添加了修改、删除数据的恶意指令，那么将会造成更大的破坏。")]),t._v(" "),a("h5",{attrs:{id:"_3）传入非法参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3）传入非法参数"}},[t._v("#")]),t._v(" 3）传入非法参数")]),t._v(" "),a("p",[t._v("SQL 语句中传入的字符串参数是用单引号引起来的，如果字符串本身包含单引号而没有被处理，那么可能会篡改原本 SQL 语句的作用。 例如：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT * FROM user_name WHERE user_name = $user_name\n")])])]),a("p",[t._v("如果 user_name 传入参数值为 G'chen，那么最终的查询语句会变为：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT * FROM user_name WHERE user_name ='G'chen'\n")])])]),a("p",[t._v("一般情况下，以上语句会执行出错，这样的语句风险比较小。虽然没有语法错误，但可能会恶意产生 SQL 语句，并且以一种你不期望的方式运行。")]),t._v(" "),a("h5",{attrs:{id:"_4）添加额外条件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4）添加额外条件"}},[t._v("#")]),t._v(" 4）添加额外条件")]),t._v(" "),a("p",[t._v("在 SQL 语句中添加一些额外条件，以此来改变执行行为。条件一般为真值表达式。例如：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("UPDATE users SET userpass=' $userpass' WHERE user_id=$user_id;\n")])])]),a("p",[t._v("如果 user_id 被传入恶意的字符串“1234 OR TRUE”，那么最终的 SQL 语句会变为：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("UPDATE users SET userpass= '123456' WHERE user_id=1234 OR TRUE;\n")])])]),a("p",[t._v("这将更改所有用户的密码。")]),t._v(" "),a("h3",{attrs:{id:"避免sql注入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#避免sql注入"}},[t._v("#")]),t._v(" 避免SQL注入")]),t._v(" "),a("p",[t._v("对于 SQL 注入，我们可以采取适当的预防措施来保护数据安全。下面是避免 SQL 注入的一些方法。")]),t._v(" "),a("h5",{attrs:{id:"_1-过滤输入内容，校验字符串"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-过滤输入内容，校验字符串"}},[t._v("#")]),t._v(" 1. 过滤输入内容，校验字符串")]),t._v(" "),a("p",[t._v("过滤输入内容就是在数据提交到数据库之前，就把用户输入中的不合法字符剔除掉。可以使用编程语言提供的处理函数或自己的处理函数来进行过滤，还可以使用正则表达式匹配安全的字符串。")]),t._v(" "),a("p",[t._v("如果值属于特定的类型或有具体的格式，那么在拼接 SQL 语句之前就要进行校验，验证其有效性。比如对于某个传入的值，如果可以确定是整型，则要判断它是否为整型，在浏览器端（客户端）和服务器端都需要进行验证。")]),t._v(" "),a("h5",{attrs:{id:"_2-参数化查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-参数化查询"}},[t._v("#")]),t._v(" 2. 参数化查询")]),t._v(" "),a("p",[t._v("参数化查询目前被视作是预防 SQL 注入攻击最有效的方法。参数化查询是指在设计与数据库连接并访问数据时，在需要填入数值或数据的地方，使用参数（Parameter）来给值。")]),t._v(" "),a("p",[t._v("MySQL 的参数格式是以“?”字符加上参数名称而成，如下所示：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("UPDATE myTable SET c1 = ?c1, c2 = ?c2, c3 = ?c3 WHERE c4 = ?c4\n")])])]),a("p",[t._v("在使用参数化查询的情况下，数据库服务器不会将参数的内容视为 SQL 语句的一部分来进行处理，而是在数据库完成 SQL 语句的编译之后，才套用参数运行。因此就算参数中含有破坏性的指令，也不会被数据库所运行。")]),t._v(" "),a("h5",{attrs:{id:"_3-安全测试、安全审计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-安全测试、安全审计"}},[t._v("#")]),t._v(" 3. 安全测试、安全审计")]),t._v(" "),a("p",[t._v("除了开发规范，还需要合适的工具来确保代码的安全。我们应该在开发过程中应对代码进行审查，在测试环节使用工具进行扫描，上线后定期扫描安全漏洞。通过多个环节的检查，一般是可以避免 SQL 注入的。")]),t._v(" "),a("p",[t._v("有些人认为存储过程可以避免 SQL 注入，存储过程在传统行业里用得比较多，对于权限的控制是有一定用处的，但如果存储过程用到了动态查询，拼接 SQL，一样会存在安全隐患。")]),t._v(" "),a("p",[t._v("下面是在开发过程中可以避免 SQL 注入的一些方法。")]),t._v(" "),a("ol",[a("li",[t._v("避免使用动态SQL")])]),t._v(" "),a("p",[t._v("避免将用户的输入数据直接放入 SQL 语句中，最好使用准备好的语句和参数化查询，这样更安全。")]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("不要将敏感数据保留在纯文本中")])]),t._v(" "),a("p",[t._v("加密存储在数据库中的私有/机密数据，这样可以提供了另一级保护，以防攻击者成功地排出敏感数据。")]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v("限制数据库权限和特权")])]),t._v(" "),a("p",[t._v("将数据库用户的功能设置为最低要求；这将限制攻击者在设法获取访问权限时可以执行的操作。")]),t._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[t._v("避免直接向用户显示数据库错误")])]),t._v(" "),a("p",[t._v("攻击者可以使用这些错误消息来获取有关数据库的信息。")]),t._v(" "),a("h2",{attrs:{id:"explain执行计划（性能调优全套）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#explain执行计划（性能调优全套）"}},[t._v("#")]),t._v(" Explain执行计划（性能调优全套）")]),t._v(" "),a("p",[t._v("这个比较重要，面试中经常考所以拎出来单独说")]),t._v(" "),a("h3",{attrs:{id:"一、性能优化的思路"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、性能优化的思路"}},[t._v("#")]),t._v(" 一、性能优化的思路")]),t._v(" "),a("ol",[a("li",[t._v("首先需要使用【慢查询日志】功能，去获取所有查询时间比较长的SQL语句")]),t._v(" "),a("li",[t._v("查看执行计划，查看有问题的SQL的执行计划")]),t._v(" "),a("li",[t._v("针对查询慢的SQL语句进行优化")]),t._v(" "),a("li",[t._v("使用【show profile[s]】 查看有问题的SQL的性能使用情况")]),t._v(" "),a("li",[t._v("调整操作系统参数优化")]),t._v(" "),a("li",[t._v("升级服务器硬件")])]),t._v(" "),a("h3",{attrs:{id:"二、慢查询日志"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、慢查询日志"}},[t._v("#")]),t._v(" 二、慢查询日志")]),t._v(" "),a("h5",{attrs:{id:"_1、慢查询日志介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、慢查询日志介绍"}},[t._v("#")]),t._v(" 1、慢查询日志介绍")]),t._v(" "),a("p",[t._v("数据库查询快慢是影响项目性能的一大因素，对于数据库，我们除了要优化 SQL，更重要的是得先找到 需要优化的SQL。MySQL数据库有一个“慢查询日志”功能，用来记录查询时间超过某个设定值的SQL语 句，这将极大程度帮助我们快速定位到症结所在，以便对症下药。")]),t._v(" "),a("p",[t._v("MySQL的慢查询日志功能"),a("strong",[t._v("默认是关闭的")]),t._v("，需要手动开启。")]),t._v(" "),a("h5",{attrs:{id:"_2、开启慢查询功能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、开启慢查询功能"}},[t._v("#")]),t._v(" 2、开启慢查询功能")]),t._v(" "),a("ul",[a("li",[t._v("查看是否开启慢查询功能")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119365.png",alt:"image-20220427120111014"}})]),t._v(" "),a("p",[t._v("参数说明：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("- 【slow_query_log】 ：是否开启慢查询日志，1为开启，0为关闭。\n- 【log-slow-queries】 ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参\n数，系统则会默认给一个缺省的文件host_name-slow.log\n- 【slow-query-log-file】：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置\n该参数，系统则会默认给一个缺省的文件host_name-slow.log\n- 【long_query_time】 ：慢查询阈值，当查询时间多于设定的阈值时，记录日志，【单位为秒】。\n")])])]),a("ul",[a("li",[t._v("临时开启慢查询功能")])]),t._v(" "),a("p",[t._v("在 MySQL 执行 SQL 语句设置，但是如果重启 MySQL 的话将失效")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" slow_query_log "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" long_query_time "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("ul",[a("li",[t._v("永久开启慢查询功能")])]),t._v(" "),a("p",[t._v("修改/etc/my.cnf配置文件，重启 MySQL, 这种永久生效.")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("mysqld"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nslow_query_log"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v("\nlong_query_time"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h5",{attrs:{id:"_3、慢查询日志格式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、慢查询日志格式"}},[t._v("#")]),t._v(" 3、慢查询日志格式")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119798.png",alt:"image-20220429153836388"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119828.png",alt:"image-20220429153845500"}})]),t._v(" "),a("p",[t._v("格式说明：")]),t._v(" "),a("ul",[a("li",[t._v("第一行,SQL查询执行的具体时间")]),t._v(" "),a("li",[t._v("第二行,执行SQL查询的连接信息，用户和连接IP")]),t._v(" "),a("li",[t._v("第三行,记录了一些我们比较有用的信息，如下解析")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Query_time,这条SQL执行的时间,越长则越慢\nLock_time,在MySQL服务器阶段(不是在存储引擎阶段)等待表锁时间\nRows_sent,查询返回的行数\nRows_examined,查询检查的行数，越长就当然越费时间\n")])])]),a("ul",[a("li",[t._v("第四行,设置时间戳，没有实际意义，只是和第一行对应执行时间。")]),t._v(" "),a("li",[t._v("第五行及后面所有行（第二个# Time:之前）,执行的sql语句记录信息，因为sql可能会很长。")])]),t._v(" "),a("h5",{attrs:{id:"_4、分析慢查询日志的工具"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4、分析慢查询日志的工具"}},[t._v("#")]),t._v(" 4、分析慢查询日志的工具")]),t._v(" "),a("p",[t._v("使用mysqldumpslow工具，mysqldumpslow是MySQL自带的慢查询日志工具。可以使用 mysqldumpslow工具搜索慢查询日志中的SQL语句。")]),t._v(" "),a("p",[t._v("得到按照时间排序的前10条里面含有左连接的查询语句：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('[root@localhost mysql]# mysqldumpslow -s t -t 10 -g "left join"\n/var/lib/mysql/slow.log\n')])])]),a("p",[a("strong",[t._v("常用参数说明：")])]),t._v(" "),a("p",[t._v("-s：是表示按照何种方式排序")]),t._v(" "),a("blockquote",[a("p",[t._v("al 平均锁定时间")]),t._v(" "),a("p",[t._v("ar 平均返回记录时间")]),t._v(" "),a("p",[t._v("at 平均查询时间（默认）")]),t._v(" "),a("p",[t._v("c 计数")]),t._v(" "),a("p",[t._v("l 锁定时间")]),t._v(" "),a("p",[t._v("r 返回记录")]),t._v(" "),a("p",[t._v("t 查询时间")])]),t._v(" "),a("p",[t._v("-t：是top n的意思，即为返回前面多少条的数据")]),t._v(" "),a("p",[t._v("-g：后边可以写一个正则匹配模式，大小写不敏感的")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("[root@mysql132 mysql]# mysqldumpslow -s t /var/lib/mysql/mysql132-slow.log\nReading mysql slow query log from /var/lib/mysql/mysql132-slow.log\nCount: 1 Time=143.16s (143s) Lock=0.00s (0s) Rows=27907961.0 (27907961),\nroot[root]@localhost\nselect * from t_slow a left join t_slow b on a.name=b.name\nCount: 5 Time=5.80s (28s) Lock=0.00s (0s) Rows=0.0 (0), root[root]@localhost\ninsert into t_slow(name,address) select name,address from t_slow\nCount: 1 Time=3.01s (3s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost\nselect sleep(N)\n")])])]),a("h3",{attrs:{id:"三、查看执行计划"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、查看执行计划"}},[t._v("#")]),t._v(" 三、查看执行计划")]),t._v(" "),a("h5",{attrs:{id:"_1、建表语句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、建表语句"}},[t._v("#")]),t._v(" 1、建表语句")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("create table tuser(\n\tid int primary key auto_increment，\n\tname varchar(100),\n\tage int,\n\tsex char(1),\n\taddress varchar(100)\n);\nalter table tuser add index idx_name_age(name(100),age);\nalter table tuser add index idx_sex(sex(1));\ninsert into tuser(id,name,age,sex,address) values (1,'zhangsan',20,'1','北京');\ninsert into tuser(id,name,age,sex,address) values (2,'lisi',16,'1','上海');\ninsert into tuser(id,name,age,sex,address) values (3,'wangwu',34,'1','杭州');\ninsert into tuser(id,name,age,sex,address) values (4,'wangxin',26,'2','广州');\ninsert into tuser(id,name,age,sex,address) values (5,'wudi',18,'2','上海');\n")])])]),a("h5",{attrs:{id:"_2、介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、介绍"}},[t._v("#")]),t._v(" 2、介绍")]),t._v(" "),a("p",[t._v("MySQL 提供了一个 "),a("strong",[t._v("EXPLAIN")]),t._v(" 命令, 它可以对 SELECT 语句的执行计划进行分析, 并输出 SELECT 执行的 详细信息, 以供开发人员针对性优化")]),t._v(" "),a("p",[t._v("使用explain这个命令来查看一个这些SQL语句的执行计划，查看该SQL语句有没有使用上了索引，有没有做全表扫描，这都可以通过explain命令来查看。")]),t._v(" "),a("p",[t._v("可以通过explain命令深入了解MySQL的基于开销的优化器，还可以获得很多可能被优化器考虑到的访 问策略的细节，以及当运行SQL语句时哪种策略预计会被优化器采用。")]),t._v(" "),a("p",[t._v("EXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 explain 就可以了, 例如:")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119861.png",alt:"image-20220429155600806"}})]),t._v(" "),a("h5",{attrs:{id:"_3、参数说明"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、参数说明"}},[t._v("#")]),t._v(" 3、参数说明")]),t._v(" "),a("p",[t._v("EXPLAIN 命令的输出内容大致如下:")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("mysql> explain select * from tuser where id = 2 \\G\n        *************************** 1. row ***************************\n        id: 1\n        select_type: SIMPLE\n        table: tuser\n        partitions: NULL\n        type: const\n        possible_keys: PRIMARY\n        key: PRIMARY\n        key_len: 4\n        ref: const\n        rows: 1\n        filtered: 100.00\n        Extra: NULL\n        1 row in set, 1 warning (0.01 sec)\n")])])]),a("p",[t._v("各列的含义如下:")]),t._v(" "),a("ul",[a("li",[t._v("id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.")]),t._v(" "),a("li",[a("strong",[t._v("select_type")]),t._v(": SELECT 查询的类型")]),t._v(" "),a("li",[t._v("table: 查询的是哪个表")]),t._v(" "),a("li",[t._v("partitions: 匹配的分区")]),t._v(" "),a("li",[a("strong",[t._v("type")]),t._v(": join 类型")]),t._v(" "),a("li",[t._v("possible_keys: 此次查询中可能选用的索引")]),t._v(" "),a("li",[t._v("key: 此次查询中确切使用到的索引")]),t._v(" "),a("li",[t._v("ref: 哪个字段或常数与 key 一起被使用")]),t._v(" "),a("li",[t._v("rows: 显示此查询一共扫描了多少行. 这个是一个估计值.")]),t._v(" "),a("li",[t._v("filtered: 表示此查询条件所过滤的数据的百分比")]),t._v(" "),a("li",[a("strong",[t._v("extra")]),t._v(": 额外的信息")])]),t._v(" "),a("p",[a("strong",[t._v("1）id")])]),t._v(" "),a("p",[t._v("每个单位查询的SELECT语句都会自动分配的一个唯一标识符，表示查询中操作表的顺序，有四种情况：")]),t._v(" "),a("ul",[a("li",[t._v("id相同：执行顺序由上到下")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119021.png",alt:"image-20220429155925627"}})]),t._v(" "),a("ul",[a("li",[t._v("id不同：如果是子查询，id号会自增，id越大，优先级越高")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119854.png",alt:"image-20220429155945017"}})]),t._v(" "),a("ul",[a("li",[t._v("id有相同，也有不同，同时存在。id相同的可以认为是一组，从上往下顺序执行；在所有的组中，id的值越大，优先级越高，越先执行。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119938.png",alt:""}})]),t._v(" "),a("p",[a("strong",[t._v("2）select_type（重要）")])]),t._v(" "),a("p",[a("strong",[t._v("单位查询的查询类型")]),t._v("，比如："),a("strong",[t._v("普通查询")]),t._v("、"),a("strong",[t._v("联合查询(union、union all)")]),t._v("、"),a("strong",[t._v("子查询等复杂查询")]),t._v("。")]),t._v(" "),a("p",[a("strong",[t._v("simple")])]),t._v(" "),a("p",[t._v("表示不需要union操作或者不包含子查询的简单select查询。有连接查询时，外层的查询为simple。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119255.png",alt:"image-20220429160328917"}})]),t._v(" "),a("p",[a("strong",[t._v("primary")])]),t._v(" "),a("p",[t._v("一个需要union操作或者含有子查询的select，位于最外层的单位查询的select_type即为primary")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119271.png",alt:"image-20220429160353446"}})]),t._v(" "),a("p",[a("strong",[t._v("union")])]),t._v(" "),a("p",[t._v("union连接的两个select查询，第一个查询是dervied派生表，除了第一个表外，第二个以后的表 select_type都是union")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119281.png",alt:"image-20220429160411029"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119264.png",alt:"image-20220429160417044"}})]),t._v(" "),a("ul",[a("li",[t._v("DERIVED 在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查 询，把结果放在临时表中")]),t._v(" "),a("li",[t._v("UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的 子查询中，外层SELECT将被标记为：DERIVED")]),t._v(" "),a("li",[t._v("UNION RESULT 从UNION表获取结果的SELECT")])]),t._v(" "),a("p",[a("strong",[t._v("dependent union")])]),t._v(" "),a("p",[t._v("与union一样，出现在union 或union all语句中，但是这个查询要受到外部查询的影响")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119366.png",alt:"image-20220429160903836"}})]),t._v(" "),a("p",[t._v("union result")]),t._v(" "),a("p",[t._v("包含union的结果集，在union和union all语句中,因为它不需要参与查询，所以id字段为null")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119536.png",alt:"image-20220429160919087"}})]),t._v(" "),a("p",[a("strong",[t._v("subquery")])]),t._v(" "),a("p",[t._v("除了from字句中包含的子查询外，其他地方出现的子查询都可能是subquery")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119831.png",alt:"image-20220429160944635"}})]),t._v(" "),a("p",[a("strong",[t._v("dependent subquery")])]),t._v(" "),a("p",[t._v("与dependent union类似，表示这个subquery的查询要受到外部表查询的影响")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119682.png",alt:"image-20220429161029389"}})]),t._v(" "),a("p",[a("strong",[t._v("derived")])]),t._v(" "),a("p",[t._v("from字句中出现的子查询，也叫做派生表，其他数据库中可能叫做内联视图或嵌套select")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119705.png",alt:"image-20220429161053888"}})]),t._v(" "),a("p",[a("strong",[t._v("3）table")])]),t._v(" "),a("p",[t._v("显示的单位查询的表名，有如下几种情况：")]),t._v(" "),a("ul",[a("li",[t._v("如果查询使用了别名，那么这里显示的是别名")]),t._v(" "),a("li",[t._v("如果不涉及对数据表的操作，那么这显示为null")]),t._v(" "),a("li",[t._v("如果显示为尖括号括起来的就表示这个是临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生")]),t._v(" "),a("li",[t._v("如果是尖括号括起来的<union M,N>，与类似，也是一个临时表，表示这个结果来自于union查询的id为M,N的结果集。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119845.png",alt:"image-20220429161711709"}})]),t._v(" "),a("p",[a("strong",[t._v("4）partitions")])]),t._v(" "),a("p",[t._v("使用的哪些分区（对于非分区表值为null）。")]),t._v(" "),a("p",[t._v("5.7之后的版本默认会有 partitions 和 filtered两列，但是5.6版本中是没有的，需要")]),t._v(" "),a("p",[t._v("使用explain partitions select ……来显示带有partitions 的列，")]),t._v(" "),a("p",[t._v("使用explain extended select ……来显示带有filtered的列。")]),t._v(" "),a("blockquote",[a("p",[t._v("什么是分区表？")]),t._v(" "),a("p",[t._v("mysql内部实现的表的水平拆分，所有数据还在一个表中，但物理存储根据一定的规则放在不同 的文件中。这个是mysql支持的功能，业务代码无需改动。")])]),t._v(" "),a("p",[a("strong",[t._v("5）type（重要）")])]),t._v(" "),a("p",[t._v("显示的是单位查询的"),a("strong",[t._v("连接类型")]),t._v("或者理解为"),a("strong",[t._v("访问类型")]),t._v("，访问性能依次从好到差：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("system\nconst\neq_ref\nref\nfulltext\nref_or_null\nunique_subquery\nindex_subquery\nrange\nindex_merge\nindex\nALL\n")])])]),a("p",[t._v("注意事项：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 除了all之外，其他的type都可以使用到索引\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 除了index_merge之外，其他的type只可以用到一个索引\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" 最少要使用到range级别\n")])])]),a("p",[a("strong",[t._v("system")])]),t._v(" "),a("p",[t._v("表中"),a("strong",[t._v("只有一行数据或者是空表")]),t._v("。等于系统表，这是const类型的特列，平时不会出现，这个也可以忽略不计")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119828.png",alt:"image-20220429163836654"}})]),t._v(" "),a("blockquote",[a("p",[t._v("注：上图为mysql5.6效果，mysql5.7只有一行计划而且select_type为simple")])]),t._v(" "),a("p",[a("strong",[t._v("const（重要）")])]),t._v(" "),a("p",[t._v("使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。其他数据库也叫做唯一索引扫描。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119871.png",alt:"image-20220429163938349"}})]),t._v(" "),a("p",[a("strong",[t._v("ref（重要）")])]),t._v(" "),a("p",[t._v("非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体。")]),t._v(" "),a("ul",[a("li",[t._v("组合索引")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119217.png",alt:"image-20220429164010497"}})]),t._v(" "),a("ul",[a("li",[t._v("非唯一索引")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119123.png",alt:"image-20220429164024643"}})]),t._v(" "),a("p",[a("strong",[t._v("fulltext")])]),t._v(" "),a("p",[t._v("全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引")]),t._v(" "),a("p",[a("strong",[t._v("ref_or_null")])]),t._v(" "),a("p",[t._v("与ref方法类似，只是增加了null值的比较。实际用的不多。")]),t._v(" "),a("p",[a("strong",[t._v("unique_subquery")])]),t._v(" "),a("p",[t._v("用于where中的in形式子查询，子查询返回不重复值唯一值")]),t._v(" "),a("p",[a("strong",[t._v("index_subquery")])]),t._v(" "),a("p",[t._v("用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重。")]),t._v(" "),a("p",[a("strong",[t._v("range（重要）")])]),t._v(" "),a("p",[t._v("索引范围扫描，常见于使用>,<,is null,between ,in ,like等运算符的查询中。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119273.png",alt:"image-20220429175034653"}})]),t._v(" "),a("p",[a("strong",[t._v("index_merge")])]),t._v(" "),a("p",[t._v("表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方 排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如range")]),t._v(" "),a("p",[a("strong",[t._v("index（重要）")])]),t._v(" "),a("p",[t._v("select结果列中使用到了索引，type会显示为index。")]),t._v(" "),a("p",[t._v("全部索引扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119250.png",alt:"image-20220429175234718"}})]),t._v(" "),a("p",[a("strong",[t._v("all（重要）")])]),t._v(" "),a("p",[t._v("这个就是全表扫描数据文件，然后再在"),a("strong",[t._v("server层进行过滤")]),t._v("返回符合要求的记录。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119271.png",alt:"image-20220429175330765"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119297.png",alt:"image-20220429175340942"}})]),t._v(" "),a("p",[a("strong",[t._v("6）possible_keys")])]),t._v(" "),a("p",[t._v("此次查询中可能选用的索引，一个或多个")]),t._v(" "),a("p",[a("strong",[t._v("7）key")])]),t._v(" "),a("p",[t._v("查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个。")]),t._v(" "),a("p",[a("strong",[t._v("8）key_len")])]),t._v(" "),a("p",[t._v("key_len越小 索引效果越好。")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("key_len的长度计算公式：\nvarchr(10)变长字段且允许NULL = 10 * ( character set：\nutf8=3,gbk=2,latin1=1)+1(NULL)+2(变长字段)\nvarchr(10)变长字段且不允许NULL = 10 *( character set：utf8=3,gbk=2,latin1=1)+2(变长\n字段)\nchar(10)固定字段且允许NULL = 10 * ( character set：\nutf8=3,gbk=2,latin1=1)+1(NULL)\nchar(10)固定字段且不允许NULL = 10 * ( character set：utf8=3,gbk=2,latin1=1)\nbigint的长度是8bytes\nint key_len长度是4 ，typeint的长度是1\nsmallint 长度是2 middleint长度是3\n")])])]),a("ul",[a("li",[t._v("用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。")]),t._v(" "),a("li",[t._v("留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了。")]),t._v(" "),a("li",[t._v("另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到 key_len中。")])]),t._v(" "),a("p",[a("strong",[t._v("9）ref")])]),t._v(" "),a("ul",[a("li",[t._v("如果是使用的常数等值查询，这里会显示const")]),t._v(" "),a("li",[t._v("如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段")]),t._v(" "),a("li",[t._v("如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func")])]),t._v(" "),a("p",[a("strong",[t._v("10）rows")])]),t._v(" "),a("p",[t._v("这里是执行计划中估算的扫描行数，不是精确值（InnoDB不是精确的值，MyISAM是精确的值，主要原因是InnoDB里面使用了MVCC并发机制）")]),t._v(" "),a("p",[a("strong",[t._v("11）filtered")])]),t._v(" "),a("p",[t._v("filtered列指示将由mysql server层需要对存储引擎层返回的记录进行筛选的估计百分比，也就是说存储 引擎层返回的结果中包含有效记录数的百分比。最大值为100，这意味着没有对行进行筛选。值从100 减小表示过滤量增加。rows显示检查的估计行数，rows×filtered显示将与下表联接的行数。例如，如 果rows为1000，filtered为50.00（50%），则要与下表联接的行数为1000×50%=500。")]),t._v(" "),a("p",[a("strong",[t._v("12）extra（重要）")])]),t._v(" "),a("p",[t._v("这个列包含不适合在其他列中显示单十分重要的额外的信息，这个列可以显示的信息非常多，有几十种")]),t._v(" "),a("p",[a("strong",[t._v("Using filesort")])]),t._v(" "),a("p",[t._v("说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利 用索引完成的排序操作称为“文件排序”。需要优化sql。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119743.png",alt:"image-20220429180733122"}})]),t._v(" "),a("p",[a("strong",[t._v("Using temporary")])]),t._v(" "),a("p",[t._v("使用了用临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序order by和分组查询group by。需要优化SQL")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119811.png",alt:"image-20220429180801665"}})]),t._v(" "),a("p",[a("strong",[t._v("using index（重要）")])]),t._v(" "),a("p",[t._v("查询时"),a("strong",[t._v("不需要回表查询")]),t._v("，直接通过索引就可以获取查询的结果数据。")]),t._v(" "),a("ul",[a("li",[t._v("表示相应的SELECT查询中使用到了覆盖索引（Covering Index），避免访问表的数据行，效率不错！")]),t._v(" "),a("li",[t._v("如果同时出现Using Where ，说明索引被用来执行查找索引键值")]),t._v(" "),a("li",[t._v("如果没有同时出现Using Where ，表明索引用来读取数据而非执行查找动作。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119768.png",alt:"image-20220429180842060"}})]),t._v(" "),a("p",[a("strong",[t._v("using where（重要）")])]),t._v(" "),a("p",[t._v("表示Mysql将对storage engine提取的结果进行过滤，过滤条件字段无索引；")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119804.png",alt:"image-20220429180902196"}})]),t._v(" "),a("p",[a("strong",[t._v("Using join buffer")])]),t._v(" "),a("p",[t._v("表明使用了连接缓存,比如说在查询的时候，多表join的次数非常多，那么将配置文件中的缓冲区的join buffer调大一些。")]),t._v(" "),a("p",[a("strong",[t._v("impossible where")])]),t._v(" "),a("p",[t._v("where子句的值总是false ，不能用来获取任何元组")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" t_user "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2'")]),t._v("\n")])])]),a("h3",{attrs:{id:"四、sql语句优化（开发人员）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四、sql语句优化（开发人员）"}},[t._v("#")]),t._v(" 四、SQL语句优化（开发人员）")]),t._v(" "),a("h5",{attrs:{id:"_1、索引优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、索引优化"}},[t._v("#")]),t._v(" "),a("strong",[t._v("1、索引优化")])]),t._v(" "),a("ul",[a("li",[t._v("为搜索字段（where中的条件）、排序字段、select查询列，创建合适的索引，不过要考虑数据的 业务场景：查询多还是增删多？")]),t._v(" "),a("li",[t._v("尽量建立组合索引并注意组合索引的创建顺序，按照顺序组织查询条件、尽量将筛选粒度大的查询 条件放到最左边")]),t._v(" "),a("li",[t._v("尽量使用"),a("strong",[t._v("覆盖索引")]),t._v("，SELECT语句中尽量不要使用*。")]),t._v(" "),a("li",[t._v("order by、group by语句要尽量使用到索引")]),t._v(" "),a("li",[t._v("索引长度尽量短，短索引可以节省索引空间，使查找的速度得到提升，同时内存中也可以装载更多的索引键值。太长的列，可以选择建立前缀索引")]),t._v(" "),a("li",[t._v("索引更新不能频繁，更新非常频繁的数据不适宜建索引，因为维护索引的成本。")]),t._v(" "),a("li",[t._v("order by的索引生效，order by排序应该遵循最佳左前缀查询，如果是使用多个索引字段进行排序，那么排序的规则必须相同（同是升序或者降序），否则索引同样会失效。")])]),t._v(" "),a("h5",{attrs:{id:"_2、limit优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、limit优化"}},[t._v("#")]),t._v(" "),a("strong",[t._v("2、LIMIT优化")])]),t._v(" "),a("ul",[a("li",[t._v("如果预计SELECT语句的查询结果是一条，最好使用 LIMIT 1，可以停止全表扫描")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("SELECT * FROM user WHERE username=’全力詹’; -- username没有建立唯一索引\nSELECT * FROM user WHERE username=’全力詹’ LIMIT 1;\n")])])]),a("ul",[a("li",[a("p",[t._v("处理分页会使用到 LIMIT ，当翻页到非常靠后的页面的时候，偏移量会非常大，这时LIMIT的效率 会非常差。 LIMIT OFFSET , SIZE；")]),t._v(" "),a("p",[t._v("LIMIT的优化问题，其实是 OFFSET 的问题，它会导致MySql扫描大量不需要的行然后再抛弃掉。")])])]),t._v(" "),a("p",[a("strong",[t._v("解决方案")]),t._v("：单表分页时，使用自增主键排序之后，先使用where条件 id > offset值，limit后面只写 rows")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select * from (select * from tuser2 where id > 1000000 and id < 1000500\nORDER BY id) t limit 0, 20\n")])])]),a("h5",{attrs:{id:"_3、其他查询优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、其他查询优化"}},[t._v("#")]),t._v(" "),a("strong",[t._v("3、其他查询优化")])]),t._v(" "),a("ul",[a("li",[t._v("小表驱动大表，建议使用left join时，以小表关联大表，因为使用join的话，第一张表是必须全扫描的，以少关联多就可以减少这个扫描次数。")]),t._v(" "),a("li",[t._v("避免全表扫描，mysql在使用不等于(!=或者<>)的时候无法使用索引导致全表扫描。在查询的时 候，如果对索引使用不等于的操作将会导致索引失效，进行全表扫描")]),t._v(" "),a("li",[t._v("避免mysql放弃索引查询，如果mysql估计使用全表扫描要比使用索引快，则不使用索引。（最典型的场景就是数据量少的时候）")]),t._v(" "),a("li",[t._v("尽量不使用count(*)、尽量使用count（主键）")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("COUNT(*)： 查询行数，是会遍历所有的行、所有的列。\nCOUNT（列）：查询指定列不为null的行数（过滤null），如果列可以为空，则COUNT（*）不等于\nCOUNT(列)，除非指定的列是非空的列才会让COUNT（*）等于\nCOUNT(列)\nCOUNT（伪列）：比如COUNT（1）\n")])])]),a("ul",[a("li",[t._v("JOIN两张表的关联字段最好都建立索引，而且最好字段类型是一样的。")]),t._v(" "),a("li",[t._v("WHERE条件中尽量不要使用not in语句（建议使用not exists）")]),t._v(" "),a("li",[t._v("合理利用慢查询日志、explain执行计划查询、show profile查看SQL执行时的资源使用情况。")])]),t._v(" "),a("h3",{attrs:{id:"五、profile分析语句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#五、profile分析语句"}},[t._v("#")]),t._v(" 五、profile分析语句")]),t._v(" "),a("h5",{attrs:{id:"_1、介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、介绍"}},[t._v("#")]),t._v(" 1、介绍")]),t._v(" "),a("p",[t._v("Query Profiler是MySQL自带的一种"),a("strong",[t._v("query诊断分析工具")]),t._v("，通过它可以分析出一条SQL语句的硬件性能瓶颈在什么地方")]),t._v(" "),a("p",[a("strong",[t._v("通常我们是使用的explain,以及slow query log都无法做到精确分析，但是Query Profiler却可以定位 出一条SQL语句执行的各种资源消耗情况")]),t._v("，比如CPU，IO等，以及该SQL执行所耗费的时间等。不过该工具只有在MySQL 5.0.37以及以上版本中才有实现。")]),t._v(" "),a("p",[a("strong",[t._v("默认的情况下，MYSQL的该功能没有打开，需要自己手动启动。")])]),t._v(" "),a("h5",{attrs:{id:"_2、开启profile功能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、开启profile功能"}},[t._v("#")]),t._v(" 2、开启Profile功能")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Profile 功能由MySQL会话变量 : profiling控制,默认是OFF关闭状态。")])]),t._v(" "),a("li",[a("p",[t._v("查看是否开启了Profile功能:")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" @"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("@profiling")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 或者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" variables "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("like")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'%profil%'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119899.png",alt:"image-20220429195258266"}})])]),t._v(" "),a("li",[a("p",[t._v("开启profile功能")])])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("set profiling=1; --1是开启、0是关闭\n")])])]),a("h5",{attrs:{id:"_3、语句使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、语句使用"}},[t._v("#")]),t._v(" 3、语句使用")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("show profile 和 show profiles 语句可以展示当前会话(退出session后,profiling重置为0) 中执行语句的资源使用情况")])]),t._v(" "),a("li",[a("p",[t._v("show profiles :以列表形式显示最近发送到服务器上执行的语句的资源使用情况.显示的记录数由 变量:profiling_history_size 控制,默认15条")])]),t._v(" "),a("li",[a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119802.png",alt:"image-20220429210102940"}})])]),t._v(" "),a("li",[a("p",[t._v("show profile: 展示最近一条语句执行的详细资源占用信息,默认显示 Status和Duration两列")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119394.png",alt:"image-20220429210124760"}})]),t._v(" "),a("ul",[a("li",[t._v("show profile 还可根据 show profiles 列表中的 Query_ID ,选择显示某条记录的性能分析信息")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119449.png",alt:"image-20220429210146277"}})]),t._v(" "),a("h5",{attrs:{id:"_4、示例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4、示例"}},[t._v("#")]),t._v(" 4、示例")]),t._v(" "),a("p",[t._v("查看是否打开了性能分析功能")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" @"),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("@profiling")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119343.png",alt:"image-20220429210213091"}})]),t._v(" "),a("p",[t._v("打开 profiling 功能")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" profiling"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119305.png",alt:"image-20220429210318311"}})]),t._v(" "),a("p",[t._v("执行sql语句")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119403.png",alt:"image-20220429210330719"}})]),t._v(" "),a("p",[t._v("执行 show profiles 查看分析列表")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119430.png",alt:"image-20220429210343028"}})]),t._v(" "),a("p",[t._v("查询第二条语句的执行情况")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" profile "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" query "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119791.png",alt:"image-20220429210402942"}})]),t._v(" "),a("p",[t._v("可指定资源类型查询")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" profile cpu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("swaps "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" query "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119840.png",alt:"image-20220429210430818"}})]),t._v(" "),a("h3",{attrs:{id:"六、服务器层面优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#六、服务器层面优化"}},[t._v("#")]),t._v(" 六、服务器层面优化")]),t._v(" "),a("h5",{attrs:{id:"_1、缓冲区优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、缓冲区优化"}},[t._v("#")]),t._v(" 1、缓冲区优化")]),t._v(" "),a("p",[t._v("将数据保存在内存中，保证从内存读取数据")]),t._v(" "),a("ul",[a("li",[t._v("设置足够大的 innodb_buffer_pool_size ，将数据读取到内存中")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("建议innodb_buffer_pool_size设置为总内存大小的3/4或者4/5.\n")])])]),a("ul",[a("li",[t._v("怎样确定 innodb_buffer_pool_size 足够大。数据是从内存读取而不是硬盘？")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119874.png",alt:"image-20220429210530401"}})]),t._v(" "),a("h5",{attrs:{id:"_2、降低磁盘写入次数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、降低磁盘写入次数"}},[t._v("#")]),t._v(" 2、降低磁盘写入次数")]),t._v(" "),a("ul",[a("li",[t._v("对于生产环境来说，很多日志是不需要开启的，比如："),a("strong",[t._v("通用查询日志")]),t._v("、"),a("strong",[t._v("慢查询日志")]),t._v("、"),a("strong",[t._v("错误日志")])]),t._v(" "),a("li",[t._v("使用足够大的写入缓存 innodb_log_file_size")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[t._v("推荐 innodb_log_file_size 设置为 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" innodb_buffer_pool_size\n")])])]),a("h5",{attrs:{id:"_3、mysql数据库配置优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、mysql数据库配置优化"}},[t._v("#")]),t._v(" 3、MySQL数据库配置优化")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("表示缓冲池字节大小。")]),t._v(" "),a("p",[t._v("推荐值为物理内存的50%~80%。")])])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_buffer_pool_size\n")])])]),a("ul",[a("li",[t._v("用来控制redo log刷新到磁盘的策略。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_flush_log_at_trx_commit=1\n")])])]),a("ul",[a("li",[t._v("每提交1次事务同步写到磁盘中，可以设置为n")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("sync_binlog=1\n")])])]),a("ul",[a("li",[t._v("脏页占innodb_buffer_pool_size的比例时，触发刷脏页到磁盘。 推荐值为25%~50%。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_max_dirty_pages_pct=30\n")])])]),a("ul",[a("li",[t._v("后台进程最大IO性能指标。 默认200，如果SSD，调整为5000~20000")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_io_capacity=200\n")])])]),a("p",[t._v("在MySQL5.1.X版本中，由于代码写死，因此最多只会刷新100个脏页到磁盘、合并20个插入缓冲，即使磁盘有能力处理更多的请求，也只会处理这么多，这样在更新量较大（比如大批量 INSERT）的时候，脏页刷新可能就会跟不上，导致性能下降。")]),t._v(" "),a("p",[t._v("而在MySQL5.5.X版本里，innodb_io_capacity参数可以动态调整刷新脏页的数量，这在一定程度 上解决了这一问题。")]),t._v(" "),a("p",[t._v("innodb_io_capacity参数默认是200，单位是页。该参数设置的大小取决于硬盘的IOPS，即每秒的输入输出量（或读写次数）。")]),t._v(" "),a("p",[t._v("至于什么样的磁盘配置应该设置innodb_io_capacity参数的值是多少，大家可参考下表。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119900.png",alt:"image-20220429210849100"}})]),t._v(" "),a("ul",[a("li",[t._v("指定innodb共享表空间文件的大小。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_data_file_path\n")])])]),a("ul",[a("li",[t._v("慢查询日志的阈值设置，单位秒。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("long_qurey_time=0.3\n")])])]),a("ul",[a("li",[t._v("mysql复制的形式，row为MySQL8.0的默认形式。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("binlog_format=row\n")])])]),a("ul",[a("li",[t._v("调高该参数则应降低interactive_timeout、wait_timeout的值。")])]),t._v(" "),a("div",{staticClass:"language-mysq； extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("max_connections=200\n")])])]),a("ul",[a("li",[t._v("过大，实例恢复时间长；过小，造成日志切换频繁。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("innodb_log_file_size\n")])])]),a("ul",[a("li",[t._v("全量日志建议关闭。 默认关闭。")])]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("general_log=0\n")])])]),a("h5",{attrs:{id:"_4、操作系统优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4、操作系统优化"}},[t._v("#")]),t._v(" 4、操作系统优化")]),t._v(" "),a("p",[t._v("1）内核参数优化")]),t._v(" "),a("p",[t._v("CentOS系统针对mysql的参数优化")]),t._v(" "),a("p",[t._v("内核相关参数(/etc/sysctl.conf)")]),t._v(" "),a("p",[t._v("以下参数可以直接放到sysctl.conf文件的末尾。")]),t._v(" "),a("p",[t._v("1.增加监听队列上限：")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("net.core.somaxconn "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("65535")]),t._v(" \n\nnet.core.netdev_max_backlog "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("65535")]),t._v(" \n\nnet.ipv4.tcp_max_syn_backlog "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("65535")]),t._v("\n")])])]),a("p",[t._v("2.加快TCP连接的回收：")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("net.ipv4.tcp_fin_timeout "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\nnet.ipv4.tcp_tw_reuse "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nnet.ipv4.tcp_tw_recycle "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("p",[t._v("3.TCP连接接收和发送缓冲区大小的默认值和最大值:")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("net.core.wmem_default "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("87380")]),t._v("\nnet.core.wmem_max "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16777216")]),t._v("\nnet.core.rmem_default "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("87380")]),t._v("\nnet.core.rmem_max "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16777216")]),t._v("\n")])])]),a("p",[t._v("4.减少失效连接所占用的TCP资源的数量，加快资源回收的效率：")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("net.ipv4.tcp_keepalive_time "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("120")]),t._v("\nnet.ipv4.tcp_keepalive_intvl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\nnet.ipv4.tcp_keepalive_probes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n")])])]),a("p",[t._v("5.单个共享内存段的最大值：")]),t._v(" "),a("p",[t._v("kernel.shmmax = 4294967295")]),t._v(" "),a("blockquote",[a("ol",[a("li",[t._v("这个参数应该设置的足够大，以便能在一个共享内存段下容纳整个的Innodb缓冲池的大小。")]),t._v(" "),a("li",[t._v("这个值的大小对于64位linux系统，可取的最大值为(物理内存值-1)byte，建议值为大于物理 内存的一半，一般取值大于Innodb缓冲池的大小即可。")])])]),t._v(" "),a("p",[t._v("6.控制换出运行时内存的相对权重：")]),t._v(" "),a("p",[t._v("vm.swappiness = 0")]),t._v(" "),a("p",[t._v("这个参数当内存不足时会对性能产生比较明显的影响。（设置为0，表示Linux内核虚拟内存完全被占 用，才会要使用交换区。）")]),t._v(" "),a("blockquote",[a("p",[t._v("Linux系统内存交换区： 在Linux系统安装时都会有一个特殊的磁盘分区，称之为系统交换分区。 使用 free -m 命令可以看到swap就是内存交换区。 作用：当操作系统没有足够的内存时，就会将部分虚拟内存写到磁盘的交换区中，这样就会发生 内存交换。")])]),t._v(" "),a("p",[t._v("如果Linux系统上完全禁用交换分区，带来的风险：")]),t._v(" "),a("ol",[a("li",[t._v("降低操作系统的性能")]),t._v(" "),a("li",[t._v("容易造成内存溢出，崩溃，或都被操作系统kill掉")])]),t._v(" "),a("p",[t._v("2）增加资源限制")]),t._v(" "),a("p",[t._v("打开文件数的限制以下参数可以直接放到(/etc/security/limit.conf)文件的末尾：")]),t._v(" "),a("p",[t._v("* soft nofile 65535")]),t._v(" "),a("ul",[a("li",[t._v("hard nofile 65535")])]),t._v(" "),a("blockquote",[a("p",[t._v("*：表示对所有用户有效 soft：表示当前系统生效的设置（soft不能大于hard ） hard：表明系统中所能设定的最大值 nofile：表示所限制的资源是打开文件的最大数目 65535：限制的数量")])]),t._v(" "),a("p",[t._v("以上两行配置将可打开的文件数量增加到65535个，以保证可以打开足够多的文件句柄。")]),t._v(" "),a("p",[t._v("3）磁盘调度策略")]),t._v(" "),a("p",[a("strong",[t._v("1.cfq (完全公平队列策略，Linux2.6.18之后内核的系统默认策略)")])]),t._v(" "),a("p",[t._v("该模式按进程创建多个队列，各个进程发来的IO请求会被cfq以轮循方式处理，对每个IO请求都是公平 的。该策略适合离散读的应用。")]),t._v(" "),a("p",[a("strong",[t._v("2.deadline (截止时间调度策略)")])]),t._v(" "),a("p",[t._v("deadline，包含读和写两个队列，确保在一个截止时间内服务请求（截止时间是可调整的），而默认读 期限短于写期限。这样就防止了写操作因为不能被读取而饿死的现象，deadline对数据库类应用是最好的选择。")]),t._v(" "),a("p",[a("strong",[t._v("3.noop (电梯式调度策略)")])]),t._v(" "),a("p",[t._v("noop只实现一个简单的FIFO队列，倾向饿死读而利于写，因此noop对于闪存设备、RAM及嵌入式系统 是最好的选择。")]),t._v(" "),a("p",[a("strong",[t._v("4.anticipatory (预料I/O调度策略)")])]),t._v(" "),a("p",[t._v("本质上与deadline策略一样，但在最后一次读操作之后，要等待6ms，才能继续进行对其它I/O请求进 行调度。它会在每个6ms中插入新的I/O操作，合并写入流，用写入延时换取最大的写入吞吐量。 anticipatory适合于写入较多的环境，比如文件服务器。该策略对数据库环境表现很差")]),t._v(" "),a("p",[t._v("查看调度策略的方法：")]),t._v(" "),a("p",[t._v("cat /sys/block/devname/queue/scheduler")]),t._v(" "),a("p",[t._v("修改调度策略的方法：")]),t._v(" "),a("p",[t._v("echo > /sys/block/devname/queue/scheduler")]),t._v(" "),a("h5",{attrs:{id:"_5、服务器硬件优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5、服务器硬件优化"}},[t._v("#")]),t._v(" 5、服务器硬件优化")]),t._v(" "),a("p",[t._v("提升硬件设备，例如选择尽量高频率的内存（频率不能高于主板的支持）、提升网络带宽、使用SSD高速磁盘、提升CPU性能等。")]),t._v(" "),a("p",[t._v("CPU的选择:")]),t._v(" "),a("ul",[a("li",[t._v("对于数据库并发比较高的场景，CPU的数量比频率重要。")]),t._v(" "),a("li",[t._v("对于CPU密集型场景和频繁执行复杂SQL的场景，CPU的频率越高越好")])]),t._v(" "),a("h2",{attrs:{id:"count-和-count-1-有什么区别？哪个性能最好？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#count-和-count-1-有什么区别？哪个性能最好？"}},[t._v("#")]),t._v(" count(*) 和 count(1) 有什么区别？哪个性能最好？")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119971.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是"),a("strong",[t._v("统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个")]),t._v("。")]),t._v(" "),a("p",[t._v("假设 count() 函数的参数是字段名，如下：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select count(name) from t_order;\n")])])]),a("p",[t._v("这条语句是统计「 t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。")]),t._v(" "),a("p",[t._v("再来假设 count() 函数的参数是数字 1 这个表达式，如下：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select count(1) from t_order;\n")])])]),a("p",[t._v("这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。")]),t._v(" "),a("p",[t._v("1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录。")]),t._v(" "),a("h3",{attrs:{id:"count-主键字段-执行过程是怎样的？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#count-主键字段-执行过程是怎样的？"}},[t._v("#")]),t._v(" count(主键字段) 执行过程是怎样的？")]),t._v(" "),a("p",[t._v("在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。")]),t._v(" "),a("p",[t._v("server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。")]),t._v(" "),a("p",[t._v("InnoDB 是通过 B+ 树来保持记录的，根据索引的类型又分为聚簇索引和二级索引，它们区别在于，聚簇索引的叶子节点存放的是实际数据，而二级索引的叶子节点存放的是主键值，而不是实际数据。")]),t._v(" "),a("p",[t._v("用下面这条语句作为例子：")]),t._v(" "),a("div",{staticClass:"language-mysql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("//id 为主键值\nselect count(id) from t_order;\n")])])]),a("p",[t._v("如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119937.png",alt:"图片"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119602.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。")]),t._v(" "),a("h4",{attrs:{id:"count-1-执行过程是怎样的？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#count-1-执行过程是怎样的？"}},[t._v("#")]),t._v(" count(1) 执行过程是怎样的？")]),t._v(" "),a("p",[t._v("用下面这条语句作为例子：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t_order"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("果表里只有主键索引，没有二级索引时。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119537.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("那么，InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，"),a("strong",[t._v("但是不会读取记录中的任何字段的值")]),t._v("，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。")]),t._v(" "),a("p",[t._v("可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。")]),t._v(" "),a("p",[t._v("但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119531.png",alt:"图片"}})]),t._v(" "),a("h3",{attrs:{id:"count-执行过程是怎样的？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#count-执行过程是怎样的？"}},[t._v("#")]),t._v(" count(*) 执行过程是怎样的？")]),t._v(" "),a("p",[t._v("看到 "),a("code",[t._v("*")]),t._v(" 这个字符的时候，是不是大家觉得是读取记录中的所有字段值？")]),t._v(" "),a("p",[t._v("对于 "),a("code",[t._v("selete *")]),t._v(" 这条语句来说是这个意思，但是在 count(*) 中并不是这个意思。")]),t._v(" "),a("p",[a("strong",[t._v("count("),a("code",[t._v("\\*")]),t._v(") 其实等于 count("),a("code",[t._v("0")]),t._v(")")]),t._v("，也就是说，当你使用 count("),a("code",[t._v("*")]),t._v(") 时，MySQL 会将 "),a("code",[t._v("*")]),t._v(" 参数转化为参数 0 来处理。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119574.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("所以，"),a("strong",[t._v("count(*) 执行过程跟 count(1) 执行过程基本一样的")]),t._v("，性能没有什么差异。")]),t._v(" "),a("p",[t._v("而且 MySQL 会对 count(*) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。")]),t._v(" "),a("p",[t._v("只有当没有二级索引的时候，才会采用主键索引来进行统计。")]),t._v(" "),a("p",[t._v("count(字段) 的执行效率相比前面的 count(1)、 count(*)、 count(主键字段) 执行效率是最差的。")]),t._v(" "),a("p",[t._v("用下面这条语句作为例子：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//name不是索引，普通字段")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t_order"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("对于这个查询来说，会采用全表扫描的方式来计数，所以它的执行效率是比较差的。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119688.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("总结")]),t._v(" "),a("p",[t._v("count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。")]),t._v(" "),a("p",[t._v("所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。")]),t._v(" "),a("p",[t._v("再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。")]),t._v(" "),a("h3",{attrs:{id:"优化count"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优化count"}},[t._v("#")]),t._v(" 优化count(*)")]),t._v(" "),a("p",[t._v("如果对一张大表经常用 count(*) 来做统计，其实是很不好的。")]),t._v(" "),a("p",[a("strong",[t._v("第一种，近似值")])]),t._v(" "),a("p",[t._v("如果你的业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119701.png",alt:"图片"}})]),t._v(" "),a("p",[t._v("这时，我们就可以使用 show table status 或者 explain 命令来表进行估算。")]),t._v(" "),a("p",[t._v("执行 explain 命令效率是很高的，因为它并不会真正的去查询，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119405.png",alt:"图片"}})]),t._v(" "),a("p",[a("strong",[t._v("第二种，额外表保存计数值")])]),t._v(" "),a("p",[t._v("如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。")]),t._v(" "),a("p",[t._v("当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。")]),t._v(" "),a("h2",{attrs:{id:"一条sql在mysql执行的过程分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一条sql在mysql执行的过程分析"}},[t._v("#")]),t._v(" 一条SQL在MySQL执行的过程分析")]),t._v(" "),a("p",[t._v("MySQL 主要分为 "),a("strong",[t._v("Server")]),t._v(" "),a("strong",[t._v("层")]),t._v("和"),a("strong",[t._v("存储引擎层")])]),t._v(" "),a("ul",[a("li",[t._v("Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。")]),t._v(" "),a("li",[t._v("存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了")])]),t._v(" "),a("h3",{attrs:{id:"server-层基本组件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#server-层基本组件"}},[t._v("#")]),t._v(" "),a("strong",[t._v("Server 层基本组件")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("连接器。连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。")]),t._v(" "),a("p",[t._v("主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。")])]),t._v(" "),a("li",[a("p",[t._v("查缓存。（MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。。）")])]),t._v(" "),a("li",[a("p",[t._v("分析器。MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：")]),t._v(" "),a("ul",[a("li",[t._v("第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。")]),t._v(" "),a("li",[t._v("第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。")])])]),t._v(" "),a("li",[a("p",[t._v("优化器是否使用索引，生成执行计划，比如组合索引优化顺序。")])]),t._v(" "),a("li",[a("p",[t._v("执行器，当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202209121119313.jpeg",alt:"img"}})]),t._v(" "),a("p",[t._v("具体的流程分为查询和更新两种")]),t._v(" "),a("h3",{attrs:{id:"查询语句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查询语句"}},[t._v("#")]),t._v(" 查询语句")]),t._v(" "),a("p",[t._v("我们先分析下查询语句，语句如下：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tb_student  A "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'18'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' 张三 '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。")]),t._v(" "),a("p",[t._v("通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id=‘1’。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。\n接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案：")]),t._v(" "),a("div",{staticClass:"language-html extra-class"},[a("pre",{pre:!0,attrs:{class:"language-html"}},[a("code",[t._v("a. 先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。\nb. 先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。\n")])])]),a("p",[t._v("那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。")]),t._v(" "),a("p",[t._v("进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。")]),t._v(" "),a("h3",{attrs:{id:"更新语句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#更新语句"}},[t._v("#")]),t._v(" 更新语句")]),t._v(" "),a("p",[t._v("以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),t._v(" tb_student A "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'19'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' 张三 '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：")]),t._v(" "),a("ul",[a("li",[t._v("先查询到张三这一条数据，如果有缓存，也是会用到缓存。")]),t._v(" "),a("li",[t._v("然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。")]),t._v(" "),a("li",[t._v("执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。")]),t._v(" "),a("li",[t._v("更新完成。")])]),t._v(" "),a("h3",{attrs:{id:"为什么记录完-redo-log，不直接提交，先进入prepare状态？"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么记录完-redo-log，不直接提交，先进入prepare状态？"}},[t._v("#")]),t._v(" 为什么记录完 redo log，不直接提交，先进入prepare状态？")]),t._v(" "),a("p",[t._v("假设先写 redo log 直接提交，然后写 binlog，写完 redo log 后，机器挂了，binlog 日志没有被写入， 那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。")])])}),[],!1,null,null,null);s.default=v.exports}}]);