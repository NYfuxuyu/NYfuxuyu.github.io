<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>操作系统 | 知识星球</title>
    <meta name="generator" content="VuePress 1.5.0">
    <link rel="icon" href="/avatar.jpg">
    <meta name="description" content="">
    <link rel="preload" href="/assets/css/0.styles.a26fb221.css" as="style"><link rel="preload" href="/assets/js/app.3bc42cf8.js" as="script"><link rel="preload" href="/assets/js/3.0146fe10.js" as="script"><link rel="preload" href="/assets/js/1.760be874.js" as="script"><link rel="preload" href="/assets/js/23.35607ff8.js" as="script"><link rel="prefetch" href="/assets/js/10.2fa36d92.js"><link rel="prefetch" href="/assets/js/11.d5259c34.js"><link rel="prefetch" href="/assets/js/12.3b11beda.js"><link rel="prefetch" href="/assets/js/13.8e606e78.js"><link rel="prefetch" href="/assets/js/14.7e273577.js"><link rel="prefetch" href="/assets/js/15.9080a48f.js"><link rel="prefetch" href="/assets/js/16.62996748.js"><link rel="prefetch" href="/assets/js/17.afa987aa.js"><link rel="prefetch" href="/assets/js/18.04a1e384.js"><link rel="prefetch" href="/assets/js/19.51469f95.js"><link rel="prefetch" href="/assets/js/20.180dc3cd.js"><link rel="prefetch" href="/assets/js/21.32d43e7f.js"><link rel="prefetch" href="/assets/js/22.f1326aa2.js"><link rel="prefetch" href="/assets/js/24.60cebcf3.js"><link rel="prefetch" href="/assets/js/25.4b8dd78e.js"><link rel="prefetch" href="/assets/js/26.13c2f0ff.js"><link rel="prefetch" href="/assets/js/4.a5370f7a.js"><link rel="prefetch" href="/assets/js/5.716a9c5a.js"><link rel="prefetch" href="/assets/js/6.048f2fb7.js"><link rel="prefetch" href="/assets/js/7.c3f4f112.js"><link rel="prefetch" href="/assets/js/8.64d54cc1.js"><link rel="prefetch" href="/assets/js/9.4411a8b9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.a26fb221.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-2d5f533b><div data-v-2d5f533b><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-2d5f533b data-v-2d5f533b><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-64685f0e data-v-2d5f533b data-v-2d5f533b><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>知识星球</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>知识星球</span>
            
          <!---->
          2022
        </a></span></div></div> <div class="hide" data-v-2d5f533b><header class="navbar" data-v-2d5f533b><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/avatar.jpg" alt="知识星球" class="logo"> <span class="site-name">知识星球</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      计算机基础
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/network/" class="nav-link"><i class="iconfont reco-network"></i>
  计算机网络
</a></li><li class="dropdown-item"><!----> <a href="/operationsystem/" class="nav-link router-link-exact-active router-link-active"><i class="iconfont reco-system"></i>
  操作系统
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-sql"></i>
      数据库
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link"><i class="iconfont undefined"></i>
  Mysql
</a></li><li class="dropdown-item"><!----> <a href="/sql/Redis.html" class="nav-link"><i class="iconfont undefined"></i>
  Redis
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-java"></i>
      Java基础
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/javase/" class="nav-link"><i class="iconfont undefined"></i>
  JavaSE
</a></li><li class="dropdown-item"><!----> <a href="/collection/" class="nav-link"><i class="iconfont undefined"></i>
  Java集合
</a></li><li class="dropdown-item"><!----> <a href="/juc/" class="nav-link"><i class="iconfont undefined"></i>
  Java并发
</a></li><li class="dropdown-item"><!----> <a href="/jvm/" class="nav-link"><i class="iconfont undefined"></i>
  JVM
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      框架
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/mybatis/" class="nav-link"><i class="iconfont undefined"></i>
  Mybaits
</a></li><li class="dropdown-item"><!----> <a href="/spring/" class="nav-link"><i class="iconfont undefined"></i>
  Spring
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      扩展
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/data/" class="nav-link"><i class="iconfont undefined"></i>
  海量数据
</a></li><li class="dropdown-item"><!----> <a href="/area/" class="nav-link"><i class="iconfont undefined"></i>
  系统设计题
</a></li><li class="dropdown-item"><!----> <a href="/suanfa/" class="nav-link"><i class="iconfont undefined"></i>
  算法
</a></li><li class="dropdown-item"><!----> <a href="/iq/" class="nav-link"><i class="iconfont undefined"></i>
  智力题
</a></li><li class="dropdown-item"><!----> <a href="/shejimoshi/" class="nav-link"><i class="iconfont undefined"></i>
  设计模式
</a></li></ul></div></div><div class="nav-item"><a href="http://blog.fuxuyu.top/" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont undefined"></i>
  个人博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://gitee.com/fuxuyu" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-mayun"></i>
  码云
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://github.com/NYfuxuyu" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-2d5f533b></div> <aside class="sidebar" data-v-2d5f533b><div class="personal-info-wrapper" data-v-ca798c94 data-v-2d5f533b><!----> <h3 class="name" data-v-ca798c94>
    知识星球
  </h3> <div class="num" data-v-ca798c94><div data-v-ca798c94><h3 data-v-ca798c94>16</h3> <h6 data-v-ca798c94>Article</h6></div> <div data-v-ca798c94><h3 data-v-ca798c94>14</h3> <h6 data-v-ca798c94>Tag</h6></div></div> <hr data-v-ca798c94></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      计算机基础
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/network/" class="nav-link"><i class="iconfont reco-network"></i>
  计算机网络
</a></li><li class="dropdown-item"><!----> <a href="/operationsystem/" class="nav-link router-link-exact-active router-link-active"><i class="iconfont reco-system"></i>
  操作系统
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-sql"></i>
      数据库
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link"><i class="iconfont undefined"></i>
  Mysql
</a></li><li class="dropdown-item"><!----> <a href="/sql/Redis.html" class="nav-link"><i class="iconfont undefined"></i>
  Redis
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-java"></i>
      Java基础
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/javase/" class="nav-link"><i class="iconfont undefined"></i>
  JavaSE
</a></li><li class="dropdown-item"><!----> <a href="/collection/" class="nav-link"><i class="iconfont undefined"></i>
  Java集合
</a></li><li class="dropdown-item"><!----> <a href="/juc/" class="nav-link"><i class="iconfont undefined"></i>
  Java并发
</a></li><li class="dropdown-item"><!----> <a href="/jvm/" class="nav-link"><i class="iconfont undefined"></i>
  JVM
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      框架
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/mybatis/" class="nav-link"><i class="iconfont undefined"></i>
  Mybaits
</a></li><li class="dropdown-item"><!----> <a href="/spring/" class="nav-link"><i class="iconfont undefined"></i>
  Spring
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      扩展
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/data/" class="nav-link"><i class="iconfont undefined"></i>
  海量数据
</a></li><li class="dropdown-item"><!----> <a href="/area/" class="nav-link"><i class="iconfont undefined"></i>
  系统设计题
</a></li><li class="dropdown-item"><!----> <a href="/suanfa/" class="nav-link"><i class="iconfont undefined"></i>
  算法
</a></li><li class="dropdown-item"><!----> <a href="/iq/" class="nav-link"><i class="iconfont undefined"></i>
  智力题
</a></li><li class="dropdown-item"><!----> <a href="/shejimoshi/" class="nav-link"><i class="iconfont undefined"></i>
  设计模式
</a></li></ul></div></div><div class="nav-item"><a href="http://blog.fuxuyu.top/" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont undefined"></i>
  个人博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://gitee.com/fuxuyu" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-mayun"></i>
  码云
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://github.com/NYfuxuyu" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-64685f0e data-v-2d5f533b><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>操作系统</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>知识星球</span>
            
          <!---->
          2022
        </a></span></div></div> <div data-v-2d5f533b><main class="page"><div class="page-title" style="display:none;"><h1 class="title">操作系统</h1> <div data-v-3b7f5bdf><i class="iconfont reco-account" data-v-3b7f5bdf><span data-v-3b7f5bdf>仪轩</span></i> <i class="iconfont reco-date" data-v-3b7f5bdf><span data-v-3b7f5bdf>2022-09-16</span></i> <!----> <i class="iconfont reco-tag tags" data-v-3b7f5bdf><span class="tag-item" data-v-3b7f5bdf>操作系统</span></i></div></div> <div class="theme-reco-content content__default" style="display:none;"><blockquote><p>操作系统</p></blockquote> <h2 id="基本特征"><a href="#基本特征" class="header-anchor">#</a> 基本特征</h2> <h3 id="_1-并发"><a href="#_1-并发" class="header-anchor">#</a> 1. 并发</h3> <p>并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。</p> <p>并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。</p> <p>操作系统通过引入进程和线程，使得程序能够并发运行。</p> <h3 id="_2-共享"><a href="#_2-共享" class="header-anchor">#</a> 2. 共享</h3> <p>共享是指系统中的资源可以被多个并发进程共同使用。</p> <p>有两种共享方式：互斥共享和同时共享。</p> <p>互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。</p> <h3 id="_3-虚拟"><a href="#_3-虚拟" class="header-anchor">#</a> 3. 虚拟</h3> <p>虚拟技术把一个物理实体转换为多个逻辑实体。</p> <p>主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。</p> <p>多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。</p> <p>虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。</p> <h3 id="_4-异步"><a href="#_4-异步" class="header-anchor">#</a> 4. 异步</h3> <p>异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。</p> <h2 id="基本功能"><a href="#基本功能" class="header-anchor">#</a> 基本功能</h2> <h3 id="_1-进程管理"><a href="#_1-进程管理" class="header-anchor">#</a> 1. 进程管理</h3> <p>进程控制、进程同步、进程通信、死锁处理、处理机调度等。</p> <h3 id="_2-内存管理"><a href="#_2-内存管理" class="header-anchor">#</a> 2. 内存管理</h3> <p>内存分配、地址映射、内存保护与共享、虚拟内存等。</p> <h3 id="_3-文件管理"><a href="#_3-文件管理" class="header-anchor">#</a> 3. 文件管理</h3> <p>文件存储空间的管理、目录管理、文件读写管理和保护等。</p> <h3 id="_4-设备管理"><a href="#_4-设备管理" class="header-anchor">#</a> 4. 设备管理</h3> <p>完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。</p> <p>主要包括缓冲管理、设备分配、设备处理、虛拟设备等。</p> <h2 id="宏内核和微内核"><a href="#宏内核和微内核" class="header-anchor">#</a> 宏内核和微内核</h2> <h3 id="宏内核"><a href="#宏内核" class="header-anchor">#</a> 宏内核</h3> <p>宏内核是将操作系统功能作为一个紧密结合的整体放到内核。由于各模块共享信息，因此有很高的性能</p> <h3 id="微内核"><a href="#微内核" class="header-anchor">#</a> 微内核</h3> <p>由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。</p> <p>在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。</p> <p>因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205031952646.png" alt="image-20211203154044937"></p> <h2 id="硬件结构"><a href="#硬件结构" class="header-anchor">#</a> 硬件结构</h2> <h3 id="冯诺依曼模型"><a href="#冯诺依曼模型" class="header-anchor">#</a> 冯诺依曼模型</h3> <p>最重要的是定义计算机基本结构为 5 个部分，分别是<strong>运算器、控制器、存储器、输入设备、输出设备</strong>，这 5 个部分也被称为<strong>冯诺依曼模型</strong>。</p> <p><img src="C:/Users/Fuxuyu/AppData/Roaming/Typora/typora-user-images/image-20220927144601375.png" alt="image-20220927144601375"></p> <p>运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。</p> <p>存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。所以，它们之间的关系如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032036190.png" alt="img"></p> <p>接下来，分别介绍内存、中央处理器、总线、输入输出设备</p> <h5 id="内存"><a href="#内存" class="header-anchor">#</a> 内存</h5> <p>我们的程序和数据都是存储在内存，存储的区域是线性的。</p> <p>数据存储的单位是一个<strong>二进制位（*bit*）</strong>，即 0 或 1。最小的存储单位是<strong>字节（*byte*）</strong>，1 字节等于 8 位。</p> <p>内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。</p> <h5 id="中央处理器中央处理器"><a href="#中央处理器中央处理器" class="header-anchor">#</a> 中央处理器中央处理器</h5> <p>中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：</p> <ul><li>32 位 CPU 一次可以计算 4 个字节；</li> <li>64 位 CPU 一次可以计算 8 个字节；</li></ul> <p>这里的 32 位和 64 位，通常称为 CPU 的位宽。</p> <p>之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 <code>0~255</code> 范围内的数值，这样就无法一次完成计算 <code>10000 * 500</code> ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 <code>4294967295</code>。</p> <p>CPU 内部还有一些组件，常见的有<strong>寄存器、控制单元和逻辑运算单元</strong>等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。</p> <p>CPU 中的寄存器主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。</p> <p>常见的寄存器种类：</p> <ul><li><strong>通用寄存器</strong>，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。</li> <li><strong>程序计数器</strong>，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。</li> <li><strong>指令寄存器</strong>，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。</li></ul> <h5 id="总线"><a href="#总线" class="header-anchor">#</a> 总线</h5> <p>总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：</p> <ul><li><strong>地址总线</strong>，用于指定 CPU 将要操作的内存地址；</li> <li><strong>数据总线</strong>，用于读写内存的数据；</li> <li><strong>控制总线</strong>，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；</li></ul> <p>当 CPU 要读写内存数据的时候，一般需要通过两个总线：</p> <ul><li>首先要通过「地址总线」来指定内存的地址；</li> <li>再通过「数据总线」来传输数据；</li></ul> <h5 id="输入、输出设备"><a href="#输入、输出设备" class="header-anchor">#</a> 输入、输出设备</h5> <p>输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。期间，如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了</p> <h3 id="存储器的层次结构"><a href="#存储器的层次结构" class="header-anchor">#</a> 存储器的层次结构</h3> <p>存储器通常可以分为这么几个级别：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032040097.png" alt="img"></p> <ul><li>寄存器；</li> <li>CPU Cache；
<ol><li>L1-Cache；</li> <li>L2-Cache；</li> <li>L3-Cahce；</li></ol></li> <li>内存；</li> <li>SSD/HDD 硬盘</li></ul> <h5 id="寄存器"><a href="#寄存器" class="header-anchor">#</a> 寄存器</h5> <p>最靠近 CPU 的控制单元和逻辑计算单元的存储器，就是寄存器了，它使用的材料速度也是最快的，因此价格也是最贵的，那么数量不能很多。</p> <p>存储器的数量通常在几十到几百之间，每个寄存器可以用来存储一定的字节（byte）的数据。比如：</p> <ul><li>32 位 CPU 中大多数寄存器可以存储 <code>4</code> 个字节；</li> <li>64 位 CPU 中大多数寄存器可以存储 <code>8</code> 个字节。</li></ul> <p>CPU Cache 用的是一种叫 <strong>SRAM（*Static Random-Access* Memory，静态随机存储器）</strong> 的芯片。</p> <p>SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。</p> <p>在 SRAM 里面，一个 bit 的数据，通常需要 6 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间下，能存储的数据是有限的，不过也因为 SRAM 的电路简单，所以访问速度非常快。</p> <p>CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二次缓存、三次缓存。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032041127.png" alt="img"></p> <p><strong>L1 高速缓存</strong></p> <p>每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成<strong>指令缓存</strong>和<strong>数据缓存</strong></p> <p><strong>L2 高速缓存</strong></p> <p>L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大，CPU 型号不同大小也就不同，通常大小在几百 KB 到几 MB 不等，访问速度则更慢，速度在 <code>10~20</code> 个时钟周期。</p> <p><strong>L3 高速缓存</strong></p> <p>L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等，具体值根据 CPU 型号而定。</p> <p>访问速度相对也比较慢一些，访问速度在 <code>20~60</code>个时钟周期。</p> <h5 id="内存-2"><a href="#内存-2" class="header-anchor">#</a> 内存</h5> <p>内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 <strong>DRAM （*Dynamic Random Access Memory*，动态随机存取存储器）</strong> 的芯片。</p> <p>相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。</p> <p>DRAM 存储一个 bit 数据，只需要一个晶体管和一个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。</p> <p>DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 <code>200~300</code> 个 时钟周期之间</p> <h5 id="ssd-hdd-硬盘"><a href="#ssd-hdd-硬盘" class="header-anchor">#</a> SSD/HDD 硬盘</h5> <p>SSD（<em>Solid-state disk</em>） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。内存的读写速度比 SSD 大概快 <code>10~1000</code> 倍。</p> <p>当然，还有一款传统的硬盘，也就是机械硬盘（<em>Hard Disk Drive, HDD</em>），它是通过物理读写的方式来访问数据的，因此它访问速度是非常慢的，它的速度比内存慢 <code>10W</code> 倍左右。</p> <p>由于 SSD 的价格快接近机械硬盘了，因此机械硬盘已经逐渐被 SSD 替代了。</p> <h5 id="存储器的层次关系"><a href="#存储器的层次关系" class="header-anchor">#</a> 存储器的层次关系</h5> <p><strong>每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，这就我们今天所说的存储器层次结构</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032043043.png" alt="img"></p> <h3 id="cpu-缓存一致性"><a href="#cpu-缓存一致性" class="header-anchor">#</a> CPU 缓存一致性</h3> <h5 id="cpu-cache数据的写入"><a href="#cpu-cache数据的写入" class="header-anchor">#</a> CPU Cache数据的写入</h5> <p>CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032047934.png" alt="img"></p> <p>问题来了，那在什么时机才把 Cache 中的数据写回到内存呢？为了应对这个问题，下面介绍两种针对写入数据的方法：</p> <ul><li>写直达（<em>Write Through</em>）</li> <li>写回（<em>Write Back</em>）</li></ul> <p><strong>写直达</strong></p> <p>保持内存与 Cache 一致性最简单的方式是，<strong>把数据同时写入内存和 Cache 中</strong>，这种方法称为<strong>写直达（Write Through）</strong>。</p> <p>在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：</p> <ul><li>如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；</li> <li>如果数据没有在 Cache 里面，就直接把数据更新到内存里面。<img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032049559.png" alt="img"></li></ul> <p><strong>写回</strong></p> <p>既然写直达由于每次写操作都会把数据写回到内存，而导致影响性能，于是为了要减少数据写回内存的频率，就出现了<strong>写回（Write Back）的方法</strong>。</p> <p>在写回机制中，<strong>当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中</strong>，减少了数据写回内存的频率，这样便可以提高系统的性能。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032049761.png" alt="img"></p> <p>那具体如何做到的呢？下面来详细说一下：</p> <ul><li>如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表这个时候，我们 CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的，这种情况是不用把数据写到内存里的；</li> <li>如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里（注意，这一步不是没用的，具体为什么要这一步，可以看这个「<a href="https://stackoverflow.com/questions/26672661/for-write-back-cache-policy-why-data-should-first-be-read-from-memory-before-w" target="_blank" rel="noopener noreferrer">回答 (opens new window)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>」），然后再写入的数据写入到 Cache Block，最后也把它标记为脏的；如果 Cache Block 里面的数据没有被标记为脏，则就直接将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。</li></ul> <p>可以发现写回这个方法，在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</p> <p>这样的好处是，如果我们大量的操作都能够命中缓存，那么大部分时间里 CPU 都不需要读写内存，自然性能相比写直达会高很多</p> <h5 id="缓存一致性问题"><a href="#缓存一致性问题" class="header-anchor">#</a> 缓存一致性问题</h5> <p>那缓存一致性的问题具体是怎么发生的呢？我们以一个含有两个核心的 CPU 作为例子看一看。</p> <p>假设 A 号核心和 B 号核心同时运行两个线程，都操作共同的变量 i（初始值为 0 ）。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032051410.png" alt="img"></p> <p>这时如果 A 号核心执行了 <code>i++</code> 语句的时候，为了考虑性能，使用了我们前面所说的写回策略，先把值为 <code>1</code> 的执行结果写入到 L1/L2 Cache 中，然后把 L1/L2 Cache 中对应的 Block 标记为脏的，这个时候数据其实没有被同步到内存中的，因为写回策略，只有在 A 号核心中的这个 Cache Block 要被替换的时候，数据才会写入到内存里。</p> <p>如果这时旁边的 B 号核心尝试从内存读取 i 变量的值，则读到的将会是错误的值，因为刚才 A 号核心更新 i 值还没写入到内存中，内存中的值还依然是 0。<strong>这个就是所谓的缓存一致性问题，A 号核心和 B 号核心的缓存，在这个时候是不一致，从而会导致执行结果的错误。</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032052774.png" alt="img"></p> <p>那么，要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：</p> <ul><li>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播（Wreite Propagation）</strong>；</li> <li>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串形化（Transaction Serialization）</strong>。</li></ul> <p>第一点写传播很容易就理解，当某个核心在 Cache 更新了数据，就需要同步到其他核心的 Cache 里。而对于第二点事务事的串形化，我们举个例子来理解它。</p> <p>假设我们有一个含有 4 个核心的 CPU，这 4 个核心都操作共同的变量 i（初始值为 0 ）。A 号核心先把 i 值变为 100，而此时同一时间，B 号核心先把 i 值变为 200，这里两个修改，都会「传播」到 C 和 D 号核心。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032052613.png" alt="img"></p> <p>那么问题就来了，C 号核心先收到了 A 号核心更新数据的事件，再收到 B 号核心更新数据的事件，因此 C 号核心看到的变量 i 是先变成 100，后变成 200。</p> <p>而如果 D 号核心收到的事件是反过来的，则 D 号核心看到的是变量 i 先变成 200，再变成 100，虽然是做到了写传播，但是各个 Cache 里面的数据还是不一致的。</p> <p>所以，我们要保证 C 号核心和 D 号核心都能看到<strong>相同顺序的数据变化</strong>，比如变量 i 都是先变成 100，再变成 200，这样的过程就是事务的串形化。</p> <p>要实现事务串形化，要做到 2 点：</p> <ul><li>CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；</li> <li>要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。</li></ul> <p>那接下来我们看看，写传播和事务串形化具体是用什么技术实现的。</p> <h5 id="总线嗅探"><a href="#总线嗅探" class="header-anchor">#</a> 总线嗅探</h5> <p>写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是<strong>总线嗅探（Bus Snooping）</strong>。</p> <p>我还是以前面的 i 变量例子来说明总线嗅探的工作机制，当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache。</p> <p>可以发现，总线嗅探方法很简单， CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载。</p> <p>另外，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串形化。</p> <p>于是，有一个协议基于总线嗅探机制实现了事务串形化，也用状态机机制降低了总线带宽压力，这个协议就是 MESI 协议，这个协议就做到了 CPU 缓存一致性</p> <h5 id="mesi-协议"><a href="#mesi-协议" class="header-anchor">#</a> <strong>MESI 协议</strong></h5> <p>MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：</p> <ul><li><em>Modified</em>，已修改</li> <li><em>Exclusive</em>，独占</li> <li><em>Shared</em>，共享</li> <li><em>Invalidated</em>，已失效</li></ul> <p>这四个状态来标记 Cache Line 四个不同的状态。</p> <p>「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。而「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。</p> <p>「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。</p> <p>「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。</p> <p>另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。</p> <p>那么，「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。</p> <p>我们举个具体的例子来看看这四个状态的转换：</p> <ol><li>当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；</li> <li>然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；</li> <li>当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。</li> <li>如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。</li> <li>如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。</li></ol> <p>所以，可以发现当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。</p> <p>事实上，整个 MESI 的状态可以用一个有限状态机来表示它的状态流转。还有一点，对于不同状态触发的事件操作，可能是来自本地 CPU 核心发出的广播事件，也可以是来自其他 CPU 核心通过总线发出的广播事件。下图即是 MESI 协议的状态图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032054375.png" alt="img"></p> <p>MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心</p> <h3 id="中断"><a href="#中断" class="header-anchor">#</a> 中断</h3> <h5 id="中断是什么"><a href="#中断是什么" class="header-anchor">#</a> 中断是什么</h5> <p>中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求</p> <p>操作系统收到了中断请求，会打断其他进程的运行，所以<strong>中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。</strong></p> <h5 id="什么是软中断"><a href="#什么是软中断" class="header-anchor">#</a> 什么是软中断</h5> <p>前面我们也提到了，中断请求的处理程序应该要短且快，这样才能减少对正常进程运行调度地影响，而且中断处理程序可能会暂时关闭中断，这时如果中断处理程序执行时间过长，可能在还未执行完中断处理程序前，会丢失当前其他设备的中断请求</p> <p>那 Linux 系统<strong>为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」</strong>。</p> <ul><li><strong>上半部用来快速处理中断</strong>，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。</li> <li><strong>下半部用来延迟处理上半部未完成的工作</strong>，一般以「内核线程」的方式运行。</li></ul> <p>举一个计算机中的例子，常见的网卡接收网络包的例子。</p> <p>网卡收到网络包后，会通过<strong>硬件中断</strong>通知内核有新的数据到了，于是内核就会调用对应的中断处理程序来响应该事件，这个事件的处理也是会分成上半部和下半部。</p> <p>上部分要做到快速处理，所以只要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态，比如把状态更新为表示数据已经读到内存中的状态值。</p> <p>接着，内核会触发一个<strong>软中断</strong>，把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其主要是需要从内存中找到网络数据，再按照网络协议栈，对网络数据进行逐层解析和处理，最后把数据送给应用程序。</p> <p>所以，中断处理程序的上部分和下半部可以理解为：</p> <ul><li><strong>上半部直接处理硬件请求，也就是硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</li> <li><strong>下半部是由内核触发，也就说软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</li></ul> <p>还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程，名字通常为「ksoftirqd/CPU 编号」，比如 0 号 CPU 对应的软中断内核线程的名字是 <code>ksoftirqd/0</code></p> <p>不过，软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度等、RCU 锁（内核里常用的一种锁）等</p> <h2 id="内存管理"><a href="#内存管理" class="header-anchor">#</a> 内存管理</h2> <p><strong>虚拟内存</strong></p> <p>虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。</p> <p>为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。</p> <p>从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032007100.png" alt="img"></p> <p>操作系统是如何管理虚拟地址与物理地址之间的关系？</p> <p>主要有两种方式，分别是<strong>内存分段和内存分页</strong></p> <h3 id="内存分段"><a href="#内存分段" class="header-anchor">#</a> 内存分段</h3> <p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。<strong>不同的段是有不同的属性的，所以就用分段（*Segmentation*）的形式把这些段分离出来。</strong></p> <p>分段机制下的虚拟地址由两部分组成，<strong>段选择子</strong>和<strong>段内偏移量</strong>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032013229.png" alt="img"></p> <ul><li><strong>段选择子</strong>就保存在段寄存器里面。段选择子里面最重要的是<strong>段号</strong>，用作段表的索引。<strong>段表</strong>里面保存的是这个<strong>段的基地址、段的界限和特权等级</strong>等。</li> <li>虚拟地址中的<strong>段内偏移量</strong>应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</li></ul> <p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p> <ul><li>第一个就是<strong>内存碎片</strong>的问题。</li> <li>第二个就是<strong>内存交换的效率低</strong>的问题。</li></ul> <p>我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：</p> <ul><li>游戏占用了 512MB 内存</li> <li>浏览器占用了 128MB 内存</li> <li>音乐占用了 256 MB 内存。</li></ul> <p>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。</p> <p>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032020693.png" alt="img"></p> <p>这里的内存碎片的问题共有两处地方：</p> <ul><li>外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；</li> <li>内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；</li></ul> <p>解决外部内存碎片的问题就是<strong>内存交换</strong></p> <blockquote><p>再来看看，分段为什么会导致内存交换效率低的问题？</p></blockquote> <p>对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 <code>Swap</code> 内存区域，这个过程会产生性能瓶颈。</p> <p>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。</p> <p>所以，<strong>如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。</strong></p> <p>为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页</p> <h3 id="内存分页"><a href="#内存分页" class="header-anchor">#</a> 内存分页</h3> <p><strong>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小</strong>。这样一个连续并且尺寸固定的内存空间，我们叫<strong>页</strong>（<em>Page</em>）。在 Linux 下，每一页的大小为 <code>4KB</code>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032022531.png" alt="img"></p> <p>页表是存储在内存里的，<strong>内存管理单元</strong> （<em>MMU</em>）就做将虚拟内存地址转换成物理地址的工作。</p> <p>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行</p> <p>由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而<strong>采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。</strong></p> <p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高。</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032022198.png" alt="img"></p> <p><strong>分页机制下，虚拟地址和物理地址是如何映射的？</strong></p> <p>在分页机制下，虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，<strong>页表</strong>包含物理页每页所在<strong>物理内存的基地址</strong>，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032023923.png" alt="img"></p> <p>总结一下，对于一个内存地址转换，其实就是这样三个步骤：</p> <ul><li>把虚拟内存地址，切分成页号和偏移量；</li> <li>根据页号，从页表里面，查询对应的物理页号；</li> <li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li></ul> <p><strong>简单的分页有什么缺陷吗？</strong></p> <p>有空间上的缺陷。</p> <p>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。</p> <p>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 <code>4MB</code> 的内存来存储页表。</p> <p>这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。</p> <p>那么，<code>100</code> 个进程的话，就需要 <code>400MB</code> 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了</p> <h3 id="多级页表"><a href="#多级页表" class="header-anchor">#</a> 多级页表</h3> <p>要解决上面的问题，就需要采用一种叫作<strong>多级页表</strong>（<em>Multi-Level Page Table</em>）的解决方案。</p> <p>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 <code>4KB</code> 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。</p> <p>我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 <code>1024</code> 个页表（二级页表），每个表（二级页表）中包含 <code>1024</code> 个「页表项」，形成<strong>二级分页</strong>。如下图所示：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032028683.png" alt="img"></p> <blockquote><p>你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？</p></blockquote> <p>当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。</p> <p>其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的<strong>局部性原理</strong>么？</p> <p>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。</p> <p>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但<strong>如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表</strong>。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= <code>0.804MB</code>，这对比单级页表的 <code>4MB</code> 是不是一个巨大的节约？</p> <p>那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以<strong>页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项</strong>（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p> <h4 id="tlb"><a href="#tlb" class="header-anchor">#</a> TLB</h4> <p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。</p> <p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。</p> <p>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（<em>Translation Lookaside Buffer</em>） ，通常称为<strong>页表缓存、转址旁路缓存、快表</strong>等。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032029410.png" alt="img"></p> <p>在 CPU 芯片里面，封装了内存管理单元（<em>Memory Management Unit</em>）芯片，它用来完成地址转换和 TLB 的访问与交互。</p> <p>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。</p> <p>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个</p> <h4 id="段页式内存管理"><a href="#段页式内存管理" class="header-anchor">#</a> 段页式内存管理</h4> <p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>。</p> <p>段页式内存管理实现的方式：</p> <ul><li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；</li> <li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；</li></ul> <p>这样，地址结构就由<strong>段号、段内页号和页内位移</strong>三部分组成。</p> <p>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032030099.png" alt="img"></p> <p>段页式地址变换中要得到物理地址须经过三次内存访问：</p> <ul><li>第一次访问段表，得到页表起始地址；</li> <li>第二次访问页表，得到物理页号；</li> <li>第三次将物理页号与页内位移组合，得到物理地址。</li></ul> <h4 id="linux-的虚拟地址空间"><a href="#linux-的虚拟地址空间" class="header-anchor">#</a> Linux 的虚拟地址空间</h4> <p>在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032033126.png" alt="img"></p> <p>通过这里可以看出：</p> <ul><li><code>32</code> 位系统的内核空间占用 <code>1G</code>，位于最高处，剩下的 <code>3G</code> 是用户空间；</li> <li><code>64</code> 位系统的内核空间和用户空间都是 <code>128T</code>，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。</li></ul> <p>再来说说，内核空间与用户空间的区别：</p> <ul><li>进程在用户态时，只能访问用户空间内存；</li> <li>只有进入内核态后，才可以访问内核空间的内存；</li></ul> <p>虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong>。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032034325.png" alt="img"></p> <h3 id="进程管理"><a href="#进程管理" class="header-anchor">#</a> 进程管理</h3> <h5 id="进程、线程基础知识"><a href="#进程、线程基础知识" class="header-anchor">#</a> 进程、线程基础知识</h5> <h5 id="进程"><a href="#进程" class="header-anchor">#</a> 进程</h5> <p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong></p> <h6 id="进程的状态"><a href="#进程的状态" class="header-anchor">#</a> 进程的状态</h6> <p><strong>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032210164.jpeg" alt="进程的三种基本状态"></p> <p>上图中各个状态的意义：</p> <ul><li>运行状态（<em>Runing</em>）：该时刻进程占用 CPU；</li> <li>就绪状态（<em>Ready</em>）：可运行，由于其他进程处于运行状态而暂时停止运行；</li> <li>阻塞状态（<em>Blocked</em>）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li></ul> <p>当然，进程还有另外两个基本状态：</p> <ul><li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li> <li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态；</li></ul> <p>于是，一个完整的进程状态的变迁如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032211167.jpeg" alt="进程五种状态的变迁"></p> <p>再来详细说明一下进程的状态变迁：</p> <ul><li><em>NULL -&gt; 创建状态</em>：一个新进程被创建时的第一个状态；</li> <li><em>创建状态 -&gt; 就绪状态</em>：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；</li> <li><em>就绪态 -&gt; 运行状态</em>：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；</li> <li><em>运行状态 -&gt; 结束状态</em>：当进程已经运行完成或出错时，会被操作系统作结束状态处理；</li> <li><em>运行状态 -&gt; 就绪状态</em>：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；</li> <li><em>运行状态 -&gt; 阻塞状态</em>：当进程请求某个事件且必须等待时，例如请求 I/O 事件；</li> <li><em>阻塞状态 -&gt; 就绪状态</em>：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；</li></ul> <h6 id="进程的控制结构"><a href="#进程的控制结构" class="header-anchor">#</a> 进程的控制结构</h6> <p>在操作系统中，是用<strong>进程控制块</strong>（<em>process control block，PCB</em>）数据结构来描述进程的</p> <blockquote><p>PCB 具体包含什么信息呢？</p></blockquote> <p><strong>进程描述信息：</strong></p> <ul><li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li> <li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li></ul> <p><strong>进程控制和管理信息：</strong></p> <ul><li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li> <li>进程优先级：进程抢占 CPU 时的优先级；</li></ul> <p><strong>资源分配清单：</strong></p> <ul><li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。</li></ul> <p><strong>CPU 相关信息：</strong></p> <ul><li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li></ul> <blockquote><p>每个 PCB 是如何组织的呢？</p></blockquote> <p>通常是通过<strong>链表</strong>的方式进行组织，把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p> <ul><li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li> <li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li> <li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li></ul> <p>那么，就绪队列和阻塞队列链表的组织形式如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032213986.jpeg" alt="就绪队列和阻塞队列"></p> <p>除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。</p> <p>一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除</p> <h6 id="进程的控制"><a href="#进程的控制" class="header-anchor">#</a> 进程的控制</h6> <p>我们熟知了进程的状态变迁和进程的数据结构 PCB 后，再来看看进程的<strong>创建、终止、阻塞、唤醒</strong>的过程，这些过程也就是进程的控制。</p> <p><strong>01 创建进程</strong></p> <p>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。</p> <p>注意：Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管。本文所指出的进程终止概念是宏观操作系统的一种观点，最后怎么实现当然是看具体的操作系统。</p> <p>创建进程的过程如下：</p> <ul><li>为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败；</li> <li>为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；</li> <li>初始化 PCB；</li> <li>如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；</li></ul> <p><strong>02 终止进程</strong></p> <p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。</p> <p>终止进程的过程如下：</p> <ul><li>查找需要终止的进程的 PCB；</li> <li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li> <li>如果其还有子进程，则应将其所有子进程终止；</li> <li>将该进程所拥有的全部资源都归还给父进程或操作系统；</li> <li>将其从 PCB 所在队列中删除；</li></ul> <p><strong>03 阻塞进程</strong></p> <p>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p> <p>阻塞进程的过程如下：</p> <ul><li>找到将要被阻塞进程标识号对应的 PCB；</li> <li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li> <li>将该 PCB 插入到阻塞队列中去；</li></ul> <p><strong>04 唤醒进程</strong></p> <p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。</p> <p>如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。</p> <p>唤醒进程的过程如下：</p> <ul><li>在该事件的阻塞队列中找到相应进程的 PCB；</li> <li>将其从阻塞队列中移出，并置其状态为就绪状态；</li> <li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li></ul> <p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句</p> <h6 id="进程的上下文切换"><a href="#进程的上下文切换" class="header-anchor">#</a> 进程的上下文切换</h6> <p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个<strong>一个进程切换到另一个进程运行，称为进程的上下文切换</strong></p> <p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。</p> <p>所以，<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong></p> <p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032214750.jpeg" alt="进程上下文切换"></p> <p><strong>发生进程上下文切换有哪些场景？</strong></p> <ul><li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li> <li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li> <li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li> <li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li> <li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li></ul> <h5 id="线程"><a href="#线程" class="header-anchor">#</a> 线程</h5> <h6 id="为什么使用线程？"><a href="#为什么使用线程？" class="header-anchor">#</a> 为什么使用线程？</h6> <p>我们举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个：</p> <ul><li>从视频文件当中读取数据；</li> <li>对读取的数据进行解压缩；</li> <li>把解压缩后的视频数据播放出来；</li></ul> <p>对于单进程的实现方式，我想大家都会是以下这个方式：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032216512.jpeg" alt="单进程实现方式"></p> <p>对于单进程的这种方式，存在以下问题：</p> <ul><li>播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，<code>Read</code> 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；</li> <li>各个函数之间不是并发执行，影响资源的使用效率；</li></ul> <p>那改进成多进程的方式：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032216848.jpeg" alt="多进程实现方式"></p> <p>对于多进程的这种方式，依然会存在问题：</p> <ul><li>进程之间如何通信，共享数据？</li> <li>维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；</li></ul> <p>那到底如何解决呢？需要有一种新的实体，满足以下特性：</p> <ul><li>实体之间可以并发运行；</li> <li>实体之间共享相同的地址空间；</li></ul> <p>这个新的实体，就是<strong>线程( Thread )</strong>，线程之间可以并发运行且共享相同的地址空间。</p> <h6 id="什么是线程？"><a href="#什么是线程？" class="header-anchor">#</a> 什么是线程？</h6> <p><strong>线程是进程当中的一条执行流程。</strong></p> <p>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032217332.jpeg" alt="多线程"></p> <p>线程的优点：</p> <ul><li>一个进程中可以同时存在多个线程；</li> <li>各个线程之间可以并发执行；</li> <li>各个线程之间可以共享地址空间和文件等资源；</li></ul> <p>线程的缺点：</p> <ul><li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）。</li></ul> <p>举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程。</p> <h6 id="线程与进程的比较"><a href="#线程与进程的比较" class="header-anchor">#</a> 线程与进程的比较</h6> <p>线程与进程的比较如下：</p> <ul><li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li> <li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li> <li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li> <li>线程能减少并发执行的时间和空间开销；</li></ul> <p>对于，线程相比进程能减少开销，体现在：</p> <ul><li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li> <li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li> <li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li> <li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li></ul> <p>所以，不管是时间效率，还是空间效率线程比进程都要高。</p> <h6 id="线程的实现"><a href="#线程的实现" class="header-anchor">#</a> 线程的实现</h6> <p>主要有三种线程的实现方式：</p> <ul><li><strong>用户线程（User Thread）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li> <li><strong>内核线程（Kernel Thread）</strong>：在内核中实现的线程，是由内核管理的线程；</li> <li><strong>轻量级进程（LightWeight Process）</strong>：在内核中来支持用户线程</li></ul> <h5 id="调度"><a href="#调度" class="header-anchor">#</a> 调度</h5> <p>进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。</p> <p>一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。</p> <p>选择一个进程运行这一功能是在操作系统中完成的，通常称为<strong>调度程序</strong>（<em>scheduler</em>）。</p> <h6 id="调度时机"><a href="#调度时机" class="header-anchor">#</a> 调度时机</h6> <p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p> <p>比如，以下状态的变化都会触发操作系统的调度：</p> <ul><li><em>从就绪态 -&gt; 运行态</em>：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li> <li><em>从运行态 -&gt; 阻塞态</em>：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li> <li><em>从运行态 -&gt; 结束态</em>：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li></ul> <p>因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。</p> <p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p> <ul><li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li> <li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong></li></ul> <h6 id="调度原则"><a href="#调度原则" class="header-anchor">#</a> 调度原则</h6> <p><em>原则一</em>：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，<strong>为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。</strong></p> <p><em>原则二</em>：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，<strong>要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。</strong></p> <p><em>原则三</em>：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，<strong>如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。</strong></p> <p><em>原则四</em>：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，<strong>就绪队列中进程的等待时间也是调度程序所需要考虑的原则。</strong></p> <p><em>原则五</em>：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，<strong>对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032219353.jpeg" alt="五种调度原则"></p> <p>针对上面的五种调度原则，总结成如下：</p> <ul><li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li> <li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li> <li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li> <li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li> <li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li></ul> <h4 id="进程间的通信"><a href="#进程间的通信" class="header-anchor">#</a> 进程间的通信</h4> <h5 id="管道"><a href="#管道" class="header-anchor">#</a> 管道</h5> <p>如果你学过 Linux 命令，那你肯定很熟悉「<code>|</code>」这个竖线。</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">ps</span> auxf <span class="token operator">|</span> <span class="token function">grep</span> mysql
</code></pre></div><p>上面命令行里的「<code>|</code>」竖线就是一个<strong>管道</strong>，它的功能是将前一个命令（<code>ps auxf</code>）的输出，作为后一个命令（<code>grep mysql</code>）的输入，从这功能描述，可以看出<strong>管道传输数据是单向的</strong>，如果想相互通信，我们需要创建两个管道才行。</p> <p>同时，我们得知上面这种管道是没有名字，所以「<code>|</code>」表示的管道称为<strong>匿名管道</strong>，用完了就销毁。</p> <p>管道还有另外一个类型是<strong>命名管道</strong>，也被叫做 <code>FIFO</code>，因为数据是先进先出的传输方式。</p> <p>在使用命名管道前，先需要通过 <code>mkfifo</code> 命令来创建，并且指定管道名字：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">mkfifo</span> myPipe
</code></pre></div><p>myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">ls</span> -l
prw-r--r--. <span class="token number">1</span> root    root         <span class="token number">0</span> Jul <span class="token number">17</span> 02:45 myPipe
</code></pre></div><p>接下来，我们往 myPipe 这个管道写入数据：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token builtin class-name">echo</span> <span class="token string">&quot;hello&quot;</span> <span class="token operator">&gt;</span> myPipe  // 将数据写进管道
                         // 停住了 <span class="token punctuation">..</span>.
</code></pre></div><p>你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。</p> <p>于是，我们执行另外一个命令来读取这个管道里的数据：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">cat</span> <span class="token operator">&lt;</span> myPipe  // 读取管道里的数据
hello
</code></pre></div><p>可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。</p> <p>我们可以看出，<strong>管道这种通信方式效率低，不适合进程间频繁地交换数据</strong>。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。</p> <p>匿名管道的创建，需要通过下面这个系统调用：</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">int</span> <span class="token function">pipe</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 <code>fd[0]</code>，另一个是管道的写入端描述符 <code>fd[1]</code>。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032223337.jpeg" alt="img"></p> <p>其实，<strong>所谓的管道，就是内核里面的一串缓存</strong>。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限</p> <p>我们可以使用 <code>fork</code> 创建子进程，<strong>创建的子进程会复制父进程的文件描述符</strong>，这样就做到了两个进程各有两个「 <code>fd[0]</code> 与 <code>fd[1]</code>」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032224923.jpeg" alt="img"></p> <p>管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：</p> <ul><li>父进程关闭读取的 fd[0]，只保留写入的 fd[1]；</li> <li>子进程关闭写入的 fd[1]，只保留读取的 fd[0]；</li></ul> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032224423.jpeg" alt="img"></p> <p>所以说如果需要双向通信，则应该创建两个管道。</p> <p>到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。</p> <p>在 shell 里面执行 <code>A | B</code>命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032224696.jpeg" alt="img"></p> <h5 id="消息队列"><a href="#消息队列" class="header-anchor">#</a> 消息队列</h5> <p><strong>消息队列是保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</p> <p>但邮件的通信方式存在不足的地方有两点，<strong>一是通信不及时，二是附件也有大小限制</strong>，这同样也是消息队列通信不足的点。</p> <p><strong>消息队列不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 <code>MSGMAX</code> 和 <code>MSGMNB</code>，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</p> <p><strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程</p> <h5 id="共享内存"><a href="#共享内存" class="header-anchor">#</a> 共享内存</h5> <p>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那<strong>共享内存</strong>的方式，就很好的解决了这一问题</p> <p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032226104.jpeg" alt="img"></p> <h5 id="信号量"><a href="#信号量" class="header-anchor">#</a> 信号量</h5> <p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。</p> <p>为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，<strong>信号量</strong>就实现了这一保护机制。</p> <p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。</p> <p>信号量表示资源的数量，控制信号量的方式有两种原子操作：</p> <ul><li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。</li> <li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li></ul> <p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p> <p>接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 <code>1</code>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032227567.jpeg" alt="img"></p> <p>具体的过程如下：</p> <ul><li>进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。</li> <li>若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。</li> <li>直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。</li></ul> <p>可以发现，信号初始化为 <code>1</code>，就代表着是<strong>互斥信号量</strong>，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。</p> <p>另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。</p> <p>例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。</p> <p>那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 <code>0</code>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032227430.jpeg" alt="img"></p> <p>具体过程：</p> <ul><li>如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；</li> <li>接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；</li> <li>最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。</li></ul> <p>可以发现，信号初始化为 <code>0</code>，就代表着是<strong>同步信号量</strong>，它可以保证进程 A 应在进程 B 之前执行。</p> <h5 id="信号"><a href="#信号" class="header-anchor">#</a> 信号</h5> <p>上面说的进程间通信，都是常规状态下的工作模式。<strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong></p> <p>在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 <code>kill -l</code> 命令，查看所有的信号：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>$ <span class="token function">kill</span> -l
 <span class="token number">1</span><span class="token punctuation">)</span> SIGHUP       <span class="token number">2</span><span class="token punctuation">)</span> SIGINT       <span class="token number">3</span><span class="token punctuation">)</span> SIGQUIT      <span class="token number">4</span><span class="token punctuation">)</span> SIGILL       <span class="token number">5</span><span class="token punctuation">)</span> SIGTRAP
 <span class="token number">6</span><span class="token punctuation">)</span> SIGABRT      <span class="token number">7</span><span class="token punctuation">)</span> SIGBUS       <span class="token number">8</span><span class="token punctuation">)</span> SIGFPE       <span class="token number">9</span><span class="token punctuation">)</span> SIGKILL     <span class="token number">10</span><span class="token punctuation">)</span> SIGUSR1
<span class="token number">11</span><span class="token punctuation">)</span> SIGSEGV     <span class="token number">12</span><span class="token punctuation">)</span> SIGUSR2     <span class="token number">13</span><span class="token punctuation">)</span> SIGPIPE     <span class="token number">14</span><span class="token punctuation">)</span> SIGALRM     <span class="token number">15</span><span class="token punctuation">)</span> SIGTERM
<span class="token number">16</span><span class="token punctuation">)</span> SIGSTKFLT   <span class="token number">17</span><span class="token punctuation">)</span> SIGCHLD     <span class="token number">18</span><span class="token punctuation">)</span> SIGCONT     <span class="token number">19</span><span class="token punctuation">)</span> SIGSTOP     <span class="token number">20</span><span class="token punctuation">)</span> SIGTSTP
<span class="token number">21</span><span class="token punctuation">)</span> SIGTTIN     <span class="token number">22</span><span class="token punctuation">)</span> SIGTTOU     <span class="token number">23</span><span class="token punctuation">)</span> SIGURG      <span class="token number">24</span><span class="token punctuation">)</span> SIGXCPU     <span class="token number">25</span><span class="token punctuation">)</span> SIGXFSZ
<span class="token number">26</span><span class="token punctuation">)</span> SIGVTALRM   <span class="token number">27</span><span class="token punctuation">)</span> SIGPROF     <span class="token number">28</span><span class="token punctuation">)</span> SIGWINCH    <span class="token number">29</span><span class="token punctuation">)</span> SIGIO       <span class="token number">30</span><span class="token punctuation">)</span> SIGPWR
<span class="token number">31</span><span class="token punctuation">)</span> SIGSYS      <span class="token number">34</span><span class="token punctuation">)</span> SIGRTMIN    <span class="token number">35</span><span class="token punctuation">)</span> SIGRTMIN+1  <span class="token number">36</span><span class="token punctuation">)</span> SIGRTMIN+2  <span class="token number">37</span><span class="token punctuation">)</span> SIGRTMIN+3
<span class="token number">38</span><span class="token punctuation">)</span> SIGRTMIN+4  <span class="token number">39</span><span class="token punctuation">)</span> SIGRTMIN+5  <span class="token number">40</span><span class="token punctuation">)</span> SIGRTMIN+6  <span class="token number">41</span><span class="token punctuation">)</span> SIGRTMIN+7  <span class="token number">42</span><span class="token punctuation">)</span> SIGRTMIN+8
<span class="token number">43</span><span class="token punctuation">)</span> SIGRTMIN+9  <span class="token number">44</span><span class="token punctuation">)</span> SIGRTMIN+10 <span class="token number">45</span><span class="token punctuation">)</span> SIGRTMIN+11 <span class="token number">46</span><span class="token punctuation">)</span> SIGRTMIN+12 <span class="token number">47</span><span class="token punctuation">)</span> SIGRTMIN+13
<span class="token number">48</span><span class="token punctuation">)</span> SIGRTMIN+14 <span class="token number">49</span><span class="token punctuation">)</span> SIGRTMIN+15 <span class="token number">50</span><span class="token punctuation">)</span> SIGRTMAX-14 <span class="token number">51</span><span class="token punctuation">)</span> SIGRTMAX-13 <span class="token number">52</span><span class="token punctuation">)</span> SIGRTMAX-12
<span class="token number">53</span><span class="token punctuation">)</span> SIGRTMAX-11 <span class="token number">54</span><span class="token punctuation">)</span> SIGRTMAX-10 <span class="token number">55</span><span class="token punctuation">)</span> SIGRTMAX-9  <span class="token number">56</span><span class="token punctuation">)</span> SIGRTMAX-8  <span class="token number">57</span><span class="token punctuation">)</span> SIGRTMAX-7
<span class="token number">58</span><span class="token punctuation">)</span> SIGRTMAX-6  <span class="token number">59</span><span class="token punctuation">)</span> SIGRTMAX-5  <span class="token number">60</span><span class="token punctuation">)</span> SIGRTMAX-4  <span class="token number">61</span><span class="token punctuation">)</span> SIGRTMAX-3  <span class="token number">62</span><span class="token punctuation">)</span> SIGRTMAX-2
<span class="token number">63</span><span class="token punctuation">)</span> SIGRTMAX-1  <span class="token number">64</span><span class="token punctuation">)</span> SIGRTMAX
</code></pre></div><p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如</p> <ul><li>Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程；</li> <li>Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束；</li></ul> <p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p> <p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p> <p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p> <p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p> <h5 id="socket"><a href="#socket" class="header-anchor">#</a> Socket</h5> <p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p> <p>实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。</p> <p>我们来看看创建 socket 的系统调用：</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">int</span> <span class="token function">socket</span><span class="token punctuation">(</span><span class="token keyword">int</span> domain<span class="token punctuation">,</span> <span class="token keyword">int</span> type<span class="token punctuation">,</span> <span class="token keyword">int</span> protocal<span class="token punctuation">)</span>
</code></pre></div><p>三个参数分别代表：</p> <ul><li>domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；</li> <li>type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；</li> <li>protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；</li></ul> <p>根据创建 socket 类型的不同，通信的方式也就不同：</p> <ul><li>实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；</li> <li>实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；</li> <li>实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；</li></ul> <p>接下来，简单说一下这三种通信的编程模式。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032229456.jpeg" alt="img"></p> <ul><li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li> <li>服务端调用 <code>bind</code>，将绑定在 IP 地址和端口;</li> <li>服务端调用 <code>listen</code>，进行监听；</li> <li>服务端调用 <code>accept</code>，等待客户端连接；</li> <li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li> <li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li> <li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li> <li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li></ul> <p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p> <p>所以，监听的 socket 和真正用来传送数据的 socket，是「<strong>两个</strong>」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p> <p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p> <p><strong>针对 UDP 协议通信的 socket 编程模型</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205032230575.jpeg" alt="img"></p> <p>UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。</p> <p>对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。</p> <p>另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。</p> <p><strong>针对本地进程间通信的 socket 编程模型</strong></p> <p>本地 socket 被用于在<strong>同一台主机上进程间通信</strong>的场景：</p> <ul><li>本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；</li> <li>本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；</li></ul> <p>对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。</p> <p>对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。</p> <p>本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是<strong>绑定一个本地文件</strong>，这也就是它们之间的最大区别</p> <h5 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h5> <p>由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。</p> <p>Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。</p> <p><strong>匿名管道</strong>顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「<code>|</code>」竖线就是匿名管道，通信的数据是<strong>无格式的流并且大小受限</strong>，通信的方式是<strong>单向</strong>的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来<strong>匿名管道是只能用于存在父子关系的进程间通信</strong>，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。</p> <p><strong>命名管道</strong>突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是<strong>缓存在内核</strong>中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循<strong>先进先出</strong>原则，不支持 lseek 之类的文件定位操作。</p> <p><strong>消息队列</strong>克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟<strong>每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。</strong></p> <p><strong>共享内存</strong>可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，<strong>它直接分配一个共享空间，每个进程都可以直接访问</strong>，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有<strong>最快</strong>的进程间通信方式之名。但是便捷高效的共享内存通信，<strong>带来新的问题，多进程竞争同个共享资源会造成数据的错乱。</strong></p> <p>那么，就需要<strong>信号量</strong>来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。<strong>信号量不仅可以实现访问的互斥性，还可以实现进程间的同步</strong>，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 <strong>P 操作和 V 操作</strong>。</p> <p>与信号量名字很相似的叫<strong>信号</strong>，它俩名字虽然相似，但功能一点儿都不一样。信号是<strong>异步通信机制</strong>，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，<strong>进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号</strong>。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SIGSTOP</code>，这是为了方便我们能在任何时候结束或停止某个进程。</p> <p>前面说到的通信机制，都是工作于同一台主机，如果<strong>要与不同主机的进程间通信，那么就需要 Socket 通信了</strong>。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。</p> <p>以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？</p> <p>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：</p> <ul><li>互斥的方式，可保证任意时刻只有一个线程访问共享资源；</li> <li>同步的方式，可保证线程 A 应在线程 B 之前执行；</li></ul> <h4 id="死锁"><a href="#死锁" class="header-anchor">#</a> 死锁</h4> <p>死锁只有<strong>同时满足</strong>以下四个条件才会发生</p> <ul><li><strong>互斥条件</strong>：多个线程不能使用同一个资源</li> <li><strong>持有并等待</strong>：一个线程持有资源并且等待其他资源</li> <li><strong>不可剥夺</strong>：在线程持有资源之后，在自己使用完之前不能被其他线程获取，只能自己释放</li> <li><strong>环路等待</strong>：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源</li></ul> <p>那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是<strong>使用资源有序分配法，来破环环路等待条件</strong>。</p> <h5 id="处理死锁"><a href="#处理死锁" class="header-anchor">#</a> 处理死锁</h5> <ul><li>鸵鸟策略</li> <li>死锁检测与死锁恢复</li> <li>死锁预防</li> <li>死锁避免</li></ul> <h5 id="鸵鸟测量"><a href="#鸵鸟测量" class="header-anchor">#</a> 鸵鸟测量</h5> <p>当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。</p> <p>大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。</p> <h5 id="死锁检测与死锁恢复"><a href="#死锁检测与死锁恢复" class="header-anchor">#</a> 死锁检测与死锁恢复</h5> <p>不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复</p> <h6 id="死锁检测"><a href="#死锁检测" class="header-anchor">#</a> 死锁检测</h6> <p>死锁预防策略是非常保守的，他们通过限制访问资源和在进程上强加约束来解决死锁的问题。死锁检测则是完全相反，它不限制资源访问或约束进程行为，只要有可能，被请求的资源就被授权给进程。但是操作系统会周期性地执行一个算法检测前面的循环等待的条件。死锁检测算法是通过资源分配图来检测是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有存在环，也就是检测到死锁的发生。</p> <blockquote><ul><li>（1）如果进程-资源分配图中无环路，此时系统没有死锁。</li> <li>（2）如果进程-资源分配图中有环路，且每个资源类中只有一个资源，则系统发生死锁。</li> <li>（3）如果进程-资源分配图中有环路，且所涉及的资源类有多个资源，则不一定会发生死锁。</li></ul></blockquote> <h6 id="死锁恢复"><a href="#死锁恢复" class="header-anchor">#</a> 死锁恢复</h6> <ul><li>利用抢占恢复</li> <li>利用回滚恢复</li> <li>通过杀死进程恢复</li></ul> <h5 id="死锁的预防"><a href="#死锁的预防" class="header-anchor">#</a> 死锁的预防</h5> <ul><li>破坏&quot;不可剥夺&quot;条件：一个进程不能获得所需要的全部资源时便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到系统的资源列表中，可以被其他的进程使用，而等待的进程只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行。</li> <li>破坏&quot;请求与保持条件&quot;：第一种方法静态分配即每个进程在开始执行时就申请他所需要的全部资源。第二种是动态分配即每个进程在申请所需要的资源时他本身不占用系统资源。</li> <li>破坏&quot;环路等待&quot;条件：采用资源有序分配。其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程。</li></ul> <h5 id="死锁的避免"><a href="#死锁的避免" class="header-anchor">#</a> 死锁的避免</h5> <p><strong>在程序运行时避免发生死锁。</strong></p> <ul><li>在系统运行过程中，对进程提出的每一个（系统能够满足的）资源申请进行动态检查（安全性检查）；</li> <li>根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配。</li></ul> <ol><li>安全状态</li></ol> <p>系统能按某种进程推进顺序( P1, P2, …, Pn)，为每个进程Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序地完成。此时称 P1, P2, …, Pn 为安全序列。如果存在这样一个安全序列，则系统是安全的。</p> <ol start="2"><li>单个资源的银行家算法</li></ol> <p>一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205041603191.png" alt="img"></p> <p>上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态</p> <ol start="3"><li>多个资源的银行家算法</li></ol> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205041603164.png" alt="img"></p> <p>上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4  个资源分别还剩下 1/0/2/0。</p> <p>检查一个状态是否安全的算法如下：</p> <ul><li>查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。</li> <li>假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。</li> <li>重复以上两步，直到所有进程都标记为终止，则状态时安全的。</li></ul> <p>如果一个状态不是安全的，需要拒绝进入这个状态。</p> <p><strong>死锁避免和死锁预防的区别</strong></p> <ul><li><strong>死锁预防是设法至少破坏产生死锁的四个必要条件之一,严格的防止死锁的出现</strong></li> <li>而死锁避免则不那么严格的限制产生死锁的必要条件的存在,因为即使死锁的必要条件存在,也不一定发生死锁。</li> <li><strong>死锁避免是在系统运行过程中注意避免死锁的最终发生。</strong></li></ul> <h2 id="锁"><a href="#锁" class="header-anchor">#</a> 锁</h2> <h3 id="锁的类别"><a href="#锁的类别" class="header-anchor">#</a> 锁的类别</h3> <p><strong>互斥锁、自旋锁、读写锁、乐观锁、悲观锁</strong></p> <h3 id="互斥锁与自旋锁"><a href="#互斥锁与自旋锁" class="header-anchor">#</a> 互斥锁与自旋锁</h3> <p>最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。</p> <p>加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。</p> <p>当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：</p> <ul><li><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；</li> <li><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；</li></ul> <p>互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，<strong>既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞</strong>。</p> <p><strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205041607311.png" alt="img"></p> <p>所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。</p> <p>那这个开销成本是什么呢？会有<strong>两次线程上下文切换的成本</strong>：</p> <ul><li>当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；</li> <li>接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。</li></ul> <p>所以，<strong>如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。</strong></p> <p>自旋锁是通过 CPU 提供的 <code>CAS</code> 函数（<em>Compare And Swap</em>），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。</p> <p>一般加锁的过程，包含两个步骤：</p> <ul><li>第一步，查看锁的状态，如果锁是空闲的，则执行第二步；</li> <li>第二步，将锁设置为当前线程持有；</li></ul> <p>CAS 函数就把这两个步骤合并成一条硬件级指令，形成<strong>原子指令</strong>，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。</p> <p>比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。</p> <p>使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 <code>while</code> 循环等待实现，不过最好是使用 CPU 提供的 <code>PAUSE</code> 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。</p> <p>自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：<strong>当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对</strong>。</p> <h3 id="读写锁"><a href="#读写锁" class="header-anchor">#</a> 读写锁</h3> <p>读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。</p> <p>所以，<strong>读写锁适用于能明确区分读操作和写操作的场景</strong>。</p> <p>读写锁的工作原理是：</p> <ul><li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li> <li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li></ul> <p>所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。</p> <p>知道了读写锁的工作原理后，我们可以发现，<strong>读写锁在读多写少的场景，能发挥出优势</strong>。</p> <p>另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。</p> <p>读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205041611678.png" alt="img"></p> <p>而写优先锁是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取读锁。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205041611995.png" alt="img"></p> <p>读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。</p> <p>写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。</p> <p>既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。</p> <p><strong>公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。</strong></p> <p>互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现</p> <h3 id="乐观锁与悲观锁"><a href="#乐观锁与悲观锁" class="header-anchor">#</a> 乐观锁与悲观锁</h3> <p>悲观锁做事比较悲观，它认为<strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。</p> <p>那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。</p> <p>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。</p> <p><strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong></p> <p>这里举一个场景例子：在线文档。</p> <p>我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。</p> <p>那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。</p> <p>怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。</p> <p>服务端要怎么验证是否冲突了呢？通常方案如下：</p> <ul><li>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；</li> <li>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。</li></ul> <p>实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。</p> <p>乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以<strong>只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁</strong></p> <h2 id="调度算法"><a href="#调度算法" class="header-anchor">#</a> 调度算法</h2> <h3 id="进程调度算法"><a href="#进程调度算法" class="header-anchor">#</a> 进程调度算法</h3> <p>进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。</p> <p>当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。</p> <p>什么时候会发生 CPU 调度呢？通常有以下情况：</p> <ol><li>当进程从运行状态转到等待状态；</li> <li>当进程从运行状态转到就绪状态；</li> <li>当进程从等待状态转到就绪状态；</li> <li>当进程从运行状态转到终止状态；</li></ol> <p>其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。</p> <h5 id="_1-批处理系统"><a href="#_1-批处理系统" class="header-anchor">#</a> 1. 批处理系统</h5> <p>批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。</p> <ul><li><strong>先来先服务（FCFS）（非抢占式）</strong></li></ul> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051249129.png" alt="image-20211202214115967"></p> <p>每次从就绪队列里面选择最先进入队列的进程，然后一直运行，直到进程退出或者被阻塞，才会继续从队列中选择第一个进程运行</p> <p>FCFS对长作业有利，适用于CPU繁忙的系统，不适合I/O繁忙的系统</p> <ul><li><strong>短作业优先（SJF）（非抢占式）</strong></li></ul> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051249146.png" alt="image-20211202214448818"></p> <p>非抢占式的调度算法，按估计运行时间最短的顺序进行调度。</p> <p>长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度</p> <ul><li><strong>最短剩余时间优先 shortest remaining time next（SRTN）</strong></li></ul> <p>最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待</p> <ul><li><strong>高响应比的调度</strong></li></ul> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051249154.png" alt="image-20211202214754686"></p> <ul><li>如果两个等待时间相同，要求服务的时间越短，响应比越高，这样短作业容易被选中</li> <li>如果两个进程的服务时间相同，等待时间越长，响应比越高，这样就兼顾到了长作业，因为只要其等待的时间足够长，其响应比就越高，越容易运行</li></ul> <h5 id="_2-交互式系统"><a href="#_2-交互式系统" class="header-anchor">#</a> 2. 交互式系统</h5> <p>交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应，也就是等待时间和响应时间要短</p> <ul><li><strong>时间片轮转</strong></li></ul> <p>每个进程被分配一个时间片，时间片用完就释放CPU</p> <p>时间片的长度很关键：</p> <ul><li><p>时间片太短了导致过多的上下文切换，降低了CPU的效率</p></li> <li><p>时间片太长将引起短作业的响应时间变长</p></li> <li><p><strong>最高优先级调度算法</strong></p></li></ul> <p>从就绪队列中选择最高优先级的进程进行运行，就称为最高优先级调度算法</p> <p>优先级可以分为静态优先级和动态优先级：</p> <ul><li>静态优先级：创建进程的时候就确定了优先级，整个运行时间都不会变</li> <li>动态优先级：根据进程的动态变化调整优先级，比如进程的运行时间增加，就降低优先级，如果进程等待时间增加，就升高优先级。</li></ul> <p>该算法也有两种处理优先级高的方法:抢占式和非抢占式</p> <ul><li><p>非抢占式：当就绪队列出现优先级高的进程，运行完当前进程，在选择优先级高的进程</p></li> <li><p>抢占式：当就绪队列出现优先级高的进程，当前进程挂起，调度优先级高的进程运行</p></li> <li><p><strong>多级反馈队列调度算法</strong></p></li></ul> <p>多级反馈队列调度算法是时间片轮转和最高优先级算法的综合和发展</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051250398.jpeg" alt="多级反馈队列"></p> <ul><li>设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li> <li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li> <li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li></ul> <p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的<strong>兼顾了长短作业，同时有较好的响应时间。</strong></p> <h3 id="内存页面置换算法"><a href="#内存页面置换算法" class="header-anchor">#</a> 内存页面置换算法</h3> <p>在了解内存页面置换算法前，我们得先谈一下<strong>缺页异常（缺页中断）</strong>。</p> <p>当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：</p> <ul><li>缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。</li> <li>缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。</li></ul> <p>我们来看一下缺页中断的处理流程，如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051314284.png" alt="缺页中断的处理流程"></p> <ol><li>在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。</li> <li>如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。</li> <li>操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。</li> <li>找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。</li> <li>页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。</li> <li>最后，CPU 重新执行导致缺页异常的指令。</li></ol> <p>不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。</p> <p>这里提一下，页表项通常有如下图的字段：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051314386.png" alt="img"></p> <p>那其中：</p> <ul><li><em>状态位</em>：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li> <li><em>访问字段</em>：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li> <li><em>修改位</em>：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li> <li><em>硬盘地址</em>：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li></ul> <p>这里我整理了虚拟内存的管理整个流程，你可以从下面这张图看到：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051314555.png" alt="虚拟内存的流程"></p> <p>所以，页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。</p> <p>那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：</p> <ul><li>最佳页面置换算法（<em>OPT</em>）</li> <li>先进先出置换算法（<em>FIFO</em>）</li> <li>最近最久未使用的置换算法（<em>LRU</em>）</li> <li>时钟页面置换算法（<em>Lock</em>）</li> <li>最不常用置换算法（<em>LFU</em>）</li></ul> <h5 id="最佳页面置换算法"><a href="#最佳页面置换算法" class="header-anchor">#</a> 最佳页面置换算法</h5> <p>最佳页面置换算法基本思路是，<strong>置换在「未来」最长时间不访问的页面</strong></p> <p>我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051315528.png" alt="最佳页面置换算法"></p> <p>在这个请求的页面序列中，缺页共发生了 <code>7</code> 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 <code>4</code> 次。</p> <p>这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。</p> <p>所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。</p> <h5 id="先进先出置换算法"><a href="#先进先出置换算法" class="header-anchor">#</a> 先进先出置换算法</h5> <p>既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以<strong>选择在内存驻留时间很长的页面进行中置换</strong>，这个就是「先进先出置换」算法的思想。</p> <p>还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051315849.png" alt="先进先出置换算法"></p> <p>在这个请求的页面序列中，缺页共发生了 <code>10</code> 次，页面置换共发生了 <code>7</code> 次，跟最佳页面置换算法比较起来，性能明显差了很多</p> <h5 id="最近最久未使用的置换算法"><a href="#最近最久未使用的置换算法" class="header-anchor">#</a> 最近最久未使用的置换算法</h5> <p>最近最久未使用（<em>LRU</em>）的置换算法的基本思路是，发生缺页时，<strong>选择最长时间没有被访问的页面进行置换</strong>，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。</p> <p>这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。</p> <p>还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051316585.png" alt="最近最久未使用的置换算法"></p> <p>在这个请求的页面序列中，缺页共发生了 <code>9</code> 次，页面置换共发生了 <code>6</code> 次，跟先进先出置换算法比较起来，性能提高了一些。</p> <p>虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。</p> <p>困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。</p> <p>所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用</p> <h5 id="时钟页面置换算法"><a href="#时钟页面置换算法" class="header-anchor">#</a> 时钟页面置换算法</h5> <p>那有没有一种即能优化置换的次数，也能方便实现的算法呢？</p> <p>时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。</p> <p>该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。</p> <p>当发生缺页中断时，算法首先检查表针指向的页面：</p> <ul><li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li> <li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li></ul> <p>我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051316465.png" alt="时钟页面置换算法"></p> <h5 id="最不常用算法"><a href="#最不常用算法" class="header-anchor">#</a> 最不常用算法</h5> <p>最不常用（<em>LFU</em>）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是<strong>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰</strong>。</p> <p>它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。</p> <p>看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。</p> <p>要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。</p> <p>但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。</p> <p>那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。</p> <h3 id="磁盘调度算法"><a href="#磁盘调度算法" class="header-anchor">#</a> 磁盘调度算法</h3> <p>我们来看看磁盘的结构，如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051317130.jpeg" alt="磁盘的结构"></p> <p><strong>磁盘结构</strong></p> <ul><li>盘面（Platter）：一个磁盘有多个盘面；</li> <li>磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；</li> <li>扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；</li> <li>磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；</li> <li>制动手臂（Actuator arm）：用于在磁道之间移动磁头；</li> <li>主轴（Spindle）：使整个盘面转动。</li></ul> <p>常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 <code>512</code> 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。</p> <p>磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。</p> <p>寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。</p> <p>假设有下面一个请求序列，每个数字代表磁道的位置：</p> <p>98，183，37，122，14，124，65，67</p> <p>初始磁头当前的位置是在第 <code>53</code> 磁道。</p> <p>接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有：</p> <ul><li>先来先服务算法</li> <li>最短寻道时间优先算法</li> <li>扫描算法算法</li> <li>循环扫描算法</li> <li>LOOK 与 C-LOOK 算法</li></ul> <h5 id="先来先服务"><a href="#先来先服务" class="header-anchor">#</a> 先来先服务</h5> <p>先来先服务（<em>First-Come，First-Served，FCFS</em>），顾名思义，先到来的请求，先被服务。</p> <p>那按照这个序列的话：</p> <p>98，183，37，122，14，124，65，67</p> <p>那么，磁盘的写入顺序是从左到右，如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051317424.png" alt="先来先服务"></p> <p>先来先服务算法总共移动了 <code>640</code> 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长</p> <h5 id="最短寻道时间优先"><a href="#最短寻道时间优先" class="header-anchor">#</a> 最短寻道时间优先</h5> <p>最短寻道时间优先（<em>Shortest Seek First，SSF</em>）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求，还是以这个序列为例子：</p> <p>98，183，37，122，14，124，65，67</p> <p>那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：</p> <p>65，67，37，14，98，122，124，183</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051317935.png" alt="最短寻道时间优先"></p> <p>磁头移动的总距离是 <code>236</code> 磁道，相比先来先服务性能提高了不少。</p> <p>但这个算法可能存在某些请求的<strong>饥饿</strong>，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里<strong>产生饥饿的原因是磁头在一小块区域来回移动</strong>。</p> <h5 id="扫描算法"><a href="#扫描算法" class="header-anchor">#</a> 扫描算法</h5> <p>最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。</p> <p>为了防止这个问题，可以规定：<strong>磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（*Scan*）算法</strong>。</p> <p>这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。</p> <p>还是以这个序列为例子，磁头的初始位置是 53：</p> <p>98，183，37，122，14，124，65，67</p> <p>那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序：</p> <p>37，14，<code>0</code>，65，67，98，122，124，183</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051318254.png" alt="扫描算法"></p> <p>磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。</p> <p>扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。</p> <h5 id="循环扫描算法"><a href="#循环扫描算法" class="header-anchor">#</a> 循环扫描算法</h5> <p>扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。</p> <p>循环扫描（<em>Circular Scan, CSCAN</em> ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且<strong>返回中途不处理任何请求</strong>，该算法的特点，就是<strong>磁道只响应一个方向上的请求</strong>。</p> <p>还是以这个序列为例子，磁头的初始位置是 53：</p> <p>98，183，37，122，14，124，65，67</p> <p>那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序：</p> <p>65，67，98，122，124，183，<code>199</code>，<code>0</code>，14，37</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051318769.png" alt="循环扫描算法"></p> <p>磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。</p> <p>循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。</p> <h5 id="look-与-c-look算法"><a href="#look-与-c-look算法" class="header-anchor">#</a> LOOK 与 C-LOOK算法</h5> <p>我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。</p> <p>那这其实是可以优化的，优化的思路就是<strong>磁头在移动到「最远的请求」位置，然后立即反向移动。</strong></p> <p>那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中会响应请求</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051318512.png" alt="LOOK 算法"></p> <p>而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中不会响应请求</strong>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051318354.png" alt="C-LOOK 算法"></p> <h2 id="文件系统"><a href="#文件系统" class="header-anchor">#</a> 文件系统</h2> <h3 id="文件系统的基本组成"><a href="#文件系统的基本组成" class="header-anchor">#</a> 文件系统的基本组成</h3> <p>文件系统是操作系统中负责管理持久数据的子系统，说简单点，就是负责把用户的文件存到磁盘硬件中，因为即使计算机断电了，磁盘里的数据并不会丢失，所以可以持久化的保存文件。</p> <p>文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</p> <p>Linux 最经典的一句话是：「<strong>一切皆文件</strong>」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。</p> <p>Linux 文件系统会为每个文件分配两个数据结构：<strong>索引节点（index node）和目录项（directory entry）</strong>，它们主要用来记录文件的元信息和目录层次结构。</p> <ul><li>索引节点，也就是 <em>inode</em>，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、<strong>数据在磁盘的位置</strong>等等。索引节点是文件的<strong>唯一</strong>标识，它们之间一一对应，也同样都会被存储在硬盘中，所以<strong>索引节点同样占用磁盘空间</strong>。</li> <li>目录项，也就是 <em>dentry</em>，用来记录文件的名字、<strong>索引节点指针</strong>以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，<strong>目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存</strong>。</li></ul> <p>由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</p> <p><strong>那文件数据是如何存储在磁盘的呢？</strong></p> <p>磁盘读写的最小单位是<strong>扇区</strong>，扇区的大小只有 <code>512B</code> 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。</p> <p>所以，文件系统把多个扇区组成了一个<strong>逻辑块</strong>，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 <code>4KB</code>，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</p> <p>以上就是索引节点、目录项以及文件数据的关系，下面这个图就很好的展示了它们之间的关系：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051418619.png" alt="img"></p> <p>索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</p> <p>另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</p> <ul><li><em>超级块</em>，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</li> <li><em>索引节点区</em>，用来存储索引节点；</li> <li><em>数据块区</em>，用来存储文件或目录数据；</li></ul> <p>我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</p> <ul><li>超级块：当文件系统挂载时进入内存；</li> <li>索引节点区：当文件被访问时进入内存</li></ul> <h3 id="虚拟文件系统"><a href="#虚拟文件系统" class="header-anchor">#</a> 虚拟文件系统</h3> <p>文件系统的种类众多，而操作系统希望<strong>对用户提供一个统一的接口</strong>，于是在用户层与文件系统层引入了中间层，这个中间层就称为<strong>虚拟文件系统（Virtual File System，VFS）。</strong></p> <p>VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可</p> <p>在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051419597.png" alt="img"></p> <p>Linux 支持的文件系统也不少，根据存储位置的不同，可以把文件系统分为三类：</p> <ul><li><em>磁盘的文件系统</em>，它是直接把数据存储在磁盘中，比如 Ext 2/3/4、XFS 等都是这类文件系统。</li> <li><em>内存的文件系统</em>，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 <code>/proc</code> 和 <code>/sys</code> 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据。</li> <li><em>网络的文件系统</em>，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</li></ul> <h3 id="文件的存储"><a href="#文件的存储" class="header-anchor">#</a> 文件的存储</h3> <p>文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</p> <ul><li>连续空间存放方式</li> <li>非连续空间存放方式</li></ul> <p>其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</p> <p>不同的存储方式，有各自的特点，重点是要分析它们的存储效率和读写性能，接下来分别对每种存储方式说一下。</p> <h5 id="连续空间存放方式"><a href="#连续空间存放方式" class="header-anchor">#</a> 连续空间存放方式</h5> <p>连续空间存放方式顾名思义，<strong>文件存放在磁盘「连续的」物理空间中</strong>。这种模式下，文件的数据都是紧密相连，<strong>读写效率很高</strong>，因为一次磁盘寻道就可以读出整个文件。</p> <p>使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</p> <p>所以，<strong>文件头里需要指定「起始块的位置」和「长度」</strong>，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</p> <p>注意，此处说的文件头，就类似于 Linux 的 inode。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051419333.png" alt="连续空间存放方式"></p> <p>连续空间存放的方式虽然读写效率高，<strong>但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。</strong></p> <p>如下图，如果文件 B 被删除，磁盘上就留下一块空缺，这时，如果新来的文件小于其中的一个空缺，我们就可以将其放在相应空缺里。但如果该文件的大小大于所有的空缺，但却小于空缺大小之和，则虽然磁盘上有足够的空缺，但该文件还是不能存放。当然了，我们可以通过将现有文件进行挪动来腾出空间以容纳新的文件，但是这个在磁盘挪动文件是非常耗时，所以这种方式不太现实。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051420990.png" alt="磁盘碎片"></p> <p>另外一个缺陷是文件长度扩展不方便，例如上图中的文件 A 要想扩大一下，需要更多的磁盘空间，唯一的办法就只能是挪动的方式，前面也说了，这种方式效率是非常低的。</p> <p>那么有没有更好的方式来解决上面的问题呢？答案当然有，既然连续空间存放的方式不太行，那么我们就改变存放的方式，使用非连续空间存放方式来解决这些缺陷。</p> <h5 id="非连续空间存放方式"><a href="#非连续空间存放方式" class="header-anchor">#</a> 非连续空间存放方式</h5> <p>非连续空间存放方式分为「链表方式」和「索引方式」</p> <p><strong>我们先来看看链表的方式。</strong></p> <p>链表的方式存放是<strong>离散的，不用连续的</strong>，于是就可以<strong>消除磁盘碎片</strong>，可大大提高磁盘空间的利用率，同时<strong>文件的长度可以动态扩展</strong>。根据实现的方式的不同，链表可分为「<strong>隐式链表</strong>」和「<strong>显式链接</strong>」两种形式。</p> <p>文件要以「<strong>隐式链表</strong>」的方式存放的话，<strong>实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置</strong>，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051420884.png" alt="隐式链表"></p> <p>隐式链表的存放方式的<strong>缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间</strong>。隐式链接分配的<strong>稳定性较差</strong>，系统在运行过程中由于软件或者硬件错误<strong>导致链表中的指针丢失或损坏，会导致文件数据的丢失。</strong></p> <p>如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「<strong>显式链接</strong>」，它指<strong>把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中</strong>，该表在整个磁盘仅设置一张，<strong>每个表项中存放链接指针，指向下一个数据块号</strong>。</p> <p>对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为<strong>文件分配表（*File Allocation Table，FAT*）</strong>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051420792.png" alt="显式链接"></p> <p>由于查找记录的过程是在内存中进行的，因而不仅显著地<strong>提高了检索速度</strong>，而且<strong>大大减少了访问磁盘的次数</strong>。但也正是整个表都存放在内存中的关系，它的主要的缺点是<strong>不适用于大磁盘</strong>。</p> <p>比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</p> <p><strong>接下来，我们来看看索引的方式。</strong></p> <p>链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</p> <p>索引的实现是为每个文件创建一个「<strong>索引数据块</strong>」，里面存放的是<strong>指向文件数据块的指针列表</strong>，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</p> <p>另外，<strong>文件头需要包含指向「索引数据块」的指针</strong>，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</p> <p>创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051421278.png" alt="索引的方式"></p> <p>索引的方式优点在于：</p> <ul><li>文件的创建、增大、缩小很方便；</li> <li>不会有碎片的问题；</li> <li>支持顺序读写和随机读写；</li></ul> <p>由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</p> <p>如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</p> <p>先来看看链表 + 索引的组合，这种组合称为「<strong>链式索引块</strong>」，它的实现方式是<strong>在索引数据块留出一个存放下一个索引数据块的指针</strong>，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051421312.png" alt="链式索引块"></p> <p>还有另外一种组合方式是索引 + 索引的方式，这种组合称为「<strong>多级索引块</strong>」，实现方式是<strong>通过一个索引块来存放多个索引数据块</strong>，一层套一层索引，像极了俄罗斯套娃是吧。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051421313.png" alt="多级索引块"></p> <h5 id="unix-文件的实现方式"><a href="#unix-文件的实现方式" class="header-anchor">#</a> Unix 文件的实现方式</h5> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051421236.png" alt="img"></p> <p>那早期 Unix 文件系统是组合了前面的文件存放方式的优点，如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051421954.png" alt="早期 Unix 文件系统"></p> <h4 id="空闲空间管理"><a href="#空闲空间管理" class="header-anchor">#</a> 空闲空间管理</h4> <p>前面说到的文件的存储是针对已经被占用的数据块组织和管理，接下来的问题是，如果我要保存一个数据块，我应该放在硬盘上的哪个位置呢？难道需要将所有的块扫描一遍，找个空的地方随便放吗？</p> <p>那这种方式效率就太低了，所以针对磁盘的空闲空间也是要引入管理的机制，接下来介绍几种常见的方法：</p> <ul><li>空闲表法</li> <li>空闲链表法</li> <li>位图法</li></ul> <h5 id="空闲表法"><a href="#空闲表法" class="header-anchor">#</a> 空闲表法</h5> <p>空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051422747.png" alt="空闲表法"></p> <p>当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。</p> <p>这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。</p> <h5 id="空闲链表法"><a href="#空闲链表法" class="header-anchor">#</a> 空闲链表法</h5> <p>我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051422478.png" alt="空闲链表法"></p> <p>当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。</p> <p>这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。</p> <p>空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大</p> <h5 id="位图法"><a href="#位图法" class="header-anchor">#</a> 位图法</h5> <p>位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。</p> <p>当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：</p> <div class="language-text extra-class"><pre class="language-text"><code>1111110011111110001110110111111100111 ...
</code></pre></div><p>在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理</p> <h4 id="文件系统的结构"><a href="#文件系统的结构" class="header-anchor">#</a> 文件系统的结构</h4> <p>前面提到 Linux 是用位图的方式管理空闲空间，用户在创建一个新文件时，Linux 内核会通过 inode 的位图找到空闲可用的 inode，并进行分配。要存储数据时，会通过块的位图找到空闲的块，并分配，但仔细计算一下还是有问题的。</p> <p>数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 <code>4 * 1024 * 8 = 2^15</code> 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 <code>2^15 * 4 * 1024 = 2^27</code> 个 byte，也就是 128M。</p> <p>也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。</p> <p>在 Linux 文件系统，把这个结构称为一个<strong>块组</strong>，那么有 N 多的块组，就能够表示 N 大的文件。</p> <p>下图给出了 Linux Ext2 整个文件系统的结构和块组的内容，文件系统都由大量块组组成，在硬盘上相继排布：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051423737.png" alt="img"></p> <p>最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：</p> <ul><li><em>超级块</em>，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。</li> <li><em>块组描述符</em>，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。</li> <li><em>数据位图和 inode 位图</em>， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。</li> <li><em>inode 列表</em>，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。</li> <li><em>数据块</em>，包含文件的有用数据。</li></ul> <p>你可以会发现每个块组里有很多重复的信息，比如<strong>超级块和块组描述符表，这两个都是全局信息，而且非常的重要</strong>，这么做是有两个原因：</p> <ul><li>如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。</li> <li>通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。</li></ul> <p>不过，Ext2 的后续版本采用了稀疏技术。该做法是，超级块和块组描述符表不再存储到文件系统的每个块组中，而是只写入到块组 0、块组 1 和其他 ID 可以表示为 3、 5、7 的幂的块组中。</p> <h4 id="目录的存储"><a href="#目录的存储" class="header-anchor">#</a> 目录的存储</h4> <p>在前面，我们知道了一个普通文件是如何存储的，但还有一个特殊的文件，经常用到的目录，它是如何保存的呢？</p> <p>基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 <code>vim</code> 打开它，它也有 inode，inode 里面也是指向一些块。</p> <p>和普通文件不同的是，<strong>普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。</strong></p> <p>在目录文件的块中，最简单的保存格式就是<strong>列表</strong>，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。</p> <p>列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051424117.png" alt="目录格式哈希表"></p> <p>通常，第一项是「<code>.</code>」，表示当前目录，第二项是「<code>..</code>」，表示上一级目录，接下来就是一项一项的文件名和 inode。</p> <p>如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。</p> <p>于是，保存目录的格式改成<strong>哈希表</strong>，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。</p> <p>Linux 系统的 ext 文件系统就是采用了哈希表，来保存目录的内容，这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免哈希冲突。</p> <p>目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I/O 操作，开销较大。所以，为了减少 I/O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。</p> <h4 id="软链接和硬链接"><a href="#软链接和硬链接" class="header-anchor">#</a> 软链接和硬链接</h4> <p>有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过<strong>硬链接（*Hard Link*）</strong> 和<strong>软链接（*Symbolic Link*）</strong> 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。</p> <p>硬链接是<strong>多个目录项中的「索引节点」指向一个文件</strong>，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以<strong>硬链接是不可用于跨文件系统的</strong>。由于多个目录项都是指向一个 inode，那么<strong>只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051424846.png" alt="硬链接"></p> <p>软链接相当于重新创建一个文件，这个文件有<strong>独立的 inode</strong>，但是这个<strong>文件的内容是另外一个文件的路径</strong>，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以<strong>软链接是可以跨文件系统的</strong>，甚至<strong>目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已</strong></p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051424170.png" alt="软链接"></p> <h4 id="文件-i-o"><a href="#文件-i-o" class="header-anchor">#</a> 文件 I/O</h4> <p>文件的读写方式各有千秋，对于文件的 I/O 分类也非常多，常见的有</p> <ul><li>缓冲与非缓冲 I/O</li> <li>直接与非直接 I/O</li> <li>阻塞与非阻塞 I/O VS 同步与异步 I/O</li></ul> <p>接下来，分别对这些分类讨论讨论。</p> <h5 id="缓冲与非缓冲-i-o"><a href="#缓冲与非缓冲-i-o" class="header-anchor">#</a> 缓冲与非缓冲 I/O</h5> <p>文件操作的标准库是可以实现数据的缓存，那么<strong>根据「是否利用标准库缓冲」，可以把文件 I/O 分为缓冲 I/O 和非缓冲 I/O</strong>：</p> <ul><li>缓冲 I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。</li> <li>非缓冲 I/O，直接通过系统调用访问文件，不经过标准库缓存。</li></ul> <p>这里所说的「缓冲」特指标准库内部实现的缓冲。</p> <p>比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。</p> <h5 id="直接与非直接-i-o"><a href="#直接与非直接-i-o" class="header-anchor">#</a> 直接与非直接 I/O</h5> <p>我们都知道磁盘 I/O 是非常慢的，所以 Linux 内核为了减少磁盘 I/O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I/O 的请求</p> <p>那么，<strong>根据是「否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O</strong>：</p> <ul><li>直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。</li> <li>非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。</li></ul> <p>如果你在使用文件操作类的系统调用函数时，指定了 <code>O_DIRECT</code> 标志，则表示使用直接 I/O。如果没有设置过，默认使用的是非直接 I/O。</p> <p><strong>如果用了非直接 I/O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘？</strong></p> <p>以下几种场景会触发内核缓存的数据写入磁盘：</p> <ul><li>在调用 <code>write</code> 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；</li> <li>用户主动调用 <code>sync</code>，内核缓存会刷到磁盘上；</li> <li>当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；</li> <li>内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；</li></ul> <h5 id="阻塞与非阻塞-i-o-vs-同步与异步-i-o"><a href="#阻塞与非阻塞-i-o-vs-同步与异步-i-o" class="header-anchor">#</a> 阻塞与非阻塞 I/O VS 同步与异步 I/O</h5> <p>先来看看<strong>阻塞 I/O</strong>，当用户程序执行 <code>read</code> ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，<code>read</code> 才会返回。</p> <p>注意，<strong>阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程</strong>。过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051444793.png" alt="阻塞 I/O"></p> <p>知道了阻塞 I/O ，来看看<strong>非阻塞 I/O</strong>，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，<code>read</code> 调用才可以获取到结果。过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051444322.png" alt="非阻塞 I/O"></p> <p>注意，<strong>这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</strong></p> <p>举个例子，访问管道或 socket 时，如果设置了 <code>O_NONBLOCK</code> 标志，那么就表示使用的是非阻塞 I/O 的方式访问，而不做任何设置的话，默认是阻塞 I/O。</p> <p>应用程序每次轮询内核的 I/O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。</p> <p>为了解决这种傻乎乎轮询方式，于是 <strong>I/O 多路复用</strong>技术就出来了，如 select、poll，它是通过 I/O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。</p> <p>这个做法大大改善了应用进程对 CPU 的利用率，在没有被通知的情况下，应用进程可以使用 CPU 做其他的事情。</p> <p>下图是使用 select I/O 多路复用过程。注意，<code>read</code> 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个<strong>同步的过程</strong>，需要等待：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051444010.png" alt="I/O 多路复用"></p> <p>实际上，无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用<strong>都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</strong></p> <p>而真正的<strong>异步 I/O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。</p> <p>当我们发起 <code>aio_read</code> 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051445795.png" alt="异步 I/O"></p> <p>在前面我们知道了，I/O 是分为两个过程的：</p> <ol><li>数据准备的过程</li> <li>数据从内核空间拷贝到用户进程缓冲区的过程</li></ol> <p>阻塞 I/O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I/O 和基于非阻塞 I/O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I/O。</p> <p>异步 I/O 则不同，「过程 1 」和「过程 2 」都不会阻塞。</p> <h2 id="设备管理"><a href="#设备管理" class="header-anchor">#</a> 设备管理</h2> <h3 id="设备控制器"><a href="#设备控制器" class="header-anchor">#</a> 设备控制器</h3> <p>我们的电脑设备可以接非常多的输入输出设备，比如键盘、鼠标、显示器、网卡、硬盘、打印机、音响等等，每个设备的用法和功能都不同，那操作系统是如何把这些输入输出设备统一管理的呢?</p> <p>为了屏蔽设备之间的差异，每个设备都有一个叫<strong>设备控制器（*Device Control*）</strong> 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051446946.png" alt="计算机 I/O 系统结构"></p> <p>因为这些控制器都很清楚的知道对应设备的用法和功能，所以 CPU 是通过设备控制器来和设备打交道的。</p> <p>设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信，比如：</p> <ul><li>通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。</li> <li>通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。</li></ul> <p>实际上，控制器是有三类寄存器，它们分别是<strong>状态寄存器（Status Register）</strong>、 <strong>命令寄存器（Command Register）以及数据寄存器（Data Register）</strong>，如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051446522.png" alt="img"></p> <p>这三个寄存器的作用：</p> <ul><li><em>数据寄存器</em>，CPU 向 I/O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I/O 设备。</li> <li><em>命令寄存器</em>，CPU 发送一个命令，告诉 I/O 设备，要进行输入/输出操作，于是就会交给 I/O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。</li> <li><em>状态寄存器</em>，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。</li></ul> <p>CPU 通过读写设备控制器中的寄存器控制设备，这可比 CPU 直接控制输入输出设备，要方便和标准很多。</p> <p>另外， 输入输出设备可分为两大类 ：<strong>块设备（*Block Device*）**和**字符设备（*Character Device*）</strong>。</p> <ul><li><em>块设备</em>，把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB 是常见的块设备。</li> <li><em>字符设备</em>，以字符为单位发送或接收一个字符流，字符设备是不可寻址的，也没有任何寻道操作，鼠标是常见的字符设备。</li></ul> <p>块设备通常传输的数据量会非常大，于是控制器设立了一个可读写的<strong>数据缓冲区</strong>。</p> <ul><li>CPU 写入数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才会发给设备。</li> <li>CPU 从控制器的缓冲区读取数据时，也需要缓冲区囤够了一部分，才拷贝到内存。</li></ul> <p>这样做是为了，减少对设备的频繁操作。</p> <p>那 CPU 是如何与设备的控制寄存器和数据缓冲区进行通信的？存在两个方法：</p> <ul><li><em>端口 I/O</em>，每个控制寄存器被分配一个 I/O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 <code>in/out</code> 类似的指令。</li> <li><em>内存映射 I/O</em>，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。</li></ul> <h3 id="i-o-控制方式"><a href="#i-o-控制方式" class="header-anchor">#</a> I/O 控制方式</h3> <p>在前面我知道，每种设备都有一个设备控制器，控制器相当于一个小 CPU，它可以自己处理一些事情，但有个问题是，当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？</p> <p>控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种<strong>轮询等待</strong>的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成，很明显，这种方式非常的傻瓜，它会占用 CPU 的全部时间。</p> <p>那我们就想到第二种方法 —— <strong>中断</strong>，通知操作系统数据已经准备好了。我们一般会有一个硬件的<strong>中断控制器</strong>，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断。</p> <p>另外，中断有两种，一种<strong>软中断</strong>，例如代码调用 <code>INT</code> 指令触发，一种是<strong>硬件中断</strong>，就是硬件通过中断控制器触发的。</p> <p>但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 <strong>DMA（Direct Memory Access）</strong> 功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I/O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051447306.png" alt="img"></p> <p>DMA 的工作方式如下：</p> <ul><li>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</li> <li>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</li> <li>当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；</li> <li>DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；</li></ul> <p>可以看到， CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷贝到内存后，DMA 控制机器通过中断的方式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU 干预</p> <h3 id="设备驱动程序"><a href="#设备驱动程序" class="header-anchor">#</a> 设备驱动程序</h3> <p>虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了<strong>设备驱动程序</strong>。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051452875.png" alt="img"></p> <p>设备控制器不属于操作系统范畴，它是属于硬件，而设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。</p> <p>不同的设备控制器虽然功能不同，但是<strong>设备驱动程序会提供统一的接口给操作系统</strong>，这样不同的设备驱动程序，就可以以相同的方式接入操作系统。如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051452974.png" alt="img"></p> <p>前面提到了不少关于中断的事情，设备完成了事情，则会发送中断来通知操作系统。那操作系统就需要有一个地方来处理这个中断，这个地方也就是在设备驱动程序里，它会及时响应控制器发来的中断请求，并根据这个中断的类型调用响应的<strong>中断处理程序</strong>进行处理。</p> <p>通常，设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051452412.png" alt="img"></p> <p>我们来看看，中断处理程序的处理流程：</p> <ol><li>在 I/O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；</li> <li>保护被中断进程的 CPU 上下文；</li> <li>转入相应的设备中断处理函数；</li> <li>进行中断处理；</li> <li>恢复被中断进程的上下文</li></ol> <h3 id="通用块层"><a href="#通用块层" class="header-anchor">#</a> 通用块层</h3> <p>对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的<strong>通用块层</strong>，来管理不同的块设备。</p> <p>通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：</p> <ul><li>第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；</li> <li>第二功能，通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。</li></ul> <p>Linux 内存支持 5 种 I/O 调度算法，分别是：</p> <ul><li>没有调度算法</li> <li>先入先出调度算法</li> <li>完全公平调度算法</li> <li>优先级调度</li> <li>最终期限调度算法</li></ul> <p>第一种，没有调度算法，是的，你没听错，它不对文件系统和应用程序的 I/O 做任何处理，这种算法常用在虚拟机 I/O 中，此时磁盘 I/O 调度算法交由物理机系统负责。</p> <p>第二种，先入先出调度算法，这是最简单的 I/O 调度算法，先进入 I/O 调度队列的 I/O 请求先发生。</p> <p>第三种，完全公平调度算法，大部分系统都把这个算法作为默认的 I/O 调度器，它为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。</p> <p>第四种，优先级调度算法，顾名思义，优先级高的 I/O 请求先发生， 它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。</p> <p>第五种，最终期限调度算法，分别为读、写请求创建了不同的 I/O 队列，这样可以提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适用于在 I/O 压力比较大的场景，比如数据库等。</p> <h3 id="存储系统-i-o-软件分层"><a href="#存储系统-i-o-软件分层" class="header-anchor">#</a> 存储系统 I/O 软件分层</h3> <p>前面说到了不少东西，设备、设备控制器、驱动程序、通用块层，现在再结合文件系统原理，我们来看看 Linux 存储系统的 I/O 软件分层。</p> <p>可以把 Linux 存储系统的 I/O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。他们整个的层次关系如下图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051453251.png" alt="img"></p> <p>这三个层次的作用是：</p> <ul><li>文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li> <li>通用块层，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。</li> <li>设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。</li></ul> <p>有了文件系统接口之后，不但可以通过文件系统的命令行操作设备，也可以通过应用程序，调用 <code>read</code>、<code>write</code> 函数，就像读写文件一样操作设备，所以说设备在 Linux 下，也只是一个特殊的文件。</p> <p>但是，除了读写操作，还需要有检查特定于设备的功能和属性。于是，需要 <code>ioctl</code> 接口，它表示输入输出控制接口，是用于配置和修改特定设备属性的通用接口。</p> <p>另外，存储系统的 I/O 是整个系统最慢的一个环节，所以 Linux 提供了不少缓存机制来提高 I/O 的效率。</p> <ul><li>为了提高文件访问的效率，会使用<strong>页缓存、索引节点缓存、目录项缓存</strong>等多种缓存机制，目的是为了减少对块设备的直接调用。</li> <li>为了提高块设备的访问效率， 会使用<strong>缓冲区</strong>，来缓存块设备的数据</li></ul> <h3 id="键盘敲入字母时，期间发生了什么？"><a href="#键盘敲入字母时，期间发生了什么？" class="header-anchor">#</a> 键盘敲入字母时，期间发生了什么？</h3> <p>看完前面的内容，相信你对输入输出设备的管理有了一定的认识，那接下来就从操作系统的角度回答开头的问题「键盘敲入字母时，操作系统期间发生了什么？」</p> <p>我们先来看看 CPU 的硬件架构图：</p> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051505963.png" alt="CPU 的硬件架构图"></p> <p>CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器，这个 I/O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I/O 总线，用来连接 I/O 设备，比如键盘、显示器等。</p> <p>那当用户输入了键盘字符，<strong>键盘控制器</strong>就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送<strong>中断请求</strong>。</p> <p>CPU 收到中断请求后，操作系统会<strong>保存被中断进程的 CPU 上下文</strong>，然后调用键盘的<strong>中断处理程序</strong>。</p> <p>键盘的中断处理程序是在<strong>键盘驱动程序</strong>初始化时注册的，那键盘<strong>中断处理函数</strong>的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。</p> <p>得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。</p> <p>显示出结果后，<strong>恢复被中断进程的上下文</strong></p> <h2 id="面试题"><a href="#面试题" class="header-anchor">#</a> 面试题</h2> <h3 id="进程与线程的区别和联系"><a href="#进程与线程的区别和联系" class="header-anchor">#</a> 进程与线程的区别和联系</h3> <p>区别
进程是对运行时程序的封装，是系统进行资源分配和调度的基本单元，而线程是进程的子任务，是CPU分配和调度的基本单元。
一个进程可以有多个线程，但是一个线程只能属于一个进程。
进程的创建需要系统分配内存和CPU，文件句柄等资源，销毁时也要进行相应的回收，所以进程的管理开销很大；但是线程的管理开销则很小。
进程之间不会相互影响；而一个线程崩溃会导致进程崩溃，从而影响同个进程里面的其他线程。
联系 进程与线程之间的关系：线程是存在进程的内部，一个进程中可以有多个线程，一个线程只能存在一个进程中</p> <h3 id="协程与线程的区别？"><a href="#协程与线程的区别？" class="header-anchor">#</a> 协程与线程的区别？</h3> <ul><li>线程和进程都是同步机制，而协程是异步机制。</li> <li>线程是抢占式，而协程是非抢占式的。需要用户释放使用权切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。</li> <li>一个线程可以有多个协程，一个进程也可以有多个协程。</li> <li>协程不被操作系统内核管理，而完全是由程序控制。线程是被分割的CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器关联任意线程或线程池。</li> <li>协程能保留上一次调用时的状态。</li></ul> <h3 id="linux理论上最多可以创建多少个进程？一个进程可以创建多少线程，和什么有关"><a href="#linux理论上最多可以创建多少个进程？一个进程可以创建多少线程，和什么有关" class="header-anchor">#</a> Linux理论上最多可以创建多少个进程？一个进程可以创建多少线程，和什么有关</h3> <p>32768因为进程的pid是用pid_t来表示的，pid_t的最大值是32768.所以理论上最多有32768个进程。</p> <p>至于线程。进程最多可以创建的线程数是根据分配给调用栈的大小，以及操作系统（32位和64位不同）共同决定的。Linux32位下是300多个。</p> <h3 id="进程间同步的方式有哪些？"><a href="#进程间同步的方式有哪些？" class="header-anchor">#</a> 进程间同步的方式有哪些？</h3> <p>1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。</p> <p>优点：保证在某一时刻只有一个线程能访问数据的简便办法。</p> <p>缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。</p> <p>2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。</p> <p>优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。</p> <p>缺点：</p> <ul><li>互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。</li> <li>通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。</li></ul> <p>3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。</p> <p>优点：适用于对Socket（套接字）程序中线程的同步。</p> <p>缺点:</p> <ul><li>信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；</li> <li>信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；</li> <li>核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。</li></ul> <p>4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。</p> <p>优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。</p> <h3 id="线程同步的方式有哪些"><a href="#线程同步的方式有哪些" class="header-anchor">#</a> 线程同步的方式有哪些</h3> <p>线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：</p> <ol><li><strong>互斥量(Mutex)</strong>：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。</li> <li><strong>信号量(Semphares)</strong> ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量</li> <li><strong>事件(Event)</strong> :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操</li></ol> <h3 id="什么是缓冲区溢出？有什么危害？"><a href="#什么是缓冲区溢出？有什么危害？" class="header-anchor">#</a> 什么是缓冲区溢出？有什么危害？</h3> <p>缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。</p> <p>危害有以下两点：</p> <ul><li>程序崩溃，导致拒绝额服务</li> <li>跳转并且执行一段恶意代码</li></ul> <p>造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。</p> <h3 id="硬链接和软链接有什么区别？"><a href="#硬链接和软链接有什么区别？" class="header-anchor">#</a> 硬链接和软链接有什么区别？</h3> <ul><li>硬链接就是在目录下创建一个条目，记录着文件名与 <code>inode</code> 编号，这个 <code>inode</code> 就是源文件的 <code>inode</code>。删除任意一个条目，文件还是存在，只要引用数量不为 <code>0</code>。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。</li> <li>符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 <code>Windows</code> 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。</li></ul> <h3 id="中断的处理过程"><a href="#中断的处理过程" class="header-anchor">#</a> 中断的处理过程?</h3> <ol><li>保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。</li> <li>开中断：以便执行中断时能响应较高级别的中断请求。</li> <li>中断处理</li> <li>关中断：保证恢复现场时不被新中断打扰</li> <li>恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。</li></ol> <h3 id="孤儿进程和僵尸进程分别是什么"><a href="#孤儿进程和僵尸进程分别是什么" class="header-anchor">#</a> 孤儿进程和僵尸进程分别是什么</h3> <ul><li><p>孤儿进程是父进程退出后它的子进程还在执行，这时候这些子进程就成为孤儿进程。孤儿进程会被init进程收养并完成状态收集。</p></li> <li><p>僵尸进程是指子进程完成并退出后父进程没有使用wait()或者waitpid()对它们进行状态收集，这些子进程的进程描述符仍然会留在系统中。这些子进程就成为僵尸进程。</p></li></ul> <h3 id="同一个进程内的线程会共享什么资源"><a href="#同一个进程内的线程会共享什么资源" class="header-anchor">#</a> 同一个进程内的线程会共享什么资源</h3> <ul><li>该进程的地址空间</li> <li>全局变量</li> <li>堆空间</li></ul> <p>线程的栈空间是自己独有的</p> <h3 id="虚拟内存"><a href="#虚拟内存" class="header-anchor">#</a> 虚拟内存</h3> <p>在运行一个进程的时候，它所需要的内存空间可能大于系统的物理内存容量。通常一个进程会有4G的空间，但是物理内存并没有这么大，所以这些空间都是虚拟内存，它的地址都是逻辑地址，每次在访问的时候都需要映射成物理地址。</p> <p>当进程访问某个逻辑地址的时候，会去查看页表，如果页表中没有相应的物理地址，说明内存中没有这页的数据，发生缺页异常，这时候进程需要把数据从磁盘拷贝到物理内存中。如果物理内存已经满了，就需要覆盖已有的页，如果这个页曾经被修改过，那么还要把它写回磁盘。</p> <h3 id="协程"><a href="#协程" class="header-anchor">#</a> 协程</h3> <p>协程和微线程是一个东西。</p> <p>协程就是子程序在执行时中断并转去执行别的子程序，在适当的时候又返回来执行。
这种子程序间的跳转不是函数调用，也不是多线程执行，所以省去了线程切换的开销，效率很高，并且不需要多线程间的锁机制，不会发生变量写冲突</p> <p><strong>那协程的底层是怎么实现的，怎么使用协程</strong></p> <p>协程进行中断跳转时将函数的上下文存放在其他位置中，而不是存放在函数堆栈里，当处理完其他事情跳转回来的时候，取回上下文继续执行原来的函数。</p> <h3 id="进程的状态以及转换图"><a href="#进程的状态以及转换图" class="header-anchor">#</a> 进程的状态以及转换图</h3> <p>三态模型
三态模型包括三种状态：</p> <ol><li>执行：进程分到CPU时间片，可以执行</li> <li>就绪：进程已经就绪，只要分配到CPU时间片，随时可以执行</li> <li>阻塞：有IO事件或者等待其他资源</li></ol> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051527298.png" alt="img"></p> <p>五态模型</p> <ol><li>新建态：进程刚刚创建。</li> <li>就绪态：</li> <li>运行态：</li> <li>等待态：出现等待事件</li> <li>终止态：进程结束</li></ol> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051527467.png" alt="img"></p> <p>七态模型</p> <ol><li>新建态</li> <li>就绪挂起态</li> <li>就绪态</li> <li>运行态</li> <li>等待态</li> <li>挂起等待态</li> <li>终止态</li></ol> <p><img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051527065.png" alt="img"></p> <h3 id="系统调用-用户态和内核态"><a href="#系统调用-用户态和内核态" class="header-anchor">#</a> 系统调用 / 用户态和内核态</h3> <p>根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：</p> <ul><li>用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。</li> <li>系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。</li></ul> <h3 id="说了用户态和系统态之后，那么什么是系统调用呢？"><a href="#说了用户态和系统态之后，那么什么是系统调用呢？" class="header-anchor">#</a> 说了用户态和系统态之后，那么什么是系统调用呢？</h3> <ul><li>我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！</li> <li>也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。</li></ul> <p>这些系统调用按功能大致可分为如下几类：</p> <ul><li>设备管理。完成设备的请求或释放，以及设备启动等功能。</li> <li>文件管理。完成文件的读、写、创建及删除等功能。</li> <li>进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。</li> <li>进程通信。完成进程之间的消息传递或信号传递等功能。</li> <li>内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。</li></ul> <h3 id="那么如何从用户态切换到内核态呢"><a href="#那么如何从用户态切换到内核态呢" class="header-anchor">#</a> 那么如何从用户态切换到内核态呢</h3> <ul><li>系统调用
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如 read 操作，比如前例中 fork() 实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。</li> <li>异常
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li> <li>外围设备的中断
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li></ul> <p>这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。</p> <h3 id="pcb是什么"><a href="#pcb是什么" class="header-anchor">#</a> PCB是什么</h3> <p>PCB主要包含下面几部分的内容：</p> <ul><li>进程的描述信息，比如进程的名称，标识符，</li> <li>处理机的状态信息，当程序中断是保留此时的信息，以便 CPU 返回时能从断点执行</li> <li>进程调度信息，比如阻塞原因，状态，优先级等等</li> <li>进程控制和资源占用，同步通信机制，链接指针（指向队列中下一个进程的 PCB 地址）</li></ul> <p>PCB 的作用</p> <ul><li>PCB是进程实体的一部分，是操作系统中最重要的数据结构</li> <li>由于它的存在，使得多道程序环境下，不能独立运行的程序成为一个能独立运行的基本单位，使得程序可以并发执行</li> <li>系统通过 PCB 来感知进程的存在。（换句话说，PCB 是进程存在的唯一标识）</li> <li>进程的组成可以用下图来表示，PCB 就是他唯一标识符。
<img src="https://guli-file-fxy.oss-cn-shanghai.aliyuncs.com/img/202205051556297.png" alt="图片说明"></li></ul> <h3 id="进程和线程创建和撤销的过程中发生了什么事情"><a href="#进程和线程创建和撤销的过程中发生了什么事情" class="header-anchor">#</a> 进程和线程创建和撤销的过程中发生了什么事情</h3> <p>进程允许创建和控制另一个进程，前者称为父进程，后者称为子进程，子进程又可以创建孙进程，如此下去进而形成一个进程的家族树，这样子进程就可以从父进程那里继承所有的资源，当子进程撤销时，便将从父进程处获得的所有资源归还，此外，撤销父进程，则必须撤销所有的子进程。（撤销的过程实际上就是对这棵家族树进行后序遍历的过程）
在应用中创建一个子进程的过程如下：</p> <ul><li>申请空白的PCB</li> <li>初始化进程描述信息</li> <li>为进程分配资源以及地址空间</li> <li>将其插入就绪队列中</li></ul> <p>当进程完成后，系统会回收占用的资源，撤销进程，而引发进程撤销的情况有：进程正常结束或者异常结束，外界的干预（比如我们在任务管理器中强制停止某个进程的运行）。</p> <ul><li>查找需要撤销的进程的 PCB</li> <li>如果进程处于运行状态，终止进程并进行调度</li> <li>终止子孙进程 - 归还资源</li> <li>将它从所在的队列中移除</li></ul></div> <footer class="page-edit" style="display:none;"><!----> <!----></footer> <!----> <!----> <!----></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/assets/js/app.3bc42cf8.js" defer></script><script src="/assets/js/3.0146fe10.js" defer></script><script src="/assets/js/1.760be874.js" defer></script><script src="/assets/js/23.35607ff8.js" defer></script>
  </body>
</html>
